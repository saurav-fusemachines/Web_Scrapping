   ,job_title                                                                            ,company                                 ,location           ,job_type             ,salary                            ,posted_on    ,job_qualification            ,job_description
 0 ,Junior Data Engineer                                                                 ,HYR Global Source Inc                   ," Dallas, TX"      ,Contract             ,Estimated: $77.3K - $97.9K a year ,6 days ago   ,"Microsoft Windows Server
                                                                                                                                                                                                                              Windows
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Scripting
                                                                                                                                                                                                                              Linux
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              PowerShell"                  ,"['Job Title - Junior Data Engineer', '', 'Location - Dallas TX Hybrid ( No Relocation )', '', 'Tax Term (W2, C2C) - W2 / C2C', '', '', 'Position Type(Contract/permanent) - Contract', '', 'Project Duration - Long term 12+ months', '', '', '', '', 'Job description -', '', 'The candidate needs to be hungry to learn and will be working with the Data team, looking for someone who is willing to learn and is motivated to grow within.', '', 'Scripting – Python, KSH, Powershell', 'Knowledge about Linux, and Windows Server Operating System', 'AWS basic knowledge']"
 1 ,Lead Big Data Engineer                                                               ,ITgen systems                           ," Dallas, TX"      ,Contract             ,$60 - $70 an hour                 ,13 hours ago ,"Azure
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Apache Hive
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Hadoop"                      ,"['Job Title: Lead Big Data Engineer', 'Location: Dallas, TX (Hybrid)', 'Duration: 12 Months.', 'Job Description :', 'MUST HAVE', '', '4 Years of Azure – REQUIRED.', '4+ years of', 'Data engineering', 'experience', '4+ years of experience in any or all', 'Big-Data stack', 'such as', 'Hadoop, Hive, Spark, python', '4+ years of Relational data base experience', '4 + years of', 'ETL (Extract, Transform, Load)', 'development experience using any Big-Data technology', '2+ years of', 'Agile', 'software development experience', 'Job Type: Contract', 'Salary: $60.00 - $70.00 per hour', 'Experience:', 'ETL: 3 years (Required)', 'AZURE: 4 years (Required)', 'Agile: 3 years (Required)', 'Data Engineering: 4 years (Required)', 'Hadoop/Hive: 4 years (Required)', 'Work Location: Hybrid remote in Dallas, TX 75201']"
 2 ,Data Engineer (Remote)                                                               ,Ad Hoc Team - 5.0                       ," Dallas, TX"      ,                     ," $101,570 - $136,994 a year"     ,5 days ago   ,"Data modeling
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Scala
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Redshift
                                                                                                                                                                                                                              4 years
                                                                                                                                                                                                                              System security
                                                                                                                                                                                                                              Python"                      ,"['This is a fully remote position.', '', 'Work on things that matter', ""Ad Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we're also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us."", '', 'What matters most', ""Ad Hoc operates according to our commitment to inclusivity, acceptance, accountability, and humility. We aren't heroes. We believe in missions larger than our individual selves and leave our egos at the door, learn from our mistakes, and iterate in order to better serve the people in our country. We prioritize building teams that represent the diversity of the people our government serves. We love the challenge of government-size projects. We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government."", '', 'Built for a remote life', ""Ad Hoc is remote-first and remote-always. We've designed our culture, communications, and tools to support a nationwide distributed team since the beginning. Being remote by design allows Ad Hoc to be thoughtful and intentional about creating diverse teams and supporting them with a work environment that fits their lives. With a generous PTO policy and Slack channels for every interest (from bird watching to space nerds to parenting) our culture embraces the things happening in your life. Maybe you need to adjust your schedule to care for your family or take a bike ride. At Ad Hoc, that's embraced."", '', ""What you'll do"", '', 'Data Engineers are responsible for working with the systems and infrastructure that enable data storage, processing, and analysis. They work closely with data scientists and analysts to ensure that data is properly collected, organized, enriched, refined, and available for analysis. They are the critical connectors between the teams that maintain existing legacy systems, and the data analysts and data scientists that will use aggregated data for analysis, reporting, and predictive analytics.', '', '', 'Shipping software that impacts the lives of millions of people', '', 'Using modern programming languages and frameworks to build scalable services that gracefully integrate with legacy systems', '', 'Building and working with APIs to support both the digital services we deliver as well as third-party usage', '', 'Helping us continuously, iteratively improve', '', ""What we hope you'll bring"", '', '', 'A minimum of four (4) years of professional software development experience', '', 'AWS experience', '', 'Understanding of ETL/ELT processes and tooling', '', 'Understanding of database technologies - setup/ maintenance / data loads / etc. (not data modeling)', '', 'Redshift experience preferred', '', 'Understand system security', '', 'API design and implementation', '', 'GIT and DevOps release process', '', 'Python or Scala, Python is preferred for ETL', '', 'Some experience with older file systems / file based processes such as MOVEit', '', 'Some experience with Mulesoft', '', 'Experience with agile software development practices emphasizing agility, flexibility, and iterative development', '', '', ""More than that, our ideal candidate wants to contribute to work that is bigger than themselves and wants to make a difference collaborating with their team. They care deeply about building better products, better relationships, and better trust in each interaction people have with their government. They believe in intuitive, easy-to-use government services. They collaborate well with designers, stakeholders, and other teams. They mentor and guide more junior engineers. They're human-centered."", '', ""And if you don't check every box on the list? That doesn't mean you can't help us in our mission to deliver critical government services. Talk to us!"", '', 'Some basic requirements', '', 'All work must be conducted within the U.S., excluding U.S. territories. Some federal contracts require U.S. citizenship to be eligible for employment.', '', 'You must be legally authorized to work in the U.S now and in the future without sponsorship.', '', 'As a government contractor, you may be required to obtain a public trust security clearance.', '', ""Bachelor's Degree in a technical field is preferred"", '', '4 years of professional software development', '', 'Our technical screening involves completing a homework assignment that is then graded blind to remove bias. We do not do tricky, unreliable whiteboarding tests. You can read more about our homework here.', '', '', 'Learn more about engineering at Ad Hoc.', '', 'Benefits', '', 'Company-subsidized Health, Dental, and Vision Insurance', '', 'Use What You Need Vacation Policy', '', '401K with employer match', '', 'Paid parental leave after one year of service', '', '', 'Ad Hoc LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.', '', ""In support of the Colorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $101,570 - $136,994 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements."", '', 'job reference: 2015']"
 3 ,Associate Data Engineer                                                              ,48forty Solutions - 2.8                 ," Houston, TX"     ,Full-time            ,Estimated: $66.2K - $83.8K a year ,11 hours ago ,"CI/CD
                                                                                                                                                                                                                              Power BI
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Test automation
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Data visualization
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Communication skills"        ,"['48forty Solutions is the largest pallet management services company in North America. We provide end-to-end pallet solutions, from supply to retrieval, on-site services, reverse logistics, and packaging materials. 48forty Solutions is truly Pallet Management Made Simple. Our operations workforce is the heart and soul of our business. We are currently looking for an', 'Associate Data Engineer.', '', 'Summary', '', 'As an Associate Data Engineer, you will be responsible for supporting the design, development, and maintenance of data pipelines and data processing systems using various technologies such as Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Databricks, Azure DevOps, Git, Power BI, Azure Synapse Analytics, and Azure Databricks. You will work under the guidance of more senior data engineers and play a vital role in ensuring the availability, reliability, and scalability of data infrastructure and supporting data-driven initiatives within the organization.', '', 'Essential Duties and Responsibilities', '', '', 'Data pipeline development:', 'Collaborate with the data engineering team to develop and maintain data pipelines, ETL processes, and data integration workflows using Azure Data Factory, Azure Synapse Analytics, Spark SQL, and other relevant technologies. Ensure the timely and accurate movement of data between systems.', '', 'Data processing and transformation:', 'Assist in implementing data processing and transformation logic using Azure Synapse Analytics, Spark SQL or Databricks. Extract insights from raw data and transform it into meaningful and structured formats in our data products.', '', 'Azure service utilization:', 'Work with Azure services such as SQL Server, Azure Data Factory, Azure Synapse and Azure Databricks to build and manage data infrastructure components. Leverage the capabilities of these services to ensure efficient and scalable data processing.', '', 'Version control and collaboration:', 'Utilize Azure DevOps and Git for version control and collaborate effectively with the team to manage code repositories and ensure proper documentation and knowledge sharing.', '', 'Azure DevOps integration:', 'Assist in integrating data engineering workflows with Azure DevOps for continuous integration, continuous deployment, and automated testing. Contribute to the implementation of CI/CD pipelines for data engineering projects.', '', 'Data visualization and reporting:', 'Gain exposure to Power BI and support the team in developing insightful and visually appealing reports and dashboards to communicate data insights effectively to stakeholders.', '', 'Troubleshooting and support:', 'Assist in identifying and resolving data pipeline issues, bottlenecks, and data quality problems. Provide support in investigating and troubleshooting data-related incidents.', '', 'Continuous learning and growth', ': Stay updated with the latest advancements in data engineering technologies and tools. Continuously enhance your knowledge of Azure services and data engineering best practices.', '', '', 'Qualifications and Skills', '', '', '2-5 years of experience in data engineering, data integration, or related roles.', '', 'Hands-on experience with Azure services, including Azure Data Factory, Azure Synapse, and Azure Databricks.', '', 'Proficiency in SQL programming and experience working with SQL Server.', '', 'Familiarity with Spark SQL or Databricks for data processing and transformation.', '', 'Exposure to Git for version control and collaborative development.', '', 'Knowledge of Azure DevOps practices for CI/CD and automated testing.', '', 'Experience with data visualization tools, such as Power BI, for developing reports and dashboards.', '', 'Understanding of Azure Analysis Services and Azure Synapse Analytics is a plus.', '', 'Strong problem-solving skills and attention to detail.', '', 'Good communication and teamwork skills, with the ability to work effectively in a collaborative environment.', '', 'Self-motivated and eager to learn and grow in the field of data engineering.', '', '', 'Work Environment', '', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.', '', '', 'The employee will be working at the corporate office and will be required to sit for long periods of time at a desk working on a laptop.', '', 'The noise level in the work environment is usually moderate.', '', '', 'Benefits', '', '', 'Competitive Pay', '', 'Holiday Pay', '', 'Referral Bonuses', '', 'Long-Term Career Advancement', '', 'Great Team Environment', '', 'PTO', '', 'Full-time employees eligible for Medical, Dental, Vision, Basic Life, AD&D and Short-Term & Long-Term Disability insurance on the 1st of the month following 60 days of employment', '', '', '48forty Solutions', 'is an equal opportunity employer.', 'Privacy Policy', '', 'CA Applicant', '', 'CA Workforce']"
 4 ,Data Engineer                                                                        ,Southwestern Energy (SWN) - 4.0         ," Spring, TX"      ,Full-time            ,Estimated: $100K - $127K a year   ,17 hours ago ,"Power BI
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              Management
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              5 years
                                                                                                                                                                                                                              Bachelor of Science
                                                                                                                                                                                                                              R
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              Information Systems
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              System testing
                                                                                                                                                                                                                              Scripting
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              SSIS
                                                                                                                                                                                                                              Informatica
                                                                                                                                                                                                                              Python"                      ,"['Southwestern Energy', 'is searching for a', 'Data Engineer', 'to join our Corporate IT team.', 'You will analyze user needs and develop solutions to support data science workflows, data and application integrations, analytics platforms, or specialized utility programs with the aim of optimizing operational efficiency while adhering to appropriate data quality and data governance principles. You will work individually and coordinate database development as part of a team and lead small to medium projects and assists on large projects. Functions as primary support for all solutions in one or more discipline(s) and secondary support for multiple solutions in related disciplines. You will report to the BIS Manager and the position is located at our headquarters in Spring, TX.', 'To be successful in this role you will:', 'Write, analyze, review, and rewrite programs, using workflow charts and diagrams, and applying knowledge of computer capabilities, subject matter, and symbolic logic.', 'Perform revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements.', 'Analyze user needs and software requirements to determine feasibility of design within time and cost constraints.', 'Confer with systems analysts, engineers, programmers and others to design systems and to obtain information on project limitations and capabilities, performance requirements and interfaces.', 'Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program.', 'Develop and perform software system testing and validation procedures.', 'Store, retrieve, and manipulate data for analysis of system capabilities and requirements.', 'Analyze information to determine, recommend, and plan installation of a new system or modification of an existing system.', 'Coordinate software system installation and monitor equipment functioning to ensure specifications are met.', 'Consult with engineering staff to evaluate interface between hardware and software, develop specifications and performance requirements, or resolve customer problems.', 'Confer with data processing or project managers to obtain information on limitations or capabilities for data processing projects.', 'Participate in on-call and after-hours support, including weekends and holidays.', 'Lead medium projects as defined by scope', 'Qualifications - External', 'Your Background includes:', 'Bachelor of Science degree in computer science, engineering, or management of information systems is preferred.', 'Minimum of 5 years of software development experience', 'Experience creating dashboards and analysis using tools such as Microsoft PowerBI, TIBCO Spotfire, Tableau, etc. is required.', 'Experience querying and developing Oracle and Microsoft SQL Server databases is required.', 'Experience integrating data using ETL technologies such as Informatica, Dell Boomi, Microsoft SSIS/DTS, etc. is required.', 'Experience integrating applications using APIs and scripting languages. Python/R is a plus.', 'Knowledge of WellView, SiteView, Enertia, and other upstream oil and gas systems is a plus.', 'Ability to communicate ideas in both technical and user-friendly language', 'Strong customer focus mindset', 'Job Type: Full-time', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Schedule:', 'Monday to Friday', 'Ability to commute/relocate:', 'Spring, TX 77389: Reliably commute or planning to relocate before starting work (Required)', 'Work Location: In person']"
 5 ,Data Engineer                                                                        ,Medici - 5.0                            ," Austin, TX"      ,                     ,Estimated: $104K - $132K a year   ,8 hours ago  ,"Performance tuning
                                                                                                                                                                                                                              Computer science
                                                                                                                                                                                                                              Data modeling
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              Relational databases
                                                                                                                                                                                                                              Encryption
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              MongoDB
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              PostgreSQL
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              AI
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              MySQL"                       ,"['Overview', 'Medici is changing the healthcare system by delivering best-in-class preventative and complex condition care that dramatically improves outcomes, provides quick access to care, and significantly reduces medical costs. We’ve been able to accomplish this by providing holistic, AI-infused, comprehensive, and integrated care, Medici helps members become healthier while delivering cost savings to employers.', 'The Medici Marketing & Communications Team focuses on creating personal human connections through modern, data-driven, and creative strategies. We create content, communications, and experiences that engage and inspire our members to take action while staying aligned with client and business values and growth goals. We continually measure our effectiveness and make adjustments to improve our impact.', 'About the role', 'We are seeking an experienced Data Engineer with 3-5 years of hands-on', 'experience in working with PostgreSQL, SQL Server, SQL, and schema design. As a Data Engineer,', 'you will be responsible for managing and optimizing our data infrastructure, ensuring the efficient', 'storage, retrieval, and processing of data. You will collaborate closely with cross-functional teams to', 'design and implement scalable data solutions, enabling data-driven decision-making across the', 'organization.', '', 'Key Responsibilities', 'Data Infrastructure Management: Design, develop, and maintain the data infrastructure, including databases, data pipelines, and ETL processes, to support efficient data storage, retrieval, and processing.', 'Schema Design: Collaborate with data scientists, analysts, and other stakeholders to design database schemas that optimize data retrieval and storage while adhering to industry best practices.', 'Data Modeling: Create and maintain data models and data dictionaries to ensure consistency and standardization across data sources and systems.', 'Performance Optimization: Monitor and fine-tune database performance by identifying and resolving bottlenecks, optimizing queries, and implementing indexing strategies.', 'ETL Development: Develop and maintain scalable Extract, Transform, Load (ETL) processes to ensure data quality, integrity, and timeliness.', 'Data Security: Implement and maintain data security measures, including access controls, data encryption, and compliance with relevant regulations (e.g., GDPR, HIPAA).', 'Data Quality and Governance: Establish data quality standards, perform data profiling, and implement data governance processes to ensure data accuracy, consistency, and completeness.', 'Collaboration and Communication: Collaborate with cross-functional teams, including data scientists, analysts, software engineers, and business stakeholders, to understand data requirements and translate them into technical solutions. Communicate effectively to present complex technical concepts to non-technical stakeholders.', 'Documentation: Document data infrastructure, processes, and technical specifications to ensure knowledge transfer and enable smooth maintenance and troubleshooting.', 'Continuous Learning: Stay up-to-date with emerging technologies, trends, and best practices in data engineering and apply them to improve existing systems and processes.', 'Required Skills and Qualifications', ""Bachelor's degree in Computer Science, Engineering, or a related field."", '3-5 years of professional experience as a Data Engineer or in a similar role.', 'Strong proficiency in working with relational databases, particularly PostgreSQL and SQL Server, including database design, querying, optimization, and performance tuning.', 'Solid understanding of SQL and experience with advanced SQL concepts, such as subqueries, window functions, and stored procedures.', 'Experience with data modeling and schema design, including normalization, denormalization, and indexing strategies.', 'Strong knowledge of ETL processes and tools for data integration, transformation, and loading.', 'Familiarity with data warehouse concepts and technologies (e.g., star schema, data lakes).', 'Understanding of data security principles and experience implementing data security measures.', 'Excellent problem-solving and analytical skills with the ability to work on complex data-related challenges.', 'Strong communication and collaboration skills with the ability to work effectively in a cross-functional team environment.', 'Attention to detail and a commitment to delivering high-quality work.', 'Self-motivated and able to work independently with minimal supervision.', 'Familiarity with other database systems, such as MySQL, Oracle, or MongoDB, is a plus.', 'Knowledge of cloud platforms and services, such as AWS, Azure, or GCP, is a plus.']"
 6 ,IT Data Engineer                                                                     ,Kelly-Moore Paint Company - 3.6         ," Irving, TX"      ,Full-time            ,Estimated: $95.4K - $121K a year  ,1 hour ago   ,"ITIL Certification
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              Writing skills
                                                                                                                                                                                                                              Architecture
                                                                                                                                                                                                                              English
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Database management
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Scripting
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              IT
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data Science"                ,"[""Kelly-Moore's mission is to provide high quality, innovative products with exceptional service at fair value. What sets Kelly-Moore Paint Company apart from the competitors, is not just premium products but also our amazing team!"", '', 'FULL TIME - Location:', 'Las Colinas, TX', 'OVERVIEW', 'Kelly-Moore Paint Company’s Information Technology department focuses on delivering effective solutions for employees, customers, and vendors. IT is comprised of talented individuals who cohesively drive effective solution strategies within a balanced ecosystem of systems and support. The Data & GRC Team is focused on fulfilling the business needs for data owners and consumers. Providing data governance guidance and meeting regulatory requirements.', '', 'PRIMARY RESPONSIBILITIES:', '', '', 'Provide day-to-day data processing development and support of existing data automation.', '', 'Manage and support the enterprise master data model, as well as inbound and outbound integrations.', '', 'Assist in the development of master data model architecture.', '', 'As needed develop, implement, and document new data integrations.', '', 'Develop data integrations using APIs and cloud native technologies.', '', 'Develop test plans and perform testing and certification of new and/or updated integrations.', '', 'Perform and document change management in line with ITIL and SDCL best practices.', '', 'Proactively fulfill project tasks with minimal supervision and raise any project gaps discovered.', '', 'Work closely IT and business team members to automate processes.', '', 'Act as subject matter expert on data integrations and data schema.', '', 'Support business intelligence projects, working collaboratively with Tableau team.', '', 'Perform all data handling in compliance with applicable regulatory requirements.', '', 'Maintain knowledge and users training documents relevant to data access, authorization, automation, and control.', '', 'Develop new projects as business need arise and document business requirements.', '', 'Perform other duties as assigned.', '', '', 'QUALIFICATIONS:', '', '', '3+ years of progressive experience data processing and/or data integration. Bachelor’s degree in information technology, data science, or equivalent experience.', '', 'Basic level knowledge of scripting languages.', '', 'Intermediate level knowledge of transact SQL or equivalent structured query language.', '', 'Knowledge of on-premises and cloud-based data processing and database systems.', '', 'Azure data lake/factory experience preferred.', '', 'Strong English writing and communication skills in a professional setting.', '', 'Ability to collaborate effectively with cross functional teams.', '', 'Self-motivated with the ability to work autonomously, effectively prioritize and manage multiple concurrent tasks and projects.', '', '', 'REQUIREMENTS:', '', '', 'Experience in database management and business process automation.', '', 'Database management or data science certifications or equivalent experience.', '', 'CompTIA Data+ or Microsoft Certified: Azure Data Engineer Associate a plus.', '', 'ITIL Foundation certification a plus.', '', 'Perform duties on site in Las Colinas 3 days per work week.', '', 'Kelly-Moore provides equal opportunity in all terms and conditions of employment. We will not discriminate against qualified applicants or employees with respect to any terms or conditions of employment because of any basis protected by federal, state, local law including race, color, religion, religious dress or grooming practice, national origin, sex, age, marital status, physical and mental disability, medical condition, veteran status, sexual orientation, gender identity, gender expression, and genetic information.']"
 7 ,Senior Data Engineer                                                                 ,Copart - 2.6                            ," Dallas, TX"      ,Full-time            ,Estimated: $110K - $140K a year   ,16 hours ago ,"Power BI
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              Pentaho
                                                                                                                                                                                                                              Customer service
                                                                                                                                                                                                                              5 years
                                                                                                                                                                                                                              Data analysis skills
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Kafka
                                                                                                                                                                                                                              Redshift
                                                                                                                                                                                                                              Informatica
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              OBIEE
                                                                                                                                                                                                                              MySQL"                       ,"[""The Senior Data Engineer will be part of the Data Services Team. The Data Services team works very closely with all aspects of applications and data pipelines. We are looking for a Senior Data Engineer to design, develop, and optimize the flow of data throughout the organization, enabling end user to provide valuable insights of data across Copart. In this role, your work will broadly influence the company's data consumers, executives and analysts."", '', 'Key Responsibilities:', '', '', 'Design and build the next generation data platform', '', 'Develop and automate data processing systems to deliver data insights at an enterprise scale.', '', 'Develop logging, metrics, and alerts that enable active monitoring of designed processes.', '', 'Collaborate with Product Managers and Application teams to develop data models and schemas that help provide easy access to complex data sets.', '', 'Assist in maintaining data integrity in production systems', '', 'Ability to balance and prioritize multiple conflicting requirements with high attention to detail.', '', '', 'Qualifications Requirements:', '', '', ""Bachelor's degree or higher in computer science, Engineering or similar"", '', '5+ years of experience designing, developing, testing and implementing scalable, high-performing data warehouse and BI solutions', '', 'Good hands-on Experience on real-time data pipelines including Kinesis and Kafka, understanding of Database architecture including MPP and ad-hoc analysis using BI/Analytical tools like Tableau, Pentaho, OBIEE or Power BI', '', 'Proven ability to analyze complex business problems using data and translate them into actionable insights stemming from data analysis', '', 'Experience with ETL and Data Blending and Transformation tools such as Pentaho Data Integrator, Talend Data Integration, Informatica', '', 'Enterprise development knowledge and/or experience with databases such as SQL Server, Oracle, MySQL and Columnar databases like Vertica, MemSQL , Netezza , Redshift', '', 'Good understanding of technology and industry and able to make decisions on the best technology for integrated solutions', '', 'Proven ability to communicate with business and technical audiences at all levels, including demonstrated success influencing senior leaders and decision makers', '', 'Technical Skill Required: SQL, Python. BI/Analytical Tool Preferred: Tableau, Pentaho, PowerBI', '', 'For 40 years, Copart has led its industry in innovation and customer service, enabling it to grow profitably in markets across the globe. Our success is the direct result of the skills and efforts of our talented and diverse employees. Our mindset? It\'s never just a ""job"" when your coworkers are like family - it\'s like coming home.']"
 8 ,Data Engineer                                                                        ,McLane Company - 3.1                    ," Temple, TX"      ,Full-time            ," $90,000 - $110,000 a year"      ,6 days ago   ,"Jira
                                                                                                                                                                                                                              CI/CD
                                                                                                                                                                                                                              Power BI
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Relational databases
                                                                                                                                                                                                                              5 years
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Alteryx
                                                                                                                                                                                                                              Data analysis skills
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              Bash
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              Linux
                                                                                                                                                                                                                              Redshift
                                                                                                                                                                                                                              AI
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Shell Scripting
                                                                                                                                                                                                                              Analytics"                   ,"['JOB SUMMARY / GENERAL DESCRIPTION:', '', 'Cleans, prepares, and optimizes data for further analysis and modelling. Designs, develops, optimizes, and maintains data architecture and pipelines that adhere to Data Pipeline (ie ELT) principles and business goals.', '', '', 'ESSENTIAL JOB FUNCTIONS / PRINCIPAL ACCOUNTABILITIES:', '', 'Designs, develops, optimizes, and maintains data architecture and pipelines that adhere to ELT principles and business goals.', 'Solves complex data problems to delivers insights that helps business achieve its goals.', 'Creates data products for engineer, analyst, and data scientist team members to accelerate their productivity.', 'Engineer effective features for modelling in close collaboration with data scientists and businesses', 'Leads the evaluation, implementation and deployment of emerging tools and process for analytics data engineering to improve productivity and quality.', 'Partners with machine learning engineers, BI, and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.', 'Fosters a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions.', 'Advises, consults, mentors, and coach other data and analytic professionals on data standards and practices.', 'Develops and delivers communication and education plans on analytic data engineering capabilities, standards, and processes.', 'Learns about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics as necessary to carry out role effectively.', '', 'MINIMUM SKILLS AND QUALIFICATION REQUIREMENTS:', '', ""Bachelor's degree in computer science, statistics, engineering, or a related field"", '5-10 years of experience required.', 'Experience with designing and maintaining data warehouses and/or data lakes with big data technologies such as Spark/Databricks, or distributed databases, like Redshift and Snowflake, and experience with housing, accessing, and transforming data in a variety of relational databases.', 'Experience in building data pipelines and deploying/maintaining them following modern DE best practices (e.g., DBT, Airflow, Spark, Python OSS Data Ecosystem)', 'Knowledge of Software Engineering fundamentals and software development tooling (e.g., Git, CI/CD, JIRA) and familiarity with the Linux operating system and the Bash/Z shell', 'Experience with cloud database technologies (e.g., Azure) and developing solutions on cloud computing services and infrastructure in the data and analytics space.', 'Basic familiarity with BI tools (e.g., Alteryx, Tableau, Power BI, Looker)', 'Expertise in ELT and data analysis, SQL primarily', 'Conceptual knowledge of data and analytics, such as dimensional modelling, reporting tools, data governance, and structured and unstructured data', '', 'WORKING CONDITIONS:', '', 'Office Environment', '', 'Pay and Benefits:', '', 'The pay range for this position is $90k to $110k annually based on qualifications and experience. This role is also eligible to participate in the annual incentive plan with a target incentive of 15% of your base annual salary. Full-time employees are offered benefits including health/RX, dental and vision insurance; flexible and health spending accounts (FSA/HSA); short and long-term disability coverage, supplemental life insurance; 401(k); paid time off and holiday pay for Company designated holidays']"
 9 ,Data Engineer                                                                        ,American National Bank of Texas - 3.4   ," Plano, TX"       ,Full-time            ,Estimated: $79.4K - $101K a year  ,2 days ago   ,"Bilingual
                                                                                                                                                                                                                              Microsoft Word
                                                                                                                                                                                                                              Spanish
                                                                                                                                                                                                                              Microsoft Excel
                                                                                                                                                                                                                              Microsoft Access
                                                                                                                                                                                                                              5 years
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              English
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              IT
                                                                                                                                                                                                                              Data collection
                                                                                                                                                                                                                              Middleware
                                                                                                                                                                                                                              Requirements gathering
                                                                                                                                                                                                                              Data warehouse"              ,"['The', 'Data Engineer', 'is responsible for the design, build, and optimization of systems for data collection, storage, access and analytics at scale. The position is responsible for creating pipelines, building algorithms for accessing raw data, and providing data that is accurate, congruent, reliable, and easily accessible. Additionally, the position is responsible for the full life cycle development, implementation, production support, and performance tuning of the Enterprise Data Warehouse, Data Marts, and Business Intelligence Reporting environments. The role supports the integration of those systems with enterprise application databases and real time processing', '', '', ""Designs, builds and optimizes systems for data collection, storage, access, and analytics AT SCALE (i.e., data that is collected, stored, secured, etc. across the entirety of the bank's technology systems)"", '', 'Builds out new API integrations to support continuing increase in data volume and complexity', '', 'Utilizes the latest technology and information management methodologies to meet requirements for effective logical data modeling, metadata management and warehouse domains', '', 'Assists with the development of architectural strategies for data modeling, design and implementation for metadata management, operational data shores and Extract Transform Load (ETL) environments', '', 'Creates and test data models for a variety of business data, applications, database structures to meet operational or project goals', '', 'Performs data analysis required to troubleshoot data related issues and assist to resolve issues', '', 'May require work on physical bank premises', '', '', 'Qualifications:', '', '', '5+ years IT experience preferably in the financial industry', '', '5 years experience developing dashboards and reports with a leading business intelligence and analytics platform like DOMO, Tableau or QLIK', '', '5 years experience with a low code solution, preferably Force.com platform', '', '5 years experience experience developing and/or supporting SQL databases preferably MS-SQL', '', '5 years experience working with integration platforms or middleware', '', '5 years user requirements gathering/user case development experience; experience converting legacy reporting platforms to dashboards; experience transforming from a manual process centric environment to a fully automated environment; experience with API integration development; experience developing and/or support data warehouse architecture, preferably Snowflake', '', '', 'Skills:', '', '', 'Advanced proficiency in the use of Microsoft Excel, Word, Access, SQL Database, modeling, data manipulation; basic keyboarding and calculator skills; must be able to perform advanced math and carry out complex written instructions', '', 'Travel to a variety of branch and vendor locations to perform work and/or attend meeting as required', '', 'Work occasionally requires more than 40 hours per week to perform the essential functions of the position', '', 'Lifting in an office setting may be required up to 30 lbs.', '', '', 'ANBTX strongly encourages candidates that are fluent in English and Spanish to apply. Jobs that specifically require candidates to be bilingual will be posted as a requirement.']"
10 ,Senior Data Engineer                                                                 ,Aroopa                                  ,Texas              ,Full-time | Contract ,Estimated: $118K - $149K a year   ,3 days ago   ,"CI/CD
                                                                                                                                                                                                                              Data modeling
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              6 years
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              Relational databases
                                                                                                                                                                                                                              Data structures
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Database design
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python"                      ,"['Role:', 'Senior Data Engineer', '', 'Location:', 'NY, NJ, PA, TX (Remote)', '', 'Duration:', '24 Months', '', 'Type:', 'Full-time/ Contract', '', 'We are seeking a highly skilled and experienced Data Engineer to join their team. As a dedicated advocate for diversity and inclusion, we encourage individuals from all backgrounds to apply.', '', 'Job Summary:', 'We are looking for a talented Data Engineer to build and optimize data infrastructure for efficient extraction, transformation, and loading of data from diverse sources. The ideal candidate will have a strong command of SQL and extensive experience with Azure technologies. You will collaborate with cross-functional teams to design, implement, and deploy data services and analytics solutions, contributing to challenging projects in data engineering, data management, and analytics.', '', 'Responsibilities:', '– Build and optimize data infrastructure for effective data extraction, transformation, and loading using SQL and Azure technologies.', '– Demonstrate expertise in advanced SQL, including query authoring and working knowledge of various relational databases.', '– Utilize experience in large data warehousing environments, specifically in platforms such as Azure SQL Data Warehouse, Azure Synapse Analytics, Oracle, and SQL Server.', '– Collaborate with data scientists, analysts, business users, and IT teams to design, implement, and deploy data services and analytics solutions.', '– Develop and maintain ETL pipelines to ensure smooth data processing and integration.', '– Apply strong database design principles and data modeling skills to create efficient and scalable data structures.', '– Integrate data from various sources and provide recommendations for optimal data models for ingestion, integration, and visualization.', '– Continuously improve code performance and optimize queries for enhanced efficiency.', '– Utilize Continuous Integration/Continuous Delivery (CI/CD) concepts to engineer a standardized data environment.', '– Demonstrate outstanding problem-solving skills and contribute innovative solutions to complex data challenges.', '– Communicate effectively with a diverse group, including executives, managers, and subject matter experts, through excellent verbal and written communication skills.', '', 'Qualifications:', '– Minimum of 6 years of experience as a Data Engineer.', '– Proficiency in SQL across multiple database platforms.', '– Experience with Snowflake, Databricks, Spark SQL, PySpark, and Python.', '– Cloud experience with Azure, AWS, or Google Cloud Platform.', '– Strong understanding of ETL pipeline development and maintenance.', '– In-depth knowledge of database design principles and data modeling.', '– Familiarity with integrating data from various source types.', '– Proven ability to optimize code performance and query efficiency.', '– Experience with Continuous Integration/Continuous Delivery (CI/CD) concepts.', '– Excellent problem-solving skills and ability to think creatively.', '– Strong communication skills, both verbal and written, with the ability to engage with diverse stakeholders.', '', 'Note: Don’t meet every single requirement? We encourage candidates who are excited about this role to apply, even if their experience doesn’t align perfectly with every qualification in the description. We value diversity and inclusivity and welcome candidates from all backgrounds.']"
 0 ,Field Engineer – Audio Visual and Data Networks                                      ,ELB US Inc.                             ," Dallas, TX"      ,Full-time            ," $70,000 - $95,000 a year"       ,2 days ago   ,"Microsoft Office
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              4 years
                                                                                                                                                                                                                              Communication skills"        ,"['ELB US Inc. is a world class integrated solutions provider, specializing in visual collaboration and unified communication services and solutions. We strive to create high quality integrated solutions for all our enterprise, government and education customers. At ELB we create experiences, we communicate ideas, and we collaborate across the world!', 'We are currently recruiting for a', 'Field Engineer – Audio Visual and Data Networks.', 'As a Field Engineer, you will configure, commission, and test hardware and software for full system operation of audio-video systems and networks. You will work with the Project Teams to provide full system functionality and ready projects for completion. In this role, you will get to work on high quality, high profile, national and international projects.', 'Key Responsibilities include, but are not limited to:', 'Provision of audio visual systems control programming services, including design and implementation', 'On site loading of programs, testing and commissioning. This includes any required rectification works – cabling, terminations etc', 'On site installation and integration of Audio Visual components including any rack building.', 'Offsite programming and support for remote locations when necessary', 'Consult with clients and colleagues as required regarding audio visual (AV) requirements.', 'Assess briefs provided by customers and/or Account Managers/Business Development Managers and identify options for potential solutions and assess them for both technical and business suitability.', 'Develop logical and innovative AV solutions to complex problems, ensuring that AV system designs meets customer business requirements.', 'Assist Project Managers where necessary with planning the installation of systems.', 'Assist with commissioning and troubleshooting of audio visual systems, including control systems and DSP platforms', 'Qualifications:', 'Possess a four-year degree, or equivalent combination of education and related work experience in the Professional Audio, Professional/Broadcast Video, Audio Visual, Security, or Data Integration fields.', 'A minimum of four years’ experience as a Field or Commissioning Engineer with an AV Integrator.', 'Extensive, hands-on experience with configuration of Audio DSP, Video Routing systems, Video Wall Processors, Display Calibration and Configuration, and Audio Room Tuning.', 'Industry and Manufacturer Certifications, such as Biamp Tesira, latest Crestron DM and NVX,QSC Q-SYS, etc. are required.', 'Knowledge of Crestron Tool Box and AMX Netlinx Studio. NOTE – Control Programming skills are a very strong plus, but are not explicitly mandatory.', 'Direct, hand-on experience with signal testers and analyzers, particularly Fluke DSX-5000 or similar.', 'Excellent verbal and written communication skills with an emphasis on the ability to organize and present designs to clients is a must. Must be proficient in Microsoft Office software.', 'Extensive knowledge of open architecture Audio Digital Signal Processor configuration and commissioning.', 'Job Type: Full-time', 'Pay: $70,000.00 - $95,000.00 per year', 'Benefits:', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Experience level:', '4 years', 'Schedule:', '8 hour shift', 'Monday to Friday', 'Ability to commute/relocate:', 'Dallas, TX 75238: Reliably commute or planning to relocate before starting work (Preferred)', 'Education:', ""Bachelor's (Preferred)"", 'Experience:', 'Field or Commissioning Engineer with an AV Integrator: 4 years (Preferred)', 'Willingness to travel:', '25% (Preferred)', 'Work Location: Hybrid remote in Dallas, TX 75238']"
 1 ,Middle Data Engineer with Matillion and Snowflake                                    ,DataArt                                 ," Dallas, TX"      ,                     ,Estimated: $121K - $154K a year   ,6 days ago   ,"Computer science
                                                                                                                                                                                                                              Cloud infrastructure
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              XML
                                                                                                                                                                                                                              Bachelor of Science
                                                                                                                                                                                                                              Calipers
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Terraform
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              S3
                                                                                                                                                                                                                              JSON
                                                                                                                                                                                                                              DynamoDB
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python"                      ,"['Client', 'Our client is a pioneer in US schools’ education since 2000, it is leading the way in next-generation curriculum and formative assessment. They develop a number of solutions and interactive web products for teachers, students, and their parents.', '', 'The company is technology-driven with a huge number of software engineers involved in product development. They have a very solid approach to technology, and employ best practices and processes, with a focus on cutting-edge frameworks, languages, and tools.', 'We invite to the company, not a project', 'Team', 'There are multiple autonomous and empowered teams who work with their own part of the product and choose their own way of doing things and they expect people to be proactive and good team players. This particular Data Engineering team consists of 5 engineers. The data team builds, augments, and maintains the infrastructure that empowers client teams and their customers to make sense of and tell stories with their data. We believe strongly in teaching our teammates to serve themselves, within a safe, reliable, and agile environment. You’ll be building data systems, but also the sharing-and-learning culture so that every team uses these tools to improve their own lives, and those of students and teachers.', 'Technology stack', 'Matillion, Snowflake', '', '', 'Responsibilities', 'Building well-tested and optimized ETL data pipelines for both full and delta extraction', 'Collaborating with data analysts and learning scientists to store, aggregate, and calculate captured students’ work', 'Contributing to leading industry data standards, such as Caliper Analytics or xAPI', 'Improving our deployment and testing automation data pipelines', 'Manage and maintain existing ELT Matillion pipelines', 'Requirements', '2+ years of professional software development or data engineering experience', 'Strong CS and data engineering fundamentals', 'Proven fluency in SQL and a development language such as Python', 'Experience with the following storages: Snowflake, AWS Storage Services (S3, RDS, Glacier, DynamoDB)', 'Experience with ETL/BI: Matillion, Airflow, DBT', 'Experience with Cloud Infrastructure: AWS Kinesis, Lambda, API Gateway, Terraform', 'Understanding of ETL/ELT pipelines and Data Warehousing design, tooling, and support', 'Understanding of different data formatting (JSON, CSV, XML) and data storage techniques (3NF, EAV Model, Star Schema, Data Lake)', 'Strong communication and interpersonal skills', 'Nice to have', 'BS in Computer Science, Data Science, or equivalent', 'Experience in education or ed-tech', 'Proven passion and talent for teaching fellow engineers and non-engineers', 'Proven passion for building and learning: open source contributions, pet projects, self-education, Stack Overflow', 'Knowledge of Airflow, DBT, AWS']"
 2 ,Data Engineer | Greater Austin Area                                                  ,Foundation Direct                       ,Texas              ,Full-time            ,Estimated: $96.7K - $122K a year  ,13 hours ago ,"Google Suite
                                                                                                                                                                                                                              Power BI
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Bachelor of Science
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              APIs
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              SSIS
                                                                                                                                                                                                                              Google Ads
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Analytics"                   ,"['Do you like using data and technology to tackle sophisticated client business problems? Are you seeking a blank canvas and an opportunity to advance your skills and your career in Cloud, data warehouse management and even Machine Learning? And maybe most importantly, do you want to work someplace where you get to do what you do best, improving your strengths and seeing the direct impact of your work? If so, this role is for you!', 'As a', 'Data Engineer,', 'you will acquire, cleanse, build, and maintain data pipelines and existing data systems in the Cloud. You will work closely with the SVP of Analytics and Business Intelligence and a team of analysts to navigate and join complex data sets to produce insights and reporting solutions for internal and external customers.', 'The ideal candidate has very strong knowledge in data engineering with a focus on SQL, BigQuery and dbt with the ability to optimize and support existing pipelines and processes and has a strong desire to build on their current expertise. Candidates will thrive in an environment with like-minded individuals that are analytical, results-oriented, self-driven, and confident.', 'At Foundation Direct you will be given creative freedom to be curious with data to develop unique solutions including exposure to maintaining a data warehouse in Cloud environments, working with various open source tools such as dbt and experimenting with Machine Learning. Your input will help to shape the direction of the company for years to come and provide significant growth potential for a lasting career.', 'This is a full-time, 100% remote, salaried position. Applicants must reside within the Continental U.S.', 'Primary Responsibilities:', 'Develop and test new pipelines and processes in data cloud environments like BigQuery', 'Migrate existing pipelines and processes to the cloud (Google Cloud Platform)', 'Design and develop dbt models and scripting to build the data pipeline processes to perform complex ETL processes', 'Analyze and organize raw data sets to meet both functional and non-functional requirements', 'Design and implement data models to support analytics and reporting initiatives', 'Assist the data analyst team to design and implement solutions that scale to meet business needs', 'Analyze and resolve technical and application problems', 'Ideal Candidate Experience includes:', 'Strong experience on Google Cloud Platform Cloud Data & Analytics service with a focus on SQL, BigQuery, Cloud Functions', 'Experience with data pipelines and ETL through tools such as dbt', 'Experience with connecting data to BI tools like Looker, Tableau or PowerBI', 'Plus if experienced in backend data tables and APIs such as Google Ads and Google Analytics', 'Requirements:', 'BA/BS in computer science, mathematics, statistics, business, or related field', '4+ years of Data Engineering experience', '3+ years of Python programming experience', 'Strong working knowledge of SQL to extract and manipulate data', 'Experience with SSIS, data integration and ETL procedures', 'Analytical mindset and attention to detail', 'Proficient in Google sheets and the Google suite of products', 'Excellent verbal and written communication skills', 'Compensation', 'Competitive compensation commensurate with experience. Company benefits offerings include medical, dental, vision, 401(k) matching, wellness, paid time off, paid maternity/paternity leave, and more. This is a full-time, remote, salaried position.', 'Next Steps!', 'If you are interested in this position and would like to be considered, please complete the ONLINE APPLICATION and be sure to include a current resume. Based on the number of applicants received, we will only reach out to those candidates whose qualifications most closely meet the needs of the position. If you are selected to move forward in the recruiting process, you will be contacted by a member of Foundation’s team within the next 7-10 business days.', 'Thank you and best of luck!', 'ABOUT FOUNDATION DIRECT', 'Created by the founders of Google’s Automotive Retail Team, Foundation Direct provides a robust technology platform that empowers Automotive Dealers to take control of their digital advertising and “go direct” to the largest media partners (Google, YouTube, Facebook, & BING). This automated digital solution drives true business outcomes and brings transparency into fees, reporting, and performance that are desperately needed within the industry.', 'While the company remains focused on prioritizing solutions that are best for the customer, Foundation Direct also promotes a culture that values diversity, equity, and inclusion. Employees are encouraged to share their opinions and have an opportunity to shape the strategy and products as the company evolves to meet the customer’s needs over time. The well-being and personal growth of Employees remains top of mind within the leadership team.']"
 3 ,"Engineer, Data - Clinical Analytics"                                                ,Concentra - 3.3                         ," Addison, TX"     ,Full-time            ,Estimated: $91.3K - $116K a year  ,4 days ago   ,"Performance tuning
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              Customer service
                                                                                                                                                                                                                              Relational databases
                                                                                                                                                                                                                              Visual Studio
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Docker
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              Computer Engineering
                                                                                                                                                                                                                              User acceptance testing
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Sybase
                                                                                                                                                                                                                              SSIS
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Python"                      ,"['Overview:', 'The Data Engineer- Clinical Analytics is primarily focused on analytical processes with ability to implement database solutions and best practices in the realm of data science and machine learning projects. Essential software engineering skills with strong foundational knowledge on data movement and orchestration both on-premises and cloud environment. The Data Engineer supports and aligns with business decisions within Concentra by analyzing raw data, constructing, and maintaining data systems, and improving data quality and efficiency. Implements programming languages to develop and test architectures that enables data operations for predictive (i.e., machine learning/AI) or prescriptive modeling.', 'Responsibilities:', 'Analyze, develop, combine raw information, and maintain various data sources', 'Improve data quality and efficiency to build data systems and pipelines', 'Identify opportunities for data acquisition and collaborate with Application owners and Subject Matter Experts (SME) to document data domain knowledge', 'Implement ETL methods to prepare both structured and unstructured data for predictive and prescriptive modeling', 'Leverage data serialization techniques to meet project needs for use in various reporting platforms', 'Collaborate with Business Intelligence (BI) ETL Developers/Data Architect, Data Scientists, Reporting Analysts, and Subject Matter Experts (SME) to understand business goals', 'Understand enterprise project life cycle and prepare for integration and user acceptance testing methods.', 'Produce technical documentation by following enterprise standards and guidelines', 'Participate in relevant information-sharing activities', 'Serve as escalation point for application support and troubleshooting', 'Proactive identification of issues and opportunities that will have an impact on the business use of reports and ensure managerial awareness', 'Daily review outstanding issues to assure that troubleshooting and resolutions are current', 'Ensure all changes comply with change management policies and procedures', 'This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.', 'Qualifications:', 'Education Level:', 'Bachelor’s Degree', 'Major:', 'Computer Science or Computer Engineering', 'Degree must be from an accredited college or university', 'Job-Related Experience', 'Customarily has at least the following experience:', 'Customarily has at least three or more years in Software development / Data-Centric pipelines / Model-Centric pipelines', 'Relational Database experience', 'Documentation and publication', 'Job-Related Skills/Competencies', 'Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility', 'Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions', 'Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism', 'The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies', 'Strong SQL development and performance tuning skills', 'Competencies with Oracle, SQLServer, SSIS, Sybase, NoSQL, Python, Azure, Docker, Git, and Visual Studio', 'Experience with Data Lakes, Lake Houses, and ELT is preferred', 'Experience with Azure ML, Azure Data Factory, Azure Data Bricks, Azure Data Flow, and Azure Functions is preferred', 'Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility', 'Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions', 'Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism', 'The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies', 'Highly organized', 'Communication skills to be able to effectively speak and write in a clear and professional manner', 'Skilled at listening and providing feedback', 'Additional Data:', 'Employee Benefits', '401(k) Retirement Plan with Employer Match', 'Medical, Vision, Prescription, Telehealth, & Dental Plans', 'Life & Disability Insurance', 'Paid Time Off', 'Colleague Referral Bonus Program', 'Tuition Reimbursement', 'Commuter Benefits', 'Dependent Care Spending Account', 'Employee Discounts', 'We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation, if required.', '*This job requires access to confidential and sensitive information, requiring ongoing discretion and secure information management*', 'Concentra is an Equal Opportunity Employer, including disability/veterans']"
 4 ,Data Engineer                                                                        ," AmeriVet Partners Management, Inc"    ," San Antonio, TX" ,                     ,Estimated: $94K - $119K a year    ,5 days ago   ,"Power BI
                                                                                                                                                                                                                              Immigration law
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              Big data
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Information Systems
                                                                                                                                                                                                                              Tableau
                                                                                                                                                                                                                              Master's degree
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Product development
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Root cause analysis
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Analytics"                   ,"['Description:', 'Reporting to the IT Director of Data and Analytics, the Data Engineer is responsible for managing and maintaining the full data lifecycle, from data ingestion to data processing, storage, and analysis. Responsible for expanding and optimizing AmeriVet’s data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data manager/ orchestrator who enjoys optimizing data systems and building them from the ground up. The Data Engineer will ensure optimal data delivery architecture is consistent throughout ongoing projects. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.', 'ESSENTIAL DUTIES AND RESPONSIBILITIES', 'Manage the full data lifecycle, from data ingestion to data processing, sustainable database storage methods, and analysis', 'Ensure data quality, accuracy, and consistency across all data sources and systems', 'Establish best practices and standards for data engineering, including data modeling, schema design, and query optimization', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability', 'Define and apply appropriate data acquisition and consumption strategies for given technical scenarios', 'Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem', 'Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns', 'Implement complex automated routines using workflow orchestration tools', 'Serve as the partner and technology leader for extracting data from the source systems, transform the data from source to the target formats, and load the data into the target systems', 'Lead continuous technology improvements and identify innovative ways of provisioning data and key business insights to achieve desired business outcomes', 'If applicable, visa sponsorship could possibly be provided for this job opportunity to qualified candidates, ensuring compliance with relevant immigration laws and regulations.', 'This position is located in San Antonio, TX and will require the candidate to sit at our corporate office.', 'Requirements:', ""Bachelor's or Master's degree in Computer Science, Information Systems, or a related field."", '8+ years of experience in data engineering, including ETL development, data modeling, and schema design', '4+ years of experience with Azure Data Lake, Azure Synapse Analytics, Apache Spark', '2+ years of experience in reporting tools such as PowerBI or Tableau', 'Proficient with programming using Python, and also writing SQLs', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Experience with ingesting, categorizing, and analyzing data originating from multiple sources with varying structures and degree of completeness to provide a succinct, compelling story for management', 'Ability to work in an agile, team-based environment and work collaboratively with operations teams and third-party vendors', 'Excellent problem-solving skills and the ability to work in a fast-paced and dynamic environment.', 'Solid understanding/experience with agile engineering and product development lifecycles and ability to manage agile engineering client engagements', 'Analytical approach to problem-solving; ability to use technology to solve business problems', 'Strong cross-functional team communication skills across the end-to-end client relationship', '', 'PHYSICAL DEMANDS AND WORK ENVIRONMENT', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the functions.', 'The physical activity of this position includes:', 'A. Climbing. Ascending or descending ladders, stairs, and the like, using feet and legs and/or hands and arms. Body agility is emphasized. This factor is important if the amount and kind of climbing required exceeds that required for ordinary locomotion.', 'B. Stooping. Bending body downward and forward by bending spine at the waist. This factor is important if it occurs to a considerable degree and requires full motion of the lower extremities and back muscles.', 'C. Kneeling. Bending legs at knee to come to a rest on knee or knees.', 'D. Crouching. Bending the body downward and forward by bending leg and spine.', 'E. Reaching. Extending hand(s) and arm(s) in any direction.', 'F. Standing. Particularly for sustained periods of time.', 'G. Walking. Moving about on foot to accomplish tasks, particularly for long distances or moving from one work site to another.', 'H. Pushing. Using upper extremities to press against something with steady force in order to thrust forward, downward or outward.', 'I. Pulling. Using upper extremities to exert force in order to draw, haul or tug objects in a sustained motion.', 'J. Lifting. Raising objects from a lower to a higher position or moving objects horizontally from position-to-position. This factor is important if it occurs to a considerable degree and requires substantial use of upper extremities and back muscles.', 'K. Fingering. Picking, pinching, typing or otherwise working, primarily with fingers rather than with the whole hand as in handling.', 'L. Grasping. Applying pressure to an object with the fingers and palm.', 'M. Feeling. Perceiving attributes of objects, such as size, shape, temperature or texture by touching with skin, particularly that of fingertips.', 'N. Talking. Expressing or exchanging ideas by means of the spoken word. Those activities in which they must convey detailed or important spoken instructions to other workers accurately, loudly, or quickly.', 'O. Hearing. Perceiving the nature of sounds at normal speaking levels with or without correction. Ability to receive detailed information through oral communication, and to make the discriminations in sound.', 'P. Repetitive motion. Substantial movements (motions) of the wrists, hands, and/or fingers.', 'The physical requirements of this position are:', 'Light work. Exerting up to 20 pounds of force occasionally, and/or up to 10 pounds of force frequently, and/or a negligible amount of force constantly to move objects. If the use of arm and/or leg controls requires exertion of forces greater than that for sedentary work and the worker sits most of the time, the job is rated for light work.', 'The visual acuity requirements including color, depth perception and field vision are:', 'The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading; visual inspection involving small defects, small parts, and/or operation of machines (including inspection); using measurement devices; and/or assembly or fabrication parts at distances close to the eyes.', 'The conditions the worker will be subject to in this position are:', 'The worker is subject to environmental conditions. Protection from weather conditions but not necessarily from temperature changes.', 'Note', 'This job description in no way states or implies that these are the only duties to be performed by the employee(s) incumbent in this position. Employees will be required to follow any other job-related instructions and to perform any other job-related duties requested by any person authorized to give instructions or assignments. All duties and responsibilities are essential functions and requirements and are subject to possible modification to reasonably accommodate individuals with disabilities. To perform this job successfully, the incumbents will possess the skills, aptitudes, and abilities to perform each duty proficiently. Some requirements may exclude individuals who pose a direct threat or significant risk to the health or safety of themselves or others. The requirements listed in this document are the minimum levels of knowledge, skills, or abilities. This document does not create an employment contract, implied or otherwise, other than an “at will” relationship.', 'EEO Information', 'The company is an Equal Opportunity Employer, drug free workplace, and complies with ADA regulations as applicable.', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and veteran status.']"
 5 ,Product Data Engineer Technician II                                                  ,Mouser Electronics - 3.1                ," Mansfield, TX"   ,                     ,Estimated: $58.6K - $74.2K a year ,2 days ago   ,"Microsoft Powerpoint
                                                                                                                                                                                                                              Microsoft Word
                                                                                                                                                                                                                              Microsoft Excel
                                                                                                                                                                                                                              System design
                                                                                                                                                                                                                              Windows
                                                                                                                                                                                                                              Electrical engineering
                                                                                                                                                                                                                              Taxonomy
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Product management
                                                                                                                                                                                                                              Organizational skills
                                                                                                                                                                                                                              Electrical Engineering
                                                                                                                                                                                                                              2 years"                     ,"['The mission of the Product Data Group is to provide the most accurate and complete data for design engineers sourcing electronic components on Mouser.com The group maintains the Product Information Management (PIM) system and Data Quality tools to accomplish that responsibility.', '', 'The Product Data Engineering Technician performs technical data research, assessment, acquisition, and quality assurance of data for electronic components using a variety of resources and tools. They work with and establish solid relationships with the Products team, Pricing team and other departments within Mouser to ensure the highest standard in the structure and maintenance of technical data.', '', 'ACCOUNTABILITIES & ESSENTIAL FUNCTIONS', '', 'Performs technical data research, assessment and acquisition using the Internet, Supplier websites, search engines, spreadsheets, and internal databases', 'Normalizes all collected data into a consistent format that is governed by Tech Data established procedures', 'Collaborates, coordinates, and manages the classification, collection, implementation, and maintenance of the product technical data using Product Information Management (PIM) system and Data Quality Analyst tools', 'Plans, develops, and manages the hierarchies for assigned product categories based on product type and/or technology through technical processes', 'Ensures that collected data is relevant for uses that are sourcing products, in all regions worldwide', 'Develop a basic Mouser Product Data acumen and use it with each classification and attribution task assigned', 'Develops an understanding of the classification Hierarchy to the extent that misclassified products can be readily identified and reclassified into the correct template', 'Evaluate template attributes for relevance with the template Taxonomy and make recommendations for changes that would benefit customers', 'Evaluate the data as presented on Mouser.com and make recommendations regarding normalization, sorting, and order of parametric attributes to enhance the overall product sourcing for customers', 'Establish open and timely communications with interested parties, stakeholders, and teams', 'Expected to utilize organizational skills to document, categorize, prioritize, provide easy access to information, ask questions, follow up and maintain communications', 'Represents the company in a professional manner with internal and external customers', '', 'SKILLS & CERTIFICATIONS', '', 'Ability to manage multiple projects and priorities', 'Familiarity in working in and with cross-functional teams', 'Strong organizational skills', 'Strong ability to work independently or in teams with a collaborative interpersonal style', 'Demonstrates a positive attitude toward self and others', 'Ability to set and track goals', 'Uses sound judgement to identify issues and escalates when appropriate', 'Able to research data for long periods of time', 'Able to quickly learn new software applications and adapt to project related process changes', 'Detailed and thorough in work habits with multi-tasking ability', 'Demonstrated ability in reading, analyzing, and interpreting Technical Data Sheets, Product Guides, Scientific and Technical Journals and other related engineering documents', 'Professional with the ability to interface directly with internal business contacts and represent the business unit', 'PC experience in Microsoft Windows environment, proficient with internet email, Microsoft Word, Excel, Power Point, Outlook, and related platforms', 'Electronic Design, Systems Design, Test Engineering or Electronic Component experience required', 'Exhibits strong analytical, technical, problem solving and organizational skills', 'Able to work with minimum supervision and independent judgements', '', 'Product Data Engineer Technician II', '', 'Maintain and continuously build on an established strong Mouser Product Data classification and attribution assignments', 'Contribute to functional design of process solutions', 'Proficient to quickly learn and adapt to project related process changes', 'Proficient in work habits with multi-tasking ability', 'Proficient in classifying and attributing products using the Product Information Management (PIM) system and related tools', 'Proficient in in using Excel', 'Knowledge and understanding of Mouser Taxonomy and hierarchies', 'Proficient in reading and using Technical Data Sheets and related scientific document', '', 'Requirements', '', 'Bachelor’s Degree in Electrical Engineering or relevant discipline. In lieu of a degree 5+ years of relevant work experience in Electrical Engineering or technical field is acceptable', '2+ years Electronic Component experience required. For internal candidates, experience can be a combination of internal and external experience.', '', 'Equal Opportunity Employer, including disability and veterans.', '', 'Category:Internet Business', '', 'This is a summary of the primary accountabilities and requirements for this position. The company reserves the right to modify or amend accountabilities and requirements at anytime at its sole discretion based on business needs. Any part of this job description is subject to possible modification to reasonably accommodate individuals with disabilities.', '', '#LI-SR1', '', 'Mouser Electronics endeavors to make its Career page accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact Human Resources at (817) 804-3850 or hr@mouser.com. This contact information is for accommodation requests only and cannot be used to apply for positions or to inquire about the status of applications.', '', 'Mouser is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.']"
 6 ,"AI Data Scientist/Machine Learning Engineer, WW CSO"                                ,Apple - 4.1                             ," Austin, TX"      ,                     ,                                  ,5 days ago   ,"Doctoral degree
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Relational databases
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Mathematics
                                                                                                                                                                                                                              E-commerce
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              Java
                                                                                                                                                                                                                              Master's degree
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Math
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              Doctor of Philosophy
                                                                                                                                                                                                                              Distributed systems
                                                                                                                                                                                                                              Scala
                                                                                                                                                                                                                              Master of Science
                                                                                                                                                                                                                              AI
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Marketing
                                                                                                                                                                                                                              Debugging
                                                                                                                                                                                                                              Hadoop
                                                                                                                                                                                                                              Performance marketing"       ,"['Summary', '', 'Posted: May 31, 2023', '', 'Role Number:', '200480440', '', ""Imagine what you could do here! The people here at Apple don’t just create products — they create the kind of wonder that’s revolutionized entire industries! It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. Apple's WW Channel Strategy & Operations (CSO) organization focuses on developing and deploying worldwide sales programs and best practices to deliver an extraordinary customer experience in the channel and drive Apple Channel sales. With deep functional expertise in digital, physical, and people enablement spaces, our WW CSO team closely collaborates with many cross-functional groups at world-wide and regional levels. We are seeking a versatile Data Scientist/Machine Learning Engineer passionate to join a new team to build pioneering solutions within the CSO group. The ideal candidate excels in building solutions from scratch using the best techniques and tools available in the market and enjoys leading high-visibility projects with a large impact on daily operations."", '', 'Key Qualifications', '', '5+ years experience in building highly scalable, compliant, and secure, enterprise-grade data and analytics platforms with robust data quality, data governance, data discovery, catalog and visualization capabilities', '', '4+ years of experience with large-scale e-commerce data and analytics platform, including building data pipelines for Digital performance KPIs, Performance Marketing, and Testing & Optimization', '', 'Strong background in mathematical modeling, linear and non-linear regression, and consumer decision making theory', '', 'Ability to convey rigorous mathematical concepts and considerations to non-experts.', '', 'Practical experience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection', '', 'Working knowledge of relational databases, including SQL, and large-scale distributed systems such as Hadoop and Spark', '', 'Ability to implement data science pipelines and applications in a general programming language such as Python, Scala, or Java', '', 'Ability to comprehend and debug complex systems integrations spanning toolchains and teams (preferred not required)', '', 'Ability to extract meaningful business insights from data and identify the stories behind the patterns', '', 'Creativity to engineer novel features and signals, and to push beyond current tools and approaches', '', 'Ability to share results with a non-technical audience and advancing multiple projects at once on a tight schedule', '', 'Excellent presentation, written and verbal communication, engagement and interpersonal skills along with validated skills in building great design', '', 'Description', '', 'In this role, you will focus on the following key areas: Requirements: Understand business requirements and translate into technical solutions Data Science: Design data science/machine learning approach, applying tried-and-true techniques or developing custom algorithms as needed by the business problem Teamwork: Collaborate with data engineers and platform architects to implement robust production real-time and batch decisioning solutions Maintenance: Ensure operational and business metric health by monitoring production decision points Analysis: Investigate adversarial trends, identify behavior patterns, and respond with agile logic changes Communication: Communicate results of analyses to business partners and executives Innovation: Research new technologies and methods across data science, data engineering, and data visualization to improve the technical capabilities of the team', '', 'Education & Experience', '', '- Ph.D. in Computer Science, Machine Learning, Statistics, Operations Research or related field; or - Ph.D. in Math, Engineering, Economics, or hard science with data science fellowship; or - M.S. in related field with 3+ years experience applying machine learning engineer to real business problems', '', 'Additional Requirements']"
 7 ,Cloud Data Engineer - Healthcare                                                     ,Deloitte - 3.9                          ," Irving, TX"      ,Full-time            ,Estimated: $117K - $148K a year   ,4 days ago   ,"CI/CD
                                                                                                                                                                                                                              Data modeling
                                                                                                                                                                                                                              5 years
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Terraform
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              S3
                                                                                                                                                                                                                              Redshift
                                                                                                                                                                                                                              AI
                                                                                                                                                                                                                              Jenkins
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Analytics
                                                                                                                                                                                                                              Hadoop"                      ,"['Are you an experienced, passionate pioneer in technology who wants to work in a collaborative environment? As an experienced Cloud Data Engineer - Healthcare you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery. This position is working on a multi-year project for a major healthcare client. This is a remote role in the United States.', '', '', ""Work you'll do/Responsibilities"", '', 'You will determine processes and automation tools to reduce IT spend and increase efficiencies on multiple projects within the Healthcare domain.', '', 'This position includes collaborating with DevOps teams to implement CI/CD pipelines, automated deployments, and infrastructure as code (IaC) practices for AWS-based solutions. Document design, development, and deployment processes, as well as create technical specifications and user guides for developed solutions.', '', 'Your role will be to design, develop, and deploy cloud-based solutions for data processing, analytics, and integration using cloud services and big data technologies. Collaborate with architects, data engineers, and business stakeholders to understand requirements and translate them into technical solutions.', '', ""You will implement data ingestion, transformation, and storage processes using cloud services like AWS's S3, Glue, Athena, Redshift, and EMR. Implement security, data governance, and compliance measures to ensure data integrity and protection in AWS-based solutions. Develop and optimize data pipelines using Snowpark, SnowSQL, Hadoop and PySpark to extract, transform, and load data efficiently."", '', 'You will conduct performance tuning and optimization of data processing and analytics workflows to maximize efficiency and scalability. Work with cross-functional teams to troubleshoot and resolve issues related to data processing, data integration, and analytics solutions.', '', 'Communicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management', '', '', 'The Team', '', 'As a part of the US Strategy & Analytics Offering Portfolio, the AI & Data Operations offering provides managed AI, Intelligent Automation, and Data DevOps services across the advise-implement-operate spectrum.', '', '', 'Qualifications', '', '', 'Required', '', '', ""5+ years' experience as a Cloud Data Engineer"", ""5+ years' hands on experience in Snowpark, SnowSQL, Hadoop and PySpark"", ""5+ years' experience in AWS services such as S3, Glue, Athena, Redshift, EMR, Lambda and Cloud Formation."", ""5+ years' experience in Python with a focus on data processing and analytics"", '5+ years in healthcare domain', '5+ years in consulting', 'Strong knowledge and hands-on experience in designing, developing, and deploying scalable solutions on the cloud platforms', 'Expertise in SQL and database technologies for data manipulation and querying', ""Bachelor's degree or equivalent experience"", 'Limited immigration sponsorship may be available', '', 'Preferred', '', '', 'Familiarity with data modeling, data warehousing, and data integration concepts.', '', 'Experience with DevOps practices, CI/CD pipelines, and infrastructure as code (IAAC) using tools like Jenkins, Git, and Terraform.', '', 'Strong analytical and problem-solving skills, with the ability to troubleshoot and resolve complex technical issues.', '', 'Familiarity with agile development methodologies and experience working in Agile teams', '', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', '', ""Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience"", '', 'Analytical/ decision making responsibilities', '', 'Analytical ability to manage multiple projects and prioritize tasks into manageable work products', '', 'Can operate independently or with minimum supervision', '', 'Excellent communication skills', '', 'Ability to deliver technical demonstrations']"
 8 ,Software Engineer - Mission Data Tools - Level 3                                     ,Lockheed Martin - 4.0                   ," Fort Worth, TX"  ,Full-time            ,                                  ,3 days ago   ,"Software Engineering
                                                                                                                                                                                                                              C#
                                                                                                                                                                                                                              Windows
                                                                                                                                                                                                                              C++
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Computer Engineering
                                                                                                                                                                                                                              Software development"        ,"['Job ID:', '632891BR', '', 'Date posted:', 'Jun. 15, 2023', '', '', 'Description:', 'Lockheed Martin is seeking expert Software Engineer to maintain the mission data software applications: Mission Data Programming Application (MDPA) and Mission Data File Release (MDFR)', '', 'The MDPA and MDFR are used by our F-35 customer Reprogramming Labs to generate and encrypt Mission Data File (MDF) sets, which are pivotal to the execution of successful missions and overall operation of the F-35. These tools have been in use for several years and are in need of dedicated engineers to support updates for upcoming deliveries and to help transition them into modern software environments. As we transition these tools into the next generation software space, there are ample opportunities for growth and technical ownership of capabilities that are critical to the success of missions for the F-35 fighter.', '', '', 'YOUR IMPACT', 'The ideal candidate will have expertise in object-oriented software development and a broad range of software technical skills. They will work closely with our MDPA and MDFR SMEs to transition the ownership of the software development to meet the requirements for upcoming deliveries.', '', '', ""What's In It For You"", 'Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually. Here are some of the benefits you can enjoy:', '', 'Medical', 'Dental', '401k', 'Paid time off', 'Work/life balance', 'Career development', 'Mentorship opportunities', 'Rewards & recognition', ""Learn more about Lockheed Martin's comprehensive benefits package here."", '', 'aerosoftware', 'aerosw', '', 'Basic Qualifications:', ""Bachelor's degree in Software Engineering, or equivalent"", '', 'Experience developing object-oriented Windows based software applications in C++ or C#', '', 'Desired Skills:', 'Experience with Avionics', '', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about."", '', ""As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'AERONAUTICS COMPANY', '', 'Relocation Available:', 'Yes', '', 'Career Area:', 'Software Engineering', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
 9 ,Data Visualization and Analytics Senior Project Engineer                             ,Great Lakes Dredge & Dock - 3.7         ," Houston, TX"     ,Full-time            ,Estimated: $106K - $134K a year   ,6 days ago   ,"Power BI
                                                                                                                                                                                                                              Project engineering
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              Databases
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              Data analytics
                                                                                                                                                                                                                              Data visualization
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Analytics"                   ,"['We are seeking a skilled and experienced Data Visualization and Analytics Senior Project Engineer to join our team. In this role, you will work closely with our data scientists and business stakeholders to develop, implement, and maintain our visualization and real-time analytics systems. The ideal candidate has a strong understanding of visualization and data analytics principles in operational assets, has a knack for real life problem-solving, and is adept at turning data into actionable insights from maritime production assets. This is a high impact role with the opportunity to shape the way our company uses data to drive business decisions.', 'About the Company:', 'Great Lakes Dredge & Dock Company, LLC is the largest provider of dredging, land reclamation and beach nourishment services in the United States, and the only U.S. dredging company with international operations. With the largest and most diverse dredging fleet in the US, Great Lakes serves a wide range of customers including the US Army Corps of Engineers; state, local and foreign governments; and private companies both international and domestic. Headquartered in Houston, TX. Our diverse fleet of equipment includes hopper, mechanical and hydraulic dredges, and approximately 200 support vessels.', 'Responsibilities:', 'Design, implement, and maintain high-performance, scalable real-time analytics systems and data pipelines', 'Work closely with data scientists to understand their data requirements and ensure that the analytics and communication infrastructure can support these needs effectively and efficiently', 'Transform raw data into meaningful insights by developing algorithms and statistical models for visualization', 'Supervise engineers and create engineering reports documenting design details or qualification test results', 'Research, select, or apply sensors, communication techniques, or sensory control devices, video feed, position sensing, pressure sensing, or electronic communication', 'Implement monitoring and alerting tools to ensure the integrity and availability of our real-time analytics systems', 'Work closely with stakeholders across the organization to understand their data requirements and develop solutions to meet their needs', 'Keep up to date with the latest trends and technologies in real-time analytics and propose ways to leverage these advancements to improve our systems', 'Requirements:', 'Bachelor’s degree in Automation, Computer Science, Engineering, or a related field', 'Proficiency with cloud-based analytics, data pipeline and workflow management tools', 'Expert in real time visualization, SCADA systems, MMI presentation concepts', 'Experience with data visualization tools and BI software (e.g., Power BI or similar)', 'Strong knowledge of Python, SQL and experience with NoSQL databases', 'Familiarity with machine learning algorithms, mathematical and statistical models in use for cloud and edge computing', 'Strong problem-solving skills and attention to detail', 'Excellent communication skills and the ability to explain complex topics to non-technical stakeholders', 'Proven experience in a similar role', 'Benefits:', 'Competitive salary and bonus program', '401(k) program that includes 100% company matching of the first 6% of employee contributions with immediate vesting', 'Annual profit-sharing contributions by the company to participants’ 401(k) accounts based on company’s annual performance', 'Medical, Dental, Prescription, Life and Disability insurance plans', 'Great Lakes Dredge & Dock Company is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment regardless of race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information, or other status protected by law or regulation.', 'GLDD participates in E-Verify as required by law.']"
10 ,Implementation Specialist - Production Data Lifecycle Solutions | Petroleum Engineer ,Peloton - 3.3                           ," Katy, TX"        ,Full-time            ,Estimated: $77.1K - $97.6K a year ,6 days ago   ,"Schematics
                                                                                                                                                                                                                              Bachelor of Science
                                                                                                                                                                                                                              Engineering
                                                                                                                                                                                                                              Oil & gas
                                                                                                                                                                                                                              Filing
                                                                                                                                                                                                                              Windows
                                                                                                                                                                                                                              Microsoft Office
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Communication skills"        ,"['Implementation Specialist, Production Data Lifecycle Solutions', '', 'Peloton Computer Enterprises Inc. (https://www.peloton.com/)', ""Peloton is looking to grow our Production Data Lifecycle Solutions team with the addition of Implementation Specialists within our Houston, TX office. The ideal candidates are Petroleum Engineers with at least 2-3 years' relevant experience and a passion for data."", 'Reports To:', 'US Services Manager, Production Data Lifecycle Solutions', 'Supervisory responsibilities:', '', '', 'None', '', '', 'Principal Duties and Responsibilities:', '', '', 'Liaise with clients to determine current and future Peloton application requirements and implement the Production Data Lifecycle solution with these requirements in mind.', '', 'Develop project plans and coordinate technical implementations and rollout of Peloton applications at client sites.', '', 'Work with clients to deliver Peloton specific, customized application training (including train the trainer programs) to be delivered throughout the organization.', '', 'Serve as technical resource of escalated technical issues for clients (liaise with Development team if necessary).', '', '', 'Deliver technical excellence presentations at staff meetings / gatherings to transfer knowledge throughout the organization.', '', '', 'Qualifications:', '', '', 'Bachelor of Science in Engineering', '', 'Entry to mid-level experience in oil and gas operations with a focus on production accounting systems is a plus', '', 'Good understanding of network flow schematics and production allocation', '', 'Working knowledge around regulatory filing requirements for production volumes is a plus', '', 'Ability to communicate effectively with client and Peloton development team', '', 'Ability to manage balance between client business needs and Peloton development capabilities', '', 'Excellent oral and written communication skills', '', 'Strong problem-solving skills', '', 'Proficient in Windows, Microsoft Office and general IT / software installation processes', '', 'Understanding of database / reporting technology', '', ""Prior knowledge of Peloton applications or competitive products like P2's ProCount, Schlumberger’s Avocet Capture or Landmark’s TOW is a strong plus"", '', 'Occasional travel will be required to client locations (up to 30% of the time)', '', '', 'As part of our team you’ll enjoy:', '', '', 'Exceptional benefits package', '', 'Vacation & Paid Time Off', '', 'Retirement benefit with employer contribution', '', '', 'About Peloton', '', 'The Peloton Platform energizes the oil and gas digital transformation through mobility, automation and data integration by providing fully integrated well data lifecycle, production data lifecycle and land data management solutions. Today, over 600 oil and gas clients worldwide rely on Peloton technology to equip their stakeholders with the tools and information necessary to manage, simplify and optimize their operations. For more information, visit www.peloton.com.', 'By submitting your job application, your confirm that you agree to the storing and processing of your personal data by Peloton as described in our Privacy Policy.']"
 0 ,DevOps & Data Integration Support Engineer                                           ,Jacobs - 3.9                            ," Houston, TX"     ,Full-time            ,Estimated: $95.2K - $121K a year  ,5 days ago   ,"CI/CD
                                                                                                                                                                                                                              Cloud infrastructure
                                                                                                                                                                                                                              Operating systems
                                                                                                                                                                                                                              Management
                                                                                                                                                                                                                              HDFS
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              NFS
                                                                                                                                                                                                                              Kubernetes
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              OOP
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              C++
                                                                                                                                                                                                                              C
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              JavaScript
                                                                                                                                                                                                                              Terraform
                                                                                                                                                                                                                              Continuous integration
                                                                                                                                                                                                                              Ruby
                                                                                                                                                                                                                              S3
                                                                                                                                                                                                                              Linux
                                                                                                                                                                                                                              Mesos
                                                                                                                                                                                                                              MySQL"                       ,"['Challenging Today. Reinventing Tomorrow.', '', ""We're invested in you and your success. Everything we do is more than just a project. It's our challenge as human beings, too. That's why we bring a thoughtful and collaborative approach to every one of our partnerships."", '', ""At Jacobs, we challenge the status quo and redefine how to solve the world's greatest challenges, transforming big ideas into intelligent solutions for a more connected, sustainable world."", '', 'Design your career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed – today and into tomorrow', '', '', 'Your Impact:', 'Are you passionate about human space exploration, understanding the origins of the universe, and working with a passionate and diverse team to make a difference? If you are, we need you!', '', 'We need your talent, teamwork, and energy to help us achieve great things that inspire people all over the globe. We need you to bring creative ideas and diverse backgrounds to help us envision, shape, and deliver systems that will enable the exploration of space while benefiting people here on Earth. We are excited about what we do, and we need you on our team as we take on exciting challenges for NASA’s pursuits in deep space exploration. Jacobs is NASA’s largest engineering solutions provider working together with NASA at centers across the United States.', '', 'We have an exciting opportunity for a', 'DevOps & Data Integration Support Engineer', 'to join the team with our IT Division.', '', 'Focus:', '', 'DevOps & Data Integration Support Engineer', '', 'Cloud Infrastructure Automation 50%', '', 'Data Pipeline Management 25%', '', 'Quality Assurance/ Continuous Monitoring 25%', '', 'Responsibilities:', '', 'Establishing initial data pipelines for engineering and partner datasets, moving data from existing Corporate and Customer data resources into hosted Cloud resources', '', 'Establishing data pipelines for future use cases', '', 'Supporting the in-cloud data engineering efforts around providing the data functionality and experiences from hosted Cloud resources', '', 'Establishing the core data services (cataloging, pipelines, interfaces)', '', 'Establishing core identity platform configurations and initial implementation', '', 'Combination of release engineering, infrastructure provisioning and management, system administration, security, and DevOps advocacy', '', 'Works on the automation quality assurance efforts for software development projects, including a review of technical specifications and user stories', '', 'S/he executes and maintains automated test scripts, provides documentation for testing methodologies and tools, reports automation results and ensures a focused, methodical approach to automation testing', '', 'Building software and systems while managing the platform infrastructure and applications', '', 'Perform other duties as required', '', 'Here’s What You’ll Need:', 'Requisition Qualifications:', '', ""This position has been posted at multiple levels. Depending on the candidate's experience, requirements, and business needs, we reserve the right to consider candidates at any level for which this position has been advertised."", '', ""Typically requires a bachelor's degree in a related area or experience in the field."", '', 'Proficient in Automation tools native to Google Cloud, AWS Platform including 3rd party tools such as Terraform', '', 'Understanding a variety of operating systems — most commonly, but not limited to, Linux — as you will be using them regularly', '', 'Managing the continuous integration/continuous development pipeline (CI/CD). You’ll probably be tasked with building this pipeline from scratch', '', 'Extensive experience with cloud-based distributed technologies such as Ceph, HDFS, NFS, and S3, as well as dynamic resource management frameworks (like Kubernetes, Mesos, or Yarn)', '', 'Deep knowledge of version control (such as Git) and monitoring tools like Grafana, as well as a variety of databases (such as NoSQL and MySQL)', '', 'Manage and partner with development teams through taxing testing and release cycles', '', 'Knowing how to code, typically in a variety of languages, both in a structured and OOP way. The m Ruby, C/C++, and JavaScript', '', 'Requisition Preferences:', '', ""Having a Bachelor's degree in computer science or some equivalent, highly technical discipline. Previous success in technical engineering is going to be preferable"", '', 'Why Join Our Team?', '', 'Click on the below links to view just a small sample of all that we do! Come join our team and be part of our future. We look forward to seeing you!', '', 'See What We Do', '', 'Jacobs Aerospace Solutions Overview', '(Please view in Chrome or Microsoft Edge)', '', 'In addition to exciting career opportunities, we also have:', 'Excellent personal and professional career growth', '9/80 work schedule (every other Friday off)', 'Onsite cafeteria (breakfast & lunch)', 'Much, much more!', 'For more information on our partnership with NASA at Johnson Space Center (JSC), please visit www.wehavespaceforyou.com', '', 'Proof of U.S. Citizenship or US Permanent Residency may be a requirement for this position', '', 'Must be able to complete a U.S. government background investigation', '', 'Management has the prerogative to select at any level for which the position is advertised', '', 'Essential Functions', '', 'Work Environment', '', 'Generally, an office environment, but can involve inside or outside work depending on task.', 'Physical Requirements', '', 'Work may involve sitting or standing for extended periods (90% of time). May require lifting and carrying up to 25 lbs. (5% of time).', 'Equipment and Machines', '', 'Standard office equipment (PC, telephone, printer, etc.).', 'Attendance', '', 'Regular attendance in accordance with established work schedule is critical. Ability to work outside normal schedule and adjust schedule to meet peak periods and surge requirements.', '', 'Other Essential Functions', '', 'Professional behavior that enhances productivity and promotes teamwork and cooperation. Grooming and dress must be appropriate for the position and must not impose a safety risk/hazard to the employee or others.', 'Jacobs is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, religion, creed, color, national origin, ancestry, sex (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, medical condition, marital or domestic partner status, sexual orientation, gender, gender identity, gender expression and transgender status, mental disability or physical disability, genetic information, military or veteran status, citizenship, low-income status or any other status or characteristic protected by applicable law. Learn more about your rights under Federal EEO laws and supplemental language.']"
 1 ,Security Data Engineer                                                               ,Koch Global Services - 1.0              ," Dallas, TX"      ,                     ,Estimated: $108K - $136K a year   ,6 days ago   ,"Operating systems
                                                                                                                                                                                                                              Windows
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              JavaScript
                                                                                                                                                                                                                              Scripting
                                                                                                                                                                                                                              SIEM
                                                                                                                                                                                                                              Linux
                                                                                                                                                                                                                              Data collection
                                                                                                                                                                                                                              Cybersecurity
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              PowerShell"                  ,"['Your Job', 'The Koch Cyber Security Team is seeking a Security Data Engineer to join our global cyber security team. As a member of this team your primary duties will be to attend to the health and support of our SIEM tool and work closely with our analyst to ensure that data is available to them when needed.', 'Our Team', ""The Koch Cyber Security team is a dynamic and proactive force, fueled by an unwavering commitment to Koch's vision for value creation. With a relentless drive, we tackle cyber threats head-on, always ready to protect our stakeholders from any potential harm. Our team members are trailblazers, spearheading transformational efforts in areas such as Incident Response, Automation, exposure management, awareness, and the ever-evolving cyber landscape. We thrive on challenges and constantly seek innovative solutions to safeguard our organization and its interests."", 'What You Will Do', 'Oversee the ingestion and normalization of new data sources.', 'Maintain data availability', 'Detect and remediate any drop in data ingestion', 'Support, maintain and improve infrastructure for the data collection tools overall health', 'Respond to customer inquiries surrounding the collection of data', ""Work closely with Cyber Security team to ensure that analyst have access to the data they need and that it's presented in a clear and concise manner"", 'Stay up to date with the latest trends and technologies in data engineering and cloud infrastructure management and applying them to our data collection tool stack', 'Actively seek ways to improve our current data collection tool stack.', '', '', 'Who You Are (Basic Qualifications)', '', 'Experience supporting a SIEM tool', 'Experience deploying Infrastructure in cloud environments', 'Experience building and troubleshooting data pipelines.', '', '', 'What Will Put You Ahead', '', 'Experience with Global Information\\Cyber Security Teams', 'Experience with Machine Learning', 'Experience with Multiple Operating Systems', 'Knowledge with PowerShell, JavaScript, or Python Scripting', 'Windows Or Linux Administration Experience', 'SOAR Platform Experience', 'Familiar with CIM date compliance', '', ""At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy."", 'Hiring Philosophy', 'All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .', 'Who We Are', 'As a Koch company, Koch Global Services (KGS) creates solutions spanning technology, human resources, finance, project management and anything else our businesses need. With locations in India, Mexico, Poland and the United States, our employees have the opportunity to make a global impact.', 'At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.', 'Our Benefits', 'Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.', 'Equal Opportunities', 'Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf', '#LI-CB1']"
 2 ,Sr Data Engineer                                                                     ,ConocoPhillips - 4.1                    ," Houston, TX"     ,                     ,Estimated: $110K - $139K a year   ,5 days ago   ,"Power BI
                                                                                                                                                                                                                              Cloud infrastructure
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Oracle
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              R
                                                                                                                                                                                                                              Oil & gas
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              Java
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Data visualization
                                                                                                                                                                                                                              Python"                      ,"['Sr Data Engineer', '', '-', '', '00WPF', 'Description', 'Who We Are', '', 'We are one of the world’s largest independent exploration and production companies, based on proved reserves and production of liquids and natural gas. With operations and activities in 13 countries, we explore for, develop, and produce crude oil and natural gas globally. We are challenged with an important job to safely find and deliver energy to the world. Our employees are critical to our success, and with them we power civilization.', '', 'We’re grounded by our SPIRIT Values – safety, people, integrity, responsibility, innovation, and teamwork. These values position us to deliver strong performance in a dynamic business – but not at all costs. We believe it’s not just what we do – it’s how we do it – that sets us apart.', '', 'We strive to make a significant difference in the communities where we live and operate. We create an inclusive environment that values all voices and opinions. Together, the different backgrounds, experiences, ideas, and perspectives of our employees drive our success.', '', 'Description', '', 'This Snr, Data Engineer role within Global Wells IT in ConocoPhillips will be responsible for building data pipelines from source systems into the analytics environment. The role will also monitor, optimize, and support the development, test and production environments working closely with the system administrators, architects, and other IT support teams to ensure system availability.', '', 'This role will be proficient at integrating and preparing large, varied datasets including time series data and designing specialized database tables and information links within the environment. The person will work closely with Global Well engineers and Wells IT team to develop and optimize the environment in providing clean and reliable data for analytical solutions.', '', 'This role requires a strong and current technology focus, practical analytical experience, and excellent written and communications skill.', '', 'You may be eligible for the voluntary hybrid office work (HOW) program that is designed to provide employees with flexibility while maintaining the advantages of in-person engagement.', '', 'Your responsibilities may include:', '', '', 'Collect, explore, validate, and condition data', '', 'Collaborate with business subject matter experts and data scientists to create data sets and engineer features for analytical models', '', 'Productionize and operationalize analytical models', '', 'Adhere to ConocoPhillips’ governance and compliance policies for data and processes', '', 'Monitor model performance', '', 'Qualifications', 'Basic/Required:', '', '', 'Must be legally authorized to work in the United States as a U.S. citizen or national, or an alien admitted as a permanent resident, refugee or asylee', '', ""Bachelor's degree or higher in Computer Science, Mathematics, Engineering, Statistics, Information Technology, Information Systems/Science, other related field, or foreign equivalent"", '', '5+ years of previous experience developing data visualization tools using Spotfire or PowerBI', '', '5+ years of previous experience with an RDBMS platforms (Oracle, SQL Server) and SQL query language', '', '3+ years of experience with data engineering/operations', '', '3+ years of previous experience handling large amount of operational data and creating ETL/ELT pipelines', '', '3+ years of previous experience with Cloud DevOps and Infrastructure as Code (IaC) in AWS and/or Azure', '', 'Advanced level of proficiency with programming skills in languages such as Python, R, practical SQL, and Java', '', '', 'Preferred:', '', '', '3+ years of experience with wells operations time series data feeds in combination with historical and unstructured data', '', '3+ years of experience in the Oil and Gas Industry', '', 'Open attitude towards and ability to learn and utilize new technologies and standards', '', 'Excellent verbal and written presentation skills, with the ability to communicate clearly and persuasively', '', 'Excellent social skills in areas such as collaboration and communications', '', 'Builds positive relationships based on trust and seeks collaboration across organizational boundaries to achieve goals', '', 'Drives thoughtful and pragmatic change, encourages innovative thinking and continuous improvement, and models adaptability through resourcefulness, flexibility and positivity', '', 'Analyzes stakeholder needs, global, political, and market trends to understand how they shape the future and impact business results', '', '', 'To be considered for this position you must complete the entire application process, which includes answering all prescreening questions and providing your eSignature on or before the requisition closing date of', 'July 14, 2023.', '', 'Candidates for this U.S. position must be a U.S. citizen or national, or an alien admitted as permanent resident, refugee, asylee or temporary resident under 8 U.S.C. 1160(a) or 1255(a) (1). Individuals with temporary visas such as A, B, C, D, E, F, G, H, I, J, L, M, NATO, O, P, Q, R or TN or who need sponsorship for work authorization in the United States now or in the future, are not eligible for hire.', '', 'ConocoPhillips is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, gender identity or expression, genetic information or any other legally protected status.', 'Job Function', ':', 'Information Management-Information Technology', 'Job Level', ':', 'Individual Contributor/Staff Level', 'Primary Location', ':', 'NORTH AMERICA-USA-TEXAS-HOUSTON', 'Organization', ':', 'TECHNICAL CAPABILITIES', 'Line of Business', ':', 'Corporate Staffs', 'Job Posting', ':', 'Jun 29, 2023, 10:53:27 AM']"
 3 ,"Senior Software Engineer, Full Stack (Enterprise Data)"                             ,Capital One - 3.9                       ," Plano, TX"       ,                     ,                                  ,4 days ago   ,"Go
                                                                                                                                                                                                                              Node.js
                                                                                                                                                                                                                              CSS
                                                                                                                                                                                                                              Software Engineering
                                                                                                                                                                                                                              Kubernetes
                                                                                                                                                                                                                              Full-stack development
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              Java
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Docker
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              JavaScript
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              TypeScript
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              HTML5"                       ,"['Plano 1 (31061), United States of America, Plano, Texas', 'Senior Software Engineer, Full Stack (Enterprise Data)', ""Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking"", '', 'Full Stack Software Engineers', '', 'who are passionate about marrying data with emerging technologies. As a Capital One Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.', 'Enterprise Data is hiring! In this role, you will contribute to critical enterprise applications, supporting data management and data transfer solutions across the company.', 'What You’ll Do:', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Utilize programming languages like Python, JavaScript, Node.js, Java, HTML/CSS, TypeScript, SQL, and Go, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services', 'Basic Qualifications:', 'Bachelor’s Degree', 'At least 4 years of experience in software engineering (Internship experience does not apply)', 'Preferred Qualifications:', '5+ years of experience with Python', '3+ years of experience with AWS', '3+ years of experience in open source frameworks', '2+ years of experience in Agile practices', 'At this time, Capital One will not sponsor a new applicant for employment authorization for this position.', 'Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.', 'No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.', 'If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.', ""For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com"", 'Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.', 'Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).']"
 4 ,Big Data Engineer - GBDETX0623                                                       ,Genpact - 3.8                           ," Richardson, TX"  ,Full-time            ,                                  ,2 days ago   ,"DataStage
                                                                                                                                                                                                                              Big data
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              Apache Hive
                                                                                                                                                                                                                              Ab Initio
                                                                                                                                                                                                                              Master's degree
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Teradata
                                                                                                                                                                                                                              Informatica
                                                                                                                                                                                                                              PL/SQL
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Hadoop"                      ,"['With a startup spirit and 115,000+ curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us. Inviting applications for the role of PD, AP Helpdesk', '', 'Skills – Genpact LLC seeks', 'Big Data Engineer (multiple positions)', 'in Richardson, TX to', '', 'develop technical specifications for software application and provide quick resolution to production incidents or problems. Communicate project status, requirements, issues, risks, and assumptions effectively to end clients, the business teams, and development resources.', 'Responsible for all the activities related to the analysis, architecture, design, and implementation of new or modified application software for data Extraction, Transformation, and Loading (ETL) solutions (including data lake, data marts, and data warehouses) within the banking, financial services, and insurance domains. Design and develop ETL and Big Data applications, scripts, queries, reports, and other automated procedures. Employ relevant application development tools, platforms, and methodologies including ETL and Big Data tools (Informatica, DataStage, Abinitio, Hadoop, and Hive), SQL, PL/SQL, Teradata tools, Python, PySpark, and data governance tools (Informatica IDQ, and Data Quality). Employ experience in Google Cloud along with Google Sataproc and Google Big Query. Apply management and technical (Distributed and Legacy technologies) expertise in primary industry domains (Banking and Financial Services, Healthcare, Pharmacy, or Insurance) to lead and coordinate the overall activities of distributed software engineering and development resources. Establish the feasibility of application development and delivery plans. Interact with clients to clarify business requirements and key operations. Manage and lead project team and coordinate efforts with client teams, serving as single point of contact. Participate in business analysis, functional design, data quality, and testing activities for any new enhancements. Responsible for assessment and effort estimates for any new enhancements or extensions, and plan and allocate resources accordingly. Participate in daily scrum calls, serve as part of the team for creation of user stories, feasibility analysis, effort estimation, and prioritization of change requests. Participate in the daily team calls and provide updates to servicing project manager for incidents. Develop technical specifications for software application and provide quick resolution to production incidents or problems. Communicate project status, requirements, issues, risks, and assumptions effectively to end clients, the business teams, and development resources.', '', 'Education –', ""Position requires a Master’s degree in an Engineering (all), Computer Science, Sciences, Mathematics, or related field and 2 years of experience in the job offered, a related software engineering architect, designer, programmer, or systems analyst position, or related occupation. As an alternative, a Bachelor’s degree in an Engineering (all), Computer Science, Sciences, Mathematics, or related field and 5 years of progressively responsible post-Bachelor's experience in the job offered, a related software engineering architect, designer, programmer or systems analyst position, or related occupation is also acceptable."", 'Foreign degree equivalents are acceptable. Position headquartered in Richardson, TX with travel required to unanticipated project sites throughout the U.S. based on client need', '.', '', 'Please send resume and cover letter to:', '', 'Talent.Recruitment@genpact.com', '', 'Indicate job code “', 'G', 'BDETX0', '623', '” when applying.', '', 'Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.', 'Job', 'Senior Principal Consultant', 'Primary Location', 'USA-Richardson', 'Education Level', ""Bachelor's / Graduation / Equivalent"", 'Job Posting', 'Jul 5, 2023, 12:54:45 PM', 'Unposting Date', 'Aug 4, 2023, 1:29:00 PM', 'Master Skills List', 'Corporate', 'Job Category', 'Full Time']"
 5 ,Sr Data Engineer                                                                     ,Vistra Corporate Services Company - 3.6 ," Irving, TX"      ,Full-time            ,Estimated: $116K - $146K a year   ,6 days ago   ,"7 years
                                                                                                                                                                                                                              Data modeling
                                                                                                                                                                                                                              SAP HANA
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              Test-driven development
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Presentation skills
                                                                                                                                                                                                                              Organizational skills
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Certified Scrum Master
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              IT
                                                                                                                                                                                                                              SAP BusinessObjects
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python"                      ,"['If you have what it takes to become part of the Vistra family and would like to start a promising career with a global leader, take a look at the exciting employment opportunities that are currently available and apply online.', 'Job Summary', ""The Sr Data ETL Engineer will be part of a team that develops and supports ETL-based data and analytics use cases. In this role, they will be responsible for implementing and maintaining ETL tools for data infrastructure systems within Vistra's technology and other business units. This person should be a highly qualified and experienced data professional. This individual must be able to work on technical and infrastructure innovation within the team of data systems and perform highly technical work efficiently and on time. The ideal candidate should have hands-on development experience handling the Extract, Transform, and Load (ETL) process for datasets containing mixed structured and unstructured data."", 'Job Description', 'Key Accountabilities', 'Drive the maintenance of systems, creation of technical designs, development and deployment of front-end and/or back-end systems, integration of the data warehouse with enterprise applications, and/or implementation of user access controls and data security measures, where appropriate.', 'Coordinate daily operational activities and measure process quality and compliance.', 'Identify, evaluate, and implement automation and continuous improvement ideas supporting ITIL-aligned processes.', 'Partner with business users, process owners, architecture, and application teams to support data needs that follow Vistra standards.', 'Create policies, standards, guidelines and procedures in order to ensure data is available, responsive, and achieving business outcomes and objectives.', 'Analyze code for non-standard practices, errors, and security vulnerabilities and present detailed plans to improve them.', 'Build unit tests to support a test-driven development approach.', 'Support the analytics platforms and provide development and testing to help deliver data needs.', 'Successfully deliver cross-team initiatives related to the platforms supported by the team.', 'Drive positive working relationships with technology teams, business teams, and vendors in order to promote alignment between functions.', 'Design and create metrics for improved measurement and reporting.', 'Understand and apply the value drivers for Vistra to deliver innovative value creation ideas.', 'Train the TS and end user community to assist with the adoption and communication of TS processes.', 'Participate in agile ceremonies.', 'Provide domain guidance to less experienced team members.', 'Apply understanding of financial principles impacting the applications supported by the team.', 'Education, Experience, & Skill Requirements', '7-10 years professional experience in a technology or business field', 'Professional certifications a plus (e.g., ITIL, CSM, AWS)', 'Proven ability to analyze code for non-standard practices, errors, and security vulnerabilities and present detailed remediation plans.', 'Experience delivering cross-team initiatives related to the platforms supported by the team.', 'Proven ability to identify, evaluate, and implement opportunities for automation and continuous improvement of ITIL-aligned processes', 'Demonstrated ability to be trustworthy and dependable', 'Ability to learn quickly, be self motivated to improve knowledge and tackle new challenges', 'Exceptional organizational skills, communication skills, and attention to detail required', 'Skilled at creating leadership-level communications and presenting to and interacting with leaders', 'Must demonstrate an energetic, hands-on, enthusiastic, results-oriented approach as a team player, capable of adding significant value to the existing team.', 'Must be comfortable sharing ideas and finding innovative ways to resolve challenges.', 'Proven ability to build support among peers and create relationships with peers and stakeholders.', 'Key Metrics', 'System availability', 'Process compliance', 'Data availability', 'Data quality', 'Agile delivery proficiency', 'Ticket volumes and trending', 'Hands-on experience in analyzing and organizing both structured and unstructured datasets is a must required skill', 'Hands-on experience with extract, transform and load (ETL) or ELT integrations tools namely Talend, SAP Data Services is highly preferred', 'Hands-on experience with SQL, Snowflake is a significant advantage', 'Experience with SAP Hana data modeling is preferred', 'Familiarity with Data Quality methods and standards is a plus', 'Familiarity with Data warehousing, Data modeling and Data Profiling is a plus', 'Being well-versed with ETL development standard cycle including coding, testing, deployment, support, and transition is highly preferred', 'Previous exposure to Git is a plus', 'Experience with Python is a plus', 'Job Family', 'Information Technology', 'Company', 'Vistra Corporate Services Company', 'Locations', 'Irving, Texas', 'Texas', 'We are a company of people committed to: Exceeding Customer Expectations, Great People, Teamwork, Competitive Spirit and Effective Communication. If this describes you, then apply today!', 'If you currently work for Vistra or its subsidiaries, please apply via the internal career site.', 'It is the policy of the Company to comply with all employment laws and to afford equal employment opportunity to individuals in all aspects of employment, including in selection for job opportunities, without regard to race, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, age, disability, genetic information, military service, protected veteran status, or any other consideration protected by federal, state or local laws.', 'If you are an individual with a disability and need assistance submitting an application or would like to request an accommodation, please email us at assistance@vistraenergy.com to make a request.']"
 6 ,Portal Req - Flight Test Instrumentation and Data Processing Engineer                ,Lockheed Martin - 4.0                   ," Fort Worth, TX"  ,Full-time            ,                                  ,6 days ago   ,"VMWare
                                                                                                                                                                                                                              vSphere"                     ,"['Job ID:', '621543BR', '', 'Date posted:', 'Mar. 01, 2023', '', '', 'Description:', 'By applying to the position listed on this site, you will be considered for opportunities within Lockheed Martin Aeronautics Corporation.', '', ""Our products play an important role in the national security of the United States and more than 70 other countries, ensuring peace and stability around the world. Highly trained and specialized personnel and facilities are key to the company's unrivaled success in the aeronautics industry. Our workforce of more than 25,000 has pre-eminent expertise in advanced aircraft design and production, modification and support, stealth technology, and systems integration."", '', ""Lockheed Martin Aeronautics Test and Evaluation (T&E) is hiring Flight Test Instrumentation and Data Processing Engineers at our test sites in California, Maryland, Nevada, Georgia, and Texas. Our Mission Statement: A United World Class Test Team Committed to Effective, Safe and Quality Product Deliver to Meet Our Customer's Needs. Every Commitment, Every Time, On Time."", '', 'Flight Test Instrumentation and Data Processing Engineers for T&E include Flight Test Instrumentation Operations Engineers, Flight Test Data Processing Engineers, Flight Test System Administrators, or Flight Test Simulation Administrators.', '', 'Flight Test Instrumentation Operations Engineers will be responsible for integrating requirements and programming new instrumentation data acquisition equipment, as well as fiber system, analog and digital signal conditioning hardware during integration and flight test. Knowledge of video compression and recording devices; solid state media recorders; analog/digital encoders/decoders; GPS and IRIG time standards and receiving devices; and other instrumentation devices to develop, test, and troubleshoot data acquisition systems is a plus. Works with LM homesite instrumentation engineers to identify instrumentation components, select parts, place orders, and manage status and costs.', '', 'Participate in real time control room activities during flight execution. The successful candidate will validate that aircraft sensors and mission system tests are conducted correctly by actively monitoring real time telemetry data during flight.', '', 'Assist with on aircraft troubleshooting and failure resolution as needed to ensure test aircraft are mission capable. Coordinate with other system personnel to resolve system failures or performance questions. Participate in problem identification, analysis, and resolution. Assist with collection, distribution, and analysis of data acquired during flight test missions.', '', 'Flight Test Data Processing Engineers will design, build, integrate, and operate systems for the real-time display of aircraft data as well as post-test processing of recorded data to create data products. Will interface with other technical personnel in the diagnosis and resolution of any problems (hardware/software) encountered in the recovery of test data utilizing various data systems including PCM ground stations, telemetry ground stations, specialized data processing equipment, etc.', '', 'Flight Test System Administrator Job duties include:', '', 'System Installation/Configuration (IT-centric tasks).', 'Network Switch Configuration/Maintenance.', 'Server Maintenance/Stand-Alone System', 'Support/Install Framework Patches.', '', 'Deploy security updates/System Regression Tests.', 'Maintain Documentation of System Configuration/Changes.', 'Troubleshooting issues as they arise.', 'Vulnerability Remediation on both Networked and Stand-Alone Systems.', 'Flight Test Simulation Administrator Job duties include:', '', 'Build Custom Test Scenarios and Weapons Loadouts for Scheduled Missions.', 'Software Integration with SCRUM Framework Style Reporting on New Build Outs.', 'Coordination with Engineering HQ (In Fort Worth, TX) on Current Issues and Build Updates.', 'Management of Flight Sim NAS, Switches, VSphere (VMWare) and Virtual Servers', 'Management of iSCSI booted Hosts Servers', 'Configuring/Supporting Security on Cybersecurity Tools and Servers such as ePO, AC', 'Basic Qualifications:', '**Must be a US Citizen. This position is located at a facility that requires special access.**', '', 'Education background in a STEM discipline', '', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about."", '', ""As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'AERONAUTICS COMPANY', '', 'Relocation Available:', 'Possible', '', 'Career Area:', 'Miscellaneous Engineering', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
 7 ,Project Engineer Stf - Mission Data                                                  ,Lockheed Martin - 4.0                   ," Fort Worth, TX"  ,Full-time            ,                                  ,16 hours ago ,"Microsoft Powerpoint
                                                                                                                                                                                                                              Microsoft Word
                                                                                                                                                                                                                              Microsoft Excel
                                                                                                                                                                                                                              Management
                                                                                                                                                                                                                              Auto estimating
                                                                                                                                                                                                                              Microsoft Office
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Systems engineering
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Avionics
                                                                                                                                                                                                                              Microsoft Project
                                                                                                                                                                                                                              Leadership
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Construction estimating"     ,"['Job ID:', '640273BR', '', 'Date posted:', 'Jun. 09, 2023', '', '', 'Description:', ""The F-35 Common Reprogramming Tool (CRT) team is in need of a Project Engineer to coordinate and perform CAM duties across a variety of CRT contracts. The project engineer shall be required to coordinate across a number of teams to ensure the mission data organization's plans are in alignment with the broader organization's goals in order to meet tool delivery and contractual constraints. The candidate will be responsible for providing support and leadership for F-35 CRT team"", 'estimate efforts along with support to program & project managers. The candidate will be responsible for coordinating software milestones are met with the appropriate technical content. The candidate will be responsible for reviewing the status of projects & budgets, support & cost inquiries, variance documentation, critical', 'path & forecast misses, and bi-annual estimate at', 'completion (EAC) efforts. The candidate will provide earned value (EV) performance and EAC assessments. The candidate will identify risks, issues and opportunities and implement approved risk handling plans. The successful', 'candidate will use the complete CAM toolset to gather cost and budget data. The candidate will ensure the team follows all tenants of the LM Aero EVMS processes as defined within the F35 program. The candidate will participate in all required reviews and audits with the', 'customer, government, DCMA, etc.', '', 'Basic Qualifications:', '', 'Bachelors degree from an accredited college', 'Knowledge of Earned Valued Management, metrics and process management', 'Familiarity with the CAM toolset', 'Proficiency with MS Office products (Project, Word, Excel, and PowerPoint)', 'Desired Skills:', '', 'Team Leadership Experience', 'EV for Agile development', 'Systems engineering and mission systems/avionics background', 'Experience with Safety Critical and trusted software development process', 'Experience with F35 proposal process', 'Experience with resource estimation & management, software development estimation, project planning, and project management', 'Excellent communication, organization, and presentation skills of technical assignments', 'Experience in areas of cost analysis, schedule, and risk & opportunity management', 'Possess strong verbal and written communication skill', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret with an investigation within 5 years', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about."", '', ""As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'AERONAUTICS COMPANY', '', 'Relocation Available:', 'Possible', '', 'Career Area:', 'Program Management', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
 8 ,"No C2C/ Only W2/1099 - Lead Big Data Engineer - Charlotte, NC, MN, TX"              ,BIGCLFY                                 ," Dallas, TX"      ,Contract             ,From $72 an hour                  ,12 hours ago ,"Azure
                                                                                                                                                                                                                              HDFS
                                                                                                                                                                                                                              Big data
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Apache Hive
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              CPT coding
                                                                                                                                                                                                                              Software development
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Kafka
                                                                                                                                                                                                                              2 years
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Hadoop"                      ,"['No C2C / No Corp to Corp', 'W2 Requirement / Direct Client Requirement :', '·', 'Only taking USC, GC or H4 EAD, L2 Visa or TN Visa', '- they', 'will not take', 'OPT EAD or CPT', 'Lead Big Data Engineer', 'Charlotte, NC, Minneapolis, MN or Dallas, TX (Hybrid) – hybrid onsite', '12+ months', 'We will transfer Visas and process GCs', '6+ years in Big Data Engineering with at least 1 year as a lead', 'Must be hands on within the following:', 'HDFS, Hive, Spark, Python, Kafka, SQL', 'Must be able to work hybrid onsite – this is not a remote role', 'MUST HAVE', '4 Years of Azure – REQUIRED', '4+ years of Data engineering experience', '4+ years of experience in any or all Big-Data stack such as Hadoop, Hive, Spark, python', '4+ years of Relational data base experience', '4 + years of ETL (Extract, Transform, Load) development experience using any Big-Data technology', '2+ years of Agile software development experience', 'Hands-on experience with', 'Job Type: Contract', 'Pay: From $72.00 per hour', 'Schedule:', '8 hour shift', 'Ability to commute/relocate:', 'Dallas, TX 75201: Reliably commute or planning to relocate before starting work (Preferred)', 'Application Question(s):', 'Expected payrate on W2 or 1099? Please suggest.', 'Experience:', 'Lead: 1 year (Preferred)', 'Software Industry Big Data Engineering: 7 years (Preferred)', 'Work Location: In person']"
 9 ,Senior Data Center Engineer                                                          ,Rockwell Automation - 3.9               ,Texas              ,Full-time            ,Estimated: $103K - $131K a year   ,12 hours ago ,"Computer science
                                                                                                                                                                                                                              Data center experience
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              IT auditing
                                                                                                                                                                                                                              Disaster recovery
                                                                                                                                                                                                                              HIPAA
                                                                                                                                                                                                                              SOX
                                                                                                                                                                                                                              8 years
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Product management
                                                                                                                                                                                                                              Communication skills"        ,"['Rockwell Automation is a global technology leader focused on helping the world’s manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility - our people are energized problem solvers that take pride in how the work we do changes the world for the better.', 'We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that’s you we would love to have you join us!', 'Job Description', 'The Sr Data Center Engineer uses current Rockwell data, statistics, insights, trend analysis, and other data analysis techniques to collect, explore, and identify the right needs for the infrastructure and operations, then constructs plans and roadmaps to provide solutions and improvements for Resilience program and Data Center operations. Assists business and other IT teams with finding fixes and solutions for tech debts. Oversees data centers services providers to execute operational tasks on DC when needed. Provide liaisons and educate other IT areas on DC (owned, colocation and CNFs) best practices and DC Service Catalog definition and execution. Lead in the planning, development and enhancement of the Data Center provision within overall business planning. ·Provide technical management of the Data Center, ensuring that agreed service levels are met and all relevant policies and procedures are adhered to, whilst seeking means of continual improvement. Ensure that operational procedures and working practices are fit for purpose, current, and policies are followed. Oversees the operations support that includes the entire IT infrastructure housed within the Data Center. Customer support responsibilities can include other IT organizations relations, responding to IT teams inquiries and coordinating with other organizations. Administrative duties include provide feedback about tasks under your duties and responsibilities, planning for capacity changes, maintaining corporate applications and databases updated and ensuring compliance with all relevant regulations (State, Federal, ISO, SOX, ITAR, etc). Assisting with the procurement of new data center equipment.', 'Key Responsibilities:', 'Drive the solutions for the owned Data Centers by owning the Data Center architecture and its roadmap.', 'Enable teams to perform their best work by coaching them on best practices and optimizations; Contribute to vision and own program backlogs and implementations.', 'Lead the team on technical and architectural design for the projects under your responsibility.', 'Conduct technology and architecture research, requirement gathering from other product/engineering management stakeholders and business owners.', 'Act as a leader, mentor, and learner- always answer/ask questions to challenge the status quo –', 'Collaborate with other capability team to achieve results across teams.', 'Lead, manages and collaborate on data center policies to increase robustness.', 'Develop the future state of owned, colocations and outsourced data centers as well remote IDF/MDFs service delivery model.', 'Apply process improvements to facilitate improved outcomes.', 'Bring industry best-practices and new thinking to the team.', 'Provide Site and Application support for global development teams.', 'Overall responsibility for team’s financial management and optimization', 'Basic Qualifications:', 'Bachelor’s Degree in computer science, or other engineering discipline, or equivalent engineering experience', 'Legal authorization to work in the US is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening.', 'Preferred Qualifications:', 'Typically requires a minimum of 8 years of Data Center experience.', 'Understanding of Data Center physical architecture, demands and needs.', 'Experience in leading infrastructure teams and delivering data center solutions.', 'Confident of making operations decisions at a team and product level', 'Demonstrated experience in Data Center implementation, upgrade, monitoring, and administration.', 'Experience managing Global Data Center IT Strategy', 'Experience with IT Audits ISO, SOX, FINRA, HIPPA and ITAR', 'Good communication skills with ability to align the organization on complex technical decisions.', 'Experience managing the overall Operational Resilience, Facilities, and All Hazard Risk Management, DC Design and Architecture providing guidance an educate others on these subjects when needed.', 'Ability to work in a highly collaborative environment and to communicate effectively with internal and external partners.', 'Experience in developing IT disaster recovery plans, infrastructure project management.', 'Be security conscious in everything you do.', 'Experience with assisting a global disperse contractors providing site and application support.', 'Serves as liaison to vendors, contractors, and service professionals.', 'This position is part of a job family. Experience will be the determining factor for position level and compensation.', 'We are an Equal Opportunity Employer including disability and veterans.', 'If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247.']"
10 ,Senior Data Engineer                                                                 ,S&P Global - 3.9                        ," Austin, TX"      ,                     ," $70,300 - $139,800 a year"      ,4 days ago   ,"CI/CD
                                                                                                                                                                                                                              Power BI
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Management
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              C#
                                                                                                                                                                                                                              Alteryx
                                                                                                                                                                                                                              Microsoft SQL Server
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              Cataloging
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Docker
                                                                                                                                                                                                                              PostgreSQL
                                                                                                                                                                                                                              Terraform
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              Python"                      ,"['The Role:', 'Senior Data Engineer', '', 'The Team:', 'As a member of the Data Operations team, you will help modernize the extensive data domain of the Issuer Solutions business.', '', 'The Impact:', 'As we redesign and reimagine our client-facing and internal tools, data quality and consistency across multiple tools and platforms will be a key factor in our success, and the Data Engineering team is tasked with ensuring that all data consumers, from developers to business analysts to clients, have tools to access the data they need in the format they need it.', '', 'What’s in it for you:', 'Designing and implementing data-ingestion and data-publishing tools for diverse datasets.', 'Implementing and maintaining data-monitoring and data-cataloguing tools.', 'Implementing and maintaining process-management and data-movement tools for ETL’s.', 'Offering guidance and best practices to scrum teams who work with data.', 'Evaluating and implementing new data management technology with the goal of continually improving team efficiency and data quality.', 'Providing support and guidance for business analysts using data analysis tools such as Alteryx and PowerBI.', '', 'Responsibilities:', 'Minimum of 3+ years experience as a software engineer', 'Experience as a Data Engineer in a production environment', 'Focus on ETL’s, data monitoring, data engineering, etc.', 'Python, C#, Docker, MS SQL Server, PostgreSQL', 'Experience with AWS and/or Azure DevOps', 'AWS tech:', 'Aurora DB, Glue, Lambda', 'Alteryx Server', 'Infrastructure as code using Terraform/CloudFormation', 'Solid understanding of containers and orchestration tools (Docker, CI/CD, etc.)', 'AirFlow, DataHub, NiFi and other data-management and process-management tools a plus', 'Experience with BI and analytical tools such as PowerBI and Alteryx', 'Flexible Working (optional)', 'We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.', 'Return to Work', 'Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.', '', 'Grade/Level ( relevant for internal applicants only ):', '10', '', 'The Location:', 'Florida, Georgia, New York, Virginia, Connecticut, Ohio, Delaware', '', 'Compensation and Benefits Information:', 'S&P Global states that the anticipated base salary range for this position is $70,300 - $139,800. Base salary ranges may vary by geographic location.', 'In addition to base compensation, this role is eligible for an annual incentive bonus plan.', 'This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit Our Benefits (spgbenefits.com) .', '', 'About Company Statement:', 'S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.', 'S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.', '-----------------------------------------------------------', 'Equal Opportunity Employer', 'S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.', 'If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.', '', 'US Candidates Only:', 'The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.', '----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group)', '', 'Job ID:', '288863', 'Posted On:', '2023-06-22', 'Location:', 'Virtual, North Carolina, United States']"
 0 ,"Data Engineer, Staff (RTE/PO) / Active Clearance / Onsite - GA or TX"               ,Lockheed Martin - 4.0                   ," Fort Worth, TX"  ,Full-time            ,                                  ,6 days ago   ,"Computer science
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Secret Clearance
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Product management
                                                                                                                                                                                                                              Business Information Systems
                                                                                                                                                                                                                              Communication skills
                                                                                                                                                                                                                              Data Science"                ,"['Job ID:', '638707BR', '', 'Date posted:', 'May. 16, 2023', '', '', 'Description:', 'This role will have Release Train Engineer, Product Owner responsibilities under Scaled Agile framework to drive mission of the data team for ADP (Advanced Development Program). This will require on-site support for Classified Aero Programs (Marietta, GA or Ft Worth, TX).', 'The individual will:', '', 'Maintain focus on the project and synchronize agile teams', 'Work with Product Management and other stakeholders to define and prioritize epics/features/stories/projects', 'Translate business requirements into features/stories for the technical teams', 'Identify and remove impediments and risks', 'Facilitate Agile ceremonies (DSU, Program Backlog/Vision, PI Planning, Iteration Planning/Review, Retrospective, etc)', 'Build significant relationships and responsibilities outside the local team, including working with Product Management, Customers, Business Owners, and other stakeholders.', 'Basic Qualifications:', '', 'US Citizenship. Will require program clearance prior to start (DoD Secret Clearance)', 'Significant years of proven experience aligned to the RTE / PO duties listed in Job Description', 'Strong problem-solving skills and strong oral and written communication skills', ""Bachelor's degree in Data Science, Computer Science, Business Information Systems, or other relevant areas, or equivalent education/experience"", 'Desired Skills:', '', 'Understanding of Data security', 'Previous experience in Data Engineering', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work."", '', 'With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.', '', ""If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'ENTERPRISE BUSINESS SERVICES', '', 'Relocation Available:', 'No', '', 'Career Area:', 'Information Technology', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
 1 ,Senior Data Engineer - Principal Associate                                           ,Capital One - 3.9                       ," Plano, TX"       ,                     ,                                  ,4 days ago   ,"Azure
                                                                                                                                                                                                                              Cassandra
                                                                                                                                                                                                                              Full-stack development
                                                                                                                                                                                                                              Big data
                                                                                                                                                                                                                              MapReduce
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              UNIX
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              Apache Hive
                                                                                                                                                                                                                              Java
                                                                                                                                                                                                                              Application development
                                                                                                                                                                                                                              Microservices
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Machine learning
                                                                                                                                                                                                                              Scala
                                                                                                                                                                                                                              Scripting
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Linux
                                                                                                                                                                                                                              Kafka
                                                                                                                                                                                                                              1 year
                                                                                                                                                                                                                              Redshift
                                                                                                                                                                                                                              Data warehouse
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Shell Scripting
                                                                                                                                                                                                                              MySQL
                                                                                                                                                                                                                              Hadoop"                      ,"['Plano 3 (31063), United States of America, Plano, Texas', 'Senior Data Engineer - Principal Associate', ""Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One."", 'What You’ll Do:', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Basic Qualifications:', 'Bachelor’s Degree', 'At least 4 years of experience in application development (Internship experience does not apply)', 'At least 1 year of experience in big data technologies', 'Preferred Qualifications:', '5+ years of experience in application development including Python, SQL, Scala, or Java', '2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)', '3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)', '2+ year experience working on real-time data and streaming applications', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of data warehousing experience (Redshift or Snowflake)', '3+ years of experience with UNIX/Linux including basic commands and shell scripting', '2+ years of experience with Agile engineering practices', 'At this time, Capital One will not sponsor a new applicant for employment authorization for this position.', 'Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.', 'No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.', 'If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.', ""For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com"", 'Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.', 'Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).']"
 2 ,Senior Principal Software Engineer - Platform Data Cloud                             ,Blue Yonder - 4.1                       ," Dallas, TX"      ,Full-time            ," $180,538 - $234,273 a year"     ,2 days ago   ,"Jira
                                                                                                                                                                                                                              Spring Boot
                                                                                                                                                                                                                              Computer science
                                                                                                                                                                                                                              Elasticsearch
                                                                                                                                                                                                                              Cloud infrastructure
                                                                                                                                                                                                                              Azure
                                                                                                                                                                                                                              Cloud architecture
                                                                                                                                                                                                                              Node.js
                                                                                                                                                                                                                              Computer Science
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              React
                                                                                                                                                                                                                              Kubernetes
                                                                                                                                                                                                                              Ansible
                                                                                                                                                                                                                              Full-stack development
                                                                                                                                                                                                                              DevOps
                                                                                                                                                                                                                              Spark
                                                                                                                                                                                                                              Test automation
                                                                                                                                                                                                                              NoSQL
                                                                                                                                                                                                                              11+ years
                                                                                                                                                                                                                              Git
                                                                                                                                                                                                                              Test-driven development
                                                                                                                                                                                                                              Google Cloud Platform
                                                                                                                                                                                                                              Java
                                                                                                                                                                                                                              Master's degree
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              AWS
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Docker
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              JavaScript
                                                                                                                                                                                                                              PostgreSQL
                                                                                                                                                                                                                              Distributed systems
                                                                                                                                                                                                                              Continuous integration
                                                                                                                                                                                                                              GitHub
                                                                                                                                                                                                                              Agile
                                                                                                                                                                                                                              Kafka
                                                                                                                                                                                                                              Groovy
                                                                                                                                                                                                                              Jenkins
                                                                                                                                                                                                                              Python
                                                                                                                                                                                                                              Spring"                      ,"['The Luminate Cloud Data Platform team’s mission is to reimagine the supply chain technology and serve as the backbone of Blue Yonder’s SaaS products. Role serves as one of the key global architect to focus on innovation in SaaS platform engineering, spanning infrastructure architecture through enterprise, application platform features, to accelerate our cloud data team’s delivery and solution quality.', '', 'Primary Duties and Responsibilities', 'Consistently delivers solid quality in both design and implementation and helps the team shape what is built how, in particular:', 'Core responsibilities includes focusing on innovation and improving delivery effectiveness by driving product development features across the organization in software development, deployment, and infrastructure consistency.', 'Provide standardized enterprise solutions for cloud infrastructure and application deployment across multiple products.', 'Apply the appropriate software engineering patterns utilizing a meta-driven systems approach to build robust and scalable systems', 'Expert in Object Oriented and Functional programming and the ability to apply your skills in developing Blue Yonder products.', 'Influence fellow engineers by proposing software designs, providing feedback on software designs and/or implementation.', 'Demonstrated experience in large-scale Kubernetes systems, including how to sufficiently scale very large services in Kubernetes', 'Modular and Service based Architectural Design', 'The team currently comprises of global associates across US, Canada, India, and Germany and is expected to grow. The incumbent will need to be a quick learner.', 'Our Current Technical Environment:', 'Software/Tools: Java, Python, Groovy, GitHub, Node.js, React.js, Jenkins, GitHub, Codacy, Checkmarx, GitHub Advance Security, Black Duck Hub, BlazeMeter, Artifactory, Ansible, Docker, etc.', 'Application Architecture: Scalable, Resilient, event driven, secure multi-tenant Microservices architecture', 'Cloud Architecture: MS Azure (ARM templates, AKS, Virtue Networks, Event Hub, Azure AD)', 'Frameworks/Others: Kubernetes, Kafka, Elasticsearch, Spark, NOSQL, RDBMS, Spring Boot, Snowflake', 'What you’ll do:', 'An Architect- You’re comfortable crafting robust distributed systems that achieve both short and long-term business goals.', 'An Influencer- You communicate well across the organization to help define technical strategies and design tactics to execute them. You have the ability to articulate a clear technical vision.', ""Clean, Performant Code- You’re hands-on and comfortable writing code. You keep up with best practices and have a breadth of experience with different languages and frameworks. You are passionate about code quality and automation. You're comfortable driving the implementation and adoption of new frameworks, tools and technologies."", 'Agile Best Practices-You like working in an agile development environment and enjoy pairing, test-driven development, leading demos with working code and slicing work in a way that focuses on the highest value.', 'A Mentor- You have a passion for passing on your hard-earned experience. You disseminate knowledge and strive to level up those around you.', 'Be a change agent with technology development using cloud native architecture patterns in a distributed environment', 'Drive culture change in technology to become a truly Agile team which is self-organizing, DevOps and believes in everything automated', 'Collaborate with application teams for adoption of single Data platform', 'Discovering, Understanding, Leveraging, and Exposing new technologies and designs that will benefit the Data Platform', 'Evaluate and coach other senior engineers on the technical and interpersonal best-practices.', 'What we are looking for:', 'Masters/Bachelor’s Degree in Computer Science or related', 'You have 12+ years of Software Engineering experience and have experience in leadership roles across the full technology stack.', 'You have demonstrated organizational impact in your career by championing engineering principles like SOLID, TDD, OO design, etc.', 'You have a passion for pulling others up the ladder in their technology career and sharing best practices with more junior engineers.', 'Ability to collaborate well with the broader organization to include product, QA, senior leadership, compliance and other key stakeholders to your work.', 'Experience building robust, highly available, and scalable data lakes', 'Experience working with SQL and no-SQL datastores like Elasticsearch, Postgres, Snowflake', 'Expert in leveraging continuous integration and robust build/test automation, with a preference for cross platform stacks and containerization (Jira, Git, Jenkins)', 'Experience in one of the public cloud technology stack in Azure , AWS, GCP', 'Experience with Docker Containerization and Cloud services such as ElasticCache, EKS', 'Strong analytical skills to be able to manage complex problems using a number of techniques', 'Experience in leading complex software product delivery in an Agile environment', 'Experience in a leadership position responsible for building, motivating and leading high performing development teams', 'Experience with enterprise multi-tenant software', '-', 'The salary range for this position is: USD $ 180,537.50 – $234,272.5', 'The salary range information provided, reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual salary will be commensurate with skills, experience, certifications or licenses and other relevant factors. In addition, this role will be eligible to participate in either the annual performance bonus or commission program, determined by the nature of the position.', 'At Blue Yonder, we care about the wellbeing of our employees and those most important to them. This is reflected in our robust benefits package and options that includes:', 'Comprehensive Medical, Dental and Vision', '401K with Matching', 'Flexible Time Off', 'Corporate Fitness Program', 'Wellbeing Days', 'A variety of voluntary benefits such as; Legal Plans, Accident and Hospital Indemnity, Pet Insurance and much more', 'At Blue Yonder, we are committed to a workplace that genuinely fosters inclusion and belonging in which everyone can share their unique voices and talents in a safe space. We continue to be guided by our core values and are proud of our diverse culture as an equal opportunity employer. We understand that your career search may look different than others, and embrace the professional, personal, educational, and volunteer opportunities through which people gain experience.', 'Our Values', 'If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here:', 'Core Values', 'Diversity, Inclusion, Value & Equality (DIVE)', ""is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural"", 'Diversity Report', 'which outlines our commitment to change, and our', 'video', 'celebrating the differences in all of us in the words of some of our associates from around the world.', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.']"
 3 ,Senior Data Engineer- Databricks                                                     ,Cognizant Technology Solutions - 3.9    ," Dallas, TX"      ,Full-time            ,Estimated: $108K - $137K a year   ,5 days ago   ,"Azure
                                                                                                                                                                                                                              Data lake
                                                                                                                                                                                                                              Big data
                                                                                                                                                                                                                              R
                                                                                                                                                                                                                              3 years
                                                                                                                                                                                                                              SQL
                                                                                                                                                                                                                              Analysis skills
                                                                                                                                                                                                                              Bachelor's degree
                                                                                                                                                                                                                              Data management
                                                                                                                                                                                                                              ETL
                                                                                                                                                                                                                              AI
                                                                                                                                                                                                                              Python"                      ,"['Senior Data Engineer- DataBricks', '', 'Location: Dallas, TX (Hybrid/Onsite)', '', ""Cognizant (NASDAQ: CTSH) is a leading provider of information technology, consulting, and business process outsourcing services, dedicated to helping the world's leading companies build stronger businesses. Headquartered in Teaneck, New Jersey (U.S.). Cognizant is a member of the NASDAQ-100, the S&P 500, the Forbes Global 1000, and the Fortune 500 and we are among the top performing and fastest growing companies in the world."", '', '*Please note, this role is not able to offer visa transfer or sponsorship now or in the future*', '', 'Practice - AIA - Artificial Intelligence and Analytics', '', 'Qualification', ':', '', '', 'Bachelors in science , engineering or equivalent', '', '10+ years of experience building, deploying, and designing data solutions: ETL, data warehousing, or Big Data.', '', '3-6 Years of experience working with DataBricks.', '', 'Experience working with Azure Data stack; Data Lake, Data factory, DataBricks, Synapse, etc.', '', '', 'Responsibility', ':', '', '', 'Provide input to cloud engineer for the design and implementation of data management and/or architecture solutions.', '', 'Partner with cloud engineer and ML engineer to develop and evolve the concept of data ops.', 'Design implement and deploy data loaders to load data into the Engineering Sandbox.', 'Assist in pulling filtering tagging joining parsing and normalizing data sets for use.', 'Work with the analytics translator data quality analyst and IT to resolve data quality issues.', 'Experience in designing and implementing large scale data loading manipulation processing analysis and exploration solutions.', 'Deep technical expertise with pulling and massaging data understanding of first/third party data.', 'Experience in R Python Modeling Big Data etc. with focus on AI/ML techniques', '', 'Advanced SQL skills and understanding of data management principles and processes.', '', '', 'Must Have Skills', '', '', 'Databricks', '', '', 'Good To Have Skills', '', '', 'PySpark', '', 'Azure Databricks', '', 'Azure Data Factory', '', 'eCommerce', '', '', 'Salary and Other Compensation:', '', 'This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.', '', 'Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:', '', '', 'Medical/Dental/Vision/Life Insurance', '', 'Paid holidays plus Paid Time Off', '', '401(k) plan and contributions', '', 'Long-term/Short-term Disability', '', 'Paid Parental Leave', '', 'Employee Stock Purchase Plan', '', '', 'Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.', '', 'Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.', '', 'Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.', '', '#LI-IR1 #CB #Ind123', 'Employee Status :', 'Full Time Employee', 'Shift :', 'Day Job', 'Travel :', 'No', 'Job Posting :', 'Jun 30 2023', 'About Cognizant', ""Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant."", 'Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.', 'Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.', 'If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.']"
