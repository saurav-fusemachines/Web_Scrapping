job_title,company,location,job_type,salary,posted_on,job_qualification,job_description
Data Engineer - Architecture, Vantage Point Consulting - 3.2 ," Houston, TX", Contract, Estimated: $119K - $151K a year, 3 days ago,"['Data mining', 'Data structures', 'Data analysis skills', 'SQL', 'AWS', 'PostgreSQL']","['Location:', 'Chicago or Houston or Remote', '', 'Duration:', '6+ months contract', '', '', 'Job Description:', '', 'United is modernizing the functionality and the user experience to enable the logistical shipment and receiving of parts required for scheduled aircraft maintenance events.', 'This will enable United to have the right parts, at the right place and at the right time to provide maintenance to aircraft.', 'AOG and BMC operate from over 15 stand-alone applications and rely on emails to channel requests and information, which impacts situational awareness and status resulting in delayed decision-making and oversights, that with time are costly to the operation.', 'This project will modernize the experience and provide United with the tools needed to facilitate decisions and provide transparency in tracking where parts are at in the procurement and shipping process.', 'Need someone that has the ability to work in both a technical and functional capacity on the team', 'From a technical standpoint creating a data structure to support the data functions but could control the data aspect. Want them more technical in nature they are able to create an appropriate data structure with multiple inputs and outputs and helping with the data services and pieces', 'Need someone self-sufficient and has experience interacting with the business team to understand the structure of the project', '', '', 'Top Skills', '', 'Data Mining, Architecting and Modeling', 'Highly proficient in SQL and nice to have is comfortable with foundry or frontier', 'Data Analysis and Design Solutions', 'PostgresSQL – Need Experience with AWS', 'Creating the architecture step above a data analysis creating new data structure and architecture', 'Design Solutioning', 'Ability to develop user stories', 'Familiarity with Supply chain Data - Pyramids or branch of supply chain']"
Associate Data Engineer, 48forty Solutions - 2.8 ," Houston, TX", Full-time, Estimated: $66.2K - $83.8K a year, 4 days ago,"['CI/CD', 'Power BI', 'Azure', 'DevOps', 'Spark', 'Test automation', 'Microsoft SQL Server', 'Git', 'SQL', 'Analysis skills', 'Data visualization', '2 years', 'Communication skills']","['48forty Solutions is the largest pallet management services company in North America. We provide end-to-end pallet solutions, from supply to retrieval, on-site services, reverse logistics, and packaging materials. 48forty Solutions is truly Pallet Management Made Simple. Our operations workforce is the heart and soul of our business. We are currently looking for an', 'Associate Data Engineer.', '', 'Summary', '', 'As an Associate Data Engineer, you will be responsible for supporting the design, development, and maintenance of data pipelines and data processing systems using various technologies such as Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Databricks, Azure DevOps, Git, Power BI, Azure Synapse Analytics, and Azure Databricks. You will work under the guidance of more senior data engineers and play a vital role in ensuring the availability, reliability, and scalability of data infrastructure and supporting data-driven initiatives within the organization.', '', 'Essential Duties and Responsibilities', '', '', 'Data pipeline development:', 'Collaborate with the data engineering team to develop and maintain data pipelines, ETL processes, and data integration workflows using Azure Data Factory, Azure Synapse Analytics, Spark SQL, and other relevant technologies. Ensure the timely and accurate movement of data between systems.', '', 'Data processing and transformation:', 'Assist in implementing data processing and transformation logic using Azure Synapse Analytics, Spark SQL or Databricks. Extract insights from raw data and transform it into meaningful and structured formats in our data products.', '', 'Azure service utilization:', 'Work with Azure services such as SQL Server, Azure Data Factory, Azure Synapse and Azure Databricks to build and manage data infrastructure components. Leverage the capabilities of these services to ensure efficient and scalable data processing.', '', 'Version control and collaboration:', 'Utilize Azure DevOps and Git for version control and collaborate effectively with the team to manage code repositories and ensure proper documentation and knowledge sharing.', '', 'Azure DevOps integration:', 'Assist in integrating data engineering workflows with Azure DevOps for continuous integration, continuous deployment, and automated testing. Contribute to the implementation of CI/CD pipelines for data engineering projects.', '', 'Data visualization and reporting:', 'Gain exposure to Power BI and support the team in developing insightful and visually appealing reports and dashboards to communicate data insights effectively to stakeholders.', '', 'Troubleshooting and support:', 'Assist in identifying and resolving data pipeline issues, bottlenecks, and data quality problems. Provide support in investigating and troubleshooting data-related incidents.', '', 'Continuous learning and growth', ': Stay updated with the latest advancements in data engineering technologies and tools. Continuously enhance your knowledge of Azure services and data engineering best practices.', '', '', 'Qualifications and Skills', '', '', '2-5 years of experience in data engineering, data integration, or related roles.', '', 'Hands-on experience with Azure services, including Azure Data Factory, Azure Synapse, and Azure Databricks.', '', 'Proficiency in SQL programming and experience working with SQL Server.', '', 'Familiarity with Spark SQL or Databricks for data processing and transformation.', '', 'Exposure to Git for version control and collaborative development.', '', 'Knowledge of Azure DevOps practices for CI/CD and automated testing.', '', 'Experience with data visualization tools, such as Power BI, for developing reports and dashboards.', '', 'Understanding of Azure Analysis Services and Azure Synapse Analytics is a plus.', '', 'Strong problem-solving skills and attention to detail.', '', 'Good communication and teamwork skills, with the ability to work effectively in a collaborative environment.', '', 'Self-motivated and eager to learn and grow in the field of data engineering.', '', '', 'Work Environment', '', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.', '', '', 'The employee will be working at the corporate office and will be required to sit for long periods of time at a desk working on a laptop.', '', 'The noise level in the work environment is usually moderate.', '', '', 'Benefits', '', '', 'Competitive Pay', '', 'Holiday Pay', '', 'Referral Bonuses', '', 'Long-Term Career Advancement', '', 'Great Team Environment', '', 'PTO', '', 'Full-time employees eligible for Medical, Dental, Vision, Basic Life, AD&D and Short-Term & Long-Term Disability insurance on the 1st of the month following 60 days of employment', '', '', '48forty Solutions', 'is an equal opportunity employer.', 'Privacy Policy', '', 'CA Applicant', '', 'CA Workforce']"
Data Engineer, Informa Tech - 3.0 ," Austin, TX", Full-time, Estimated: $110K - $139K a year, 4 days ago,"['Jira', 'Power BI', 'Visual Basic', 'Kanban', 'C#', 'R', 'Business analysis', 'Alteryx', 'Process improvement', 'Tableau', 'SQL', 'AWS', 'Six Sigma', 'Smartsheet', 'Scripting', 'Rally', 'Scrum', 'VBA', 'Agile', 'Apache', 'Communication skills', 'Python', 'SDLC']","['Company Description', 'Informa Tech informs, educates and connects the technology community through world-class research, training, events and media. A vibrant community of over 1,000 colleagues across 19 locations, we’re dedicated to inspiring the tech community to design better, to build better.', 'Which is why we champion you, the individual, to make an impact through change and innovation. Life at Informa means more freedom and fewer barriers. Our entrepreneurial spirit runs deep, encouraging our team to stick their hands up to spark innovation, or get stuck in to deliver amazing results. It’s time to feel the impact of your work and enjoy making a difference. Are you ready to start your future, today?', '', '', 'Job Description', 'Purpose of Role', 'This Data Engineer is a member of the Data & Analytics Community at Informa Tech and is a unique role among a group of Data Analysts in the Central Data & Analytics team within Informa Tech’s Strategy department. They will develop and maintain solutions to support the collection, storage, enrichment, and delivery of data from across our varied businesses practices. The successful candidate will work with cross-functional teams to help design, build, test, deploy, maintain, and enhance pipelines and tools to improve business data accessibility, quality, transparency, and understandability.', 'Key Responsibilities', 'Developing and maintaining tools, processes, and pipelines needed to successfully (reliably, on time, and at high quality) deliver critical data products from most business data domains (audience development, event registration and sponsorship, client and product—e.g. SalesForce, HR/people, and more) into internal user-facing platforms.', 'Supporting all phases of the software development life cycle, including plan, design, implement, test/integrate/deploy, and maintain', 'Evaluating requests for new datasets by assessing their feasibility, development effort, and value', 'Managing relationships with technical (e.g. data analysts, data product managers, marketing platform admins, other data/technology teams) and business user (e.g. marketing, sales, events, content) stakeholders of all levels, including identifying and resolving risks/issues, prioritizing work, and organizing/attending stakeholder meetings and other communications', 'Acting as an interface between the Informa Tech Data Analytics Community and other data engineering colleagues/teams within Informa Tech and Informa Group.', 'Implementing best practices for data tooling, testing, and implementation; training internal users, coordinating with peers throughout Informa Tech and Informa Group to share knowledge and best practices; participate in relevant data governance processes', 'Regularly soliciting, evaluating, and prioritizing feedback to continuously improve data products and processes', 'Staying up to date on current and emerging industry best practices, tools, and techniques', '', '', 'Qualifications', 'Experience & Qualifications', 'Familiarity with the entire data life cycle', 'Demonstrable success building data pipelines (ingestion, cleansing, and ETL/ELT) with cloud platforms (AWS, Power BI Service—Power Query and data flows/data sets/data marts—any Microsoft Fabric experience a plus, Alteryx, Apache Airflow, etc.)', 'Successful track record in building and maintaining data tools in SQL', 'Experience in scripting/programming languages (e.g., Python, R, VBA, VB.Net, C#, etc.)', 'Familiarity with reporting and visualization tools such as Power BI and Tableau', 'Experience in documenting processes, procedures, and standards', 'Prior experience collaborating with Business Analyst and Product Owner roles to effectively develop products (especially data products) a plus', 'Prior experience working under Agile frameworks (Kanban, Scrum) and familiarity with related tools (Jira, Rally/CA Agile Central, Smartsheet, etc.) a plus', 'Experience and comfort interacting with stakeholders and consumers across the business', 'Process improvement qualification or experience (e.g., Lean/Six Sigma) a plus', 'Academic or professional experience related field(s) (e.g., Data Analytics, Statistics, Software Engineering, Computer Science, Information Technology, Mathematics, Engineering) a plus', 'Knowledge & Skills', 'A genuine affinity for problem solving - having an inquisitive and positive mindset to overcome complex challenges', 'Entrepreneurial spirit – able to constructively question and criticize existing processes, identify potential for new processes, advocate for identified enhancements to convince stakeholders, and proactively pursue execution (including self-organizing with related colleagues)', 'Product-centric mindset (as opposed to project-centric) to deliver value early and continuously, including understanding and embracing the product life cycle', 'Strong attention to detail and proactive in highlighting and resolving errors/issues', 'Communication and presentation skills and ability to collaborate effectively across groups and time zones', 'Additional Information', 'Just as no two days are the same, at Informa Tech we recognise that no two people are the same, putting diversity and inclusivity at the heart of what we do. This doesn’t happen by chance. We actively work to create a shared culture. It’s a place where individuals bring their own experience and insights to discover new opportunities and build a varied career. We want you to thrive as part of a fantastic community. We champion', 'you', '.']"
Lead Big Data Engineer, ITgen systems," Dallas, TX", Contract, $60 - $70 an hour, 4 days ago,"['Azure', 'Spark', 'Apache Hive', 'Software development', 'ETL', 'Agile', '2 years', 'Python', 'Hadoop']","['Job Title: Lead Big Data Engineer', 'Location: Dallas, TX (Hybrid)', 'Duration: 12 Months.', 'Job Description :', 'MUST HAVE', '', '4 Years of Azure – REQUIRED.', '4+ years of', 'Data engineering', 'experience', '4+ years of experience in any or all', 'Big-Data stack', 'such as', 'Hadoop, Hive, Spark, python', '4+ years of Relational data base experience', '4 + years of', 'ETL (Extract, Transform, Load)', 'development experience using any Big-Data technology', '2+ years of', 'Agile', 'software development experience', 'Job Type: Contract', 'Salary: $60.00 - $70.00 per hour', 'Experience:', 'ETL: 3 years (Required)', 'AZURE: 4 years (Required)', 'Agile: 3 years (Required)', 'Data Engineering: 4 years (Required)', 'Hadoop/Hive: 4 years (Required)', 'Work Location: Hybrid remote in Dallas, TX 75201']"
Data Engineer, Medici - 5.0 ," Austin, TX",, Estimated: $104K - $132K a year, 4 days ago,"['Performance tuning', 'Computer science', 'Data modeling', 'Azure', 'Oracle', 'Computer Science', 'Data lake', 'Relational databases', 'Encryption', 'Microsoft SQL Server', 'Google Cloud Platform', 'MongoDB', '3 years', 'SQL', 'AWS', 'Analysis skills', ""Bachelor's degree"", 'PostgreSQL', 'ETL', 'AI', 'Communication skills', 'Data warehouse', 'MySQL']","['Overview', 'Medici is changing the healthcare system by delivering best-in-class preventative and complex condition care that dramatically improves outcomes, provides quick access to care, and significantly reduces medical costs. We’ve been able to accomplish this by providing holistic, AI-infused, comprehensive, and integrated care, Medici helps members become healthier while delivering cost savings to employers.', 'About the role', 'We are seeking an experienced Data Engineer with 3-5 years of hands-on', 'experience in working with PostgreSQL, SQL Server, SQL, and schema design. As a Data Engineer,', 'you will be responsible for managing and optimizing our data infrastructure, ensuring the efficient', 'storage, retrieval, and processing of data. You will collaborate closely with cross-functional teams to', 'design and implement scalable data solutions, enabling data-driven decision-making across the', 'organization.', '', 'Key Responsibilities', 'Data Infrastructure Management: Design, develop, and maintain the data infrastructure, including databases, data pipelines, and ETL processes, to support efficient data storage, retrieval, and processing.', 'Schema Design: Collaborate with data scientists, analysts, and other stakeholders to design database schemas that optimize data retrieval and storage while adhering to industry best practices.', 'Data Modeling: Create and maintain data models and data dictionaries to ensure consistency and standardization across data sources and systems.', 'Performance Optimization: Monitor and fine-tune database performance by identifying and resolving bottlenecks, optimizing queries, and implementing indexing strategies.', 'ETL Development: Develop and maintain scalable Extract, Transform, Load (ETL) processes to ensure data quality, integrity, and timeliness.', 'Data Security: Implement and maintain data security measures, including access controls, data encryption, and compliance with relevant regulations (e.g., GDPR, HIPAA).', 'Data Quality and Governance: Establish data quality standards, perform data profiling, and implement data governance processes to ensure data accuracy, consistency, and completeness.', 'Collaboration and Communication: Collaborate with cross-functional teams, including data scientists, analysts, software engineers, and business stakeholders, to understand data requirements and translate them into technical solutions. Communicate effectively to present complex technical concepts to non-technical stakeholders.', 'Documentation: Document data infrastructure, processes, and technical specifications to ensure knowledge transfer and enable smooth maintenance and troubleshooting.', 'Continuous Learning: Stay up-to-date with emerging technologies, trends, and best practices in data engineering and apply them to improve existing systems and processes.', 'Required Skills and Qualifications', ""Bachelor's degree in Computer Science, Engineering, or a related field."", '3-5 years of professional experience as a Data Engineer or in a similar role.', 'Strong proficiency in working with relational databases, particularly PostgreSQL and SQL Server, including database design, querying, optimization, and performance tuning.', 'Solid understanding of SQL and experience with advanced SQL concepts, such as subqueries, window functions, and stored procedures.', 'Experience with data modeling and schema design, including normalization, denormalization, and indexing strategies.', 'Strong knowledge of ETL processes and tools for data integration, transformation, and loading.', 'Familiarity with data warehouse concepts and technologies (e.g., star schema, data lakes).', 'Understanding of data security principles and experience implementing data security measures.', 'Excellent problem-solving and analytical skills with the ability to work on complex data-related challenges.', 'Strong communication and collaboration skills with the ability to work effectively in a cross-functional team environment.', 'Attention to detail and a commitment to delivering high-quality work.', 'Self-motivated and able to work independently with minimal supervision.', 'Familiarity with other database systems, such as MySQL, Oracle, or MongoDB, is a plus.', 'Knowledge of cloud platforms and services, such as AWS, Azure, or GCP, is a plus.']"
Data Engineer, TDECU - 4.5 ," Sugar Land, TX", Full-time," $106,000 - $140,000 a year", 2 days ago,"['Microsoft Powerpoint', 'Microsoft Word', 'Computer science', 'Microsoft Excel', 'Microsoft Access', 'Azure', 'Data mining', 'Computer Science', '5 years', 'C#', 'Business analysis', 'Visio', 'Information Systems', 'Microsoft Office', 'Java', 'SQL', 'Database design', 'Analysis skills', ""Bachelor's degree"", 'Data management', 'Scripting', 'GitHub', 'SSIS', 'TFS', 'Communication skills', 'Python', 'Master data management', 'T-SQL']","['*NOTICE! YOU MUST BE LOCATED IN THE HOUSTON METRO AREA (TEXAS) TO BE CONSIDERED FOR THIS ROLE*', 'The Data Engineer role will be responsible to analyze raw data, develop and maintain datasets, improve data quality and efficiency, identify business intelligence, reporting, and data analysis needs. They will work closely with end-users and business units to turn data into critical information and knowledge that can be used to make sound business decisions.', 'Essential Duties and Responsibilities:', 'Analyze and organize raw data', 'Build data systems and pipelines', 'Evaluate business needs and objectives', 'Interpret trends and patterns', 'Conduct complex data analysis and report on results', 'Prepare data for prescriptive and predictive modeling', 'Build algorithms and prototypes', 'Combine raw information from different sources', 'Explore ways to enhance data quality and reliability', 'Identify opportunities for data acquisition', 'Develop analytical tools and programs', 'Collaborate with data scientists and architects on several projects', 'Minimum Qualifications:', '', '(Education, Licensure, Experience, Knowledge, Skills, and Abilities)', 'Education:', 'Bachelor’s degree in Computer Science, Information Systems, or related field OR equivalent combination of education and work experience', 'Certifications:', 'Microsoft Azure, Snowflake', 'Experience:', 'A minimum of 5 years experience in Cloud Data platform like Azure, Snowflake, Matillion, Microsoft Integration Services, Reporting Services, business documentation, and T-SQL systems.', 'Experience working with master data management technologies preferred.', 'Experience working with streaming data technologies preferred.', 'Experience in a financial institution preferred.', 'Previous experience as a data engineer or in a similar role', 'Technical expertise with data models, data mining, and segmentation techniques', 'Knowledge of programming languages (e.g. Java and Python)', 'Hands-on experience with SQL database design', 'Great numerical and analytical skills', 'Knowledge, Skills, and Abilities:', 'Working knowledge of Microsoft stack (Azure, Integration Services, Reporting Services, and Analysis Services)', 'C# knowledge for SSIS scripting', 'Competent with MS Office (Word, Excel, PowerPoint, Access, Visio)', 'In depth knowledge of SISS and its capabilities.', 'Knowledge of T-SQL and ANSI SQL stored procedures with multiple parameters.', 'Ability to perform business analysis and documentation.', 'Experience in ADO, GitHub, Team Foundation Server or other source control system.', 'Ability to do data integrity and validation; and manage multiple priorities simultaneously.', 'Excellent written and oral communication skills to Identifies, researches, and resolves technical problem.', 'Ability to work both independently and within teams.', 'Physical Demands and Work Environment:', '(The physical demands and work environment characteristics described herein are representative of those that must be met by an employee to successfully perform essential functions of this position and/or may be encountered while performing essential functions. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.', 'Hybrid General: On average, employees in this role report to a designated TDECU office location 1-2 days per week.', 'Disclaimer:', 'The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.', 'Texas Dow Employees Credit Union is an equal opportunity employer, dedicated to a policy of non-discrimination in employment on any basis including race, color, age, protected veteran status, sex, religion, disability, genetic information, national origin or other status protected by federal, state or local law. Consistent with the American Disabilities Act, applicants may request accommodations needed to participate in the application process.', 'Job Type: Full-time', 'Pay: $106,000.00 - $140,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Employee discount', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Experience:', 'Cloud Data Platforms (Azure, Snowflake, Matillion): 5 years (Required)', 'Azure Stack (Integration, Reporting & Analysis Services: 5 years (Required)', 'Data Engineer: 5 years (Required)', 'Work Location: Hybrid remote in Sugar Land, TX 77478']"
IT Data Engineer, Kelly-Moore Paint Company - 3.6 ," Irving, TX", Full-time, Estimated: $95.4K - $121K a year, 3 days ago,"['ITIL Certification', 'Azure', 'Computer Science', 'Data lake', 'Writing skills', 'Architecture', 'English', 'Tableau', '3 years', 'SQL', 'Database management', ""Bachelor's degree"", 'Scripting', 'APIs', 'IT', 'Communication skills', 'Data Science']","[""Kelly-Moore's mission is to provide high quality, innovative products with exceptional service at fair value. What sets Kelly-Moore Paint Company apart from the competitors, is not just premium products but also our amazing team!"", '', 'FULL TIME - Location:', 'Las Colinas, TX', 'OVERVIEW', 'Kelly-Moore Paint Company’s Information Technology department focuses on delivering effective solutions for employees, customers, and vendors. IT is comprised of talented individuals who cohesively drive effective solution strategies within a balanced ecosystem of systems and support. The Data & GRC Team is focused on fulfilling the business needs for data owners and consumers. Providing data governance guidance and meeting regulatory requirements.', '', 'PRIMARY RESPONSIBILITIES:', '', '', 'Provide day-to-day data processing development and support of existing data automation.', '', 'Manage and support the enterprise master data model, as well as inbound and outbound integrations.', '', 'Assist in the development of master data model architecture.', '', 'As needed develop, implement, and document new data integrations.', '', 'Develop data integrations using APIs and cloud native technologies.', '', 'Develop test plans and perform testing and certification of new and/or updated integrations.', '', 'Perform and document change management in line with ITIL and SDCL best practices.', '', 'Proactively fulfill project tasks with minimal supervision and raise any project gaps discovered.', '', 'Work closely IT and business team members to automate processes.', '', 'Act as subject matter expert on data integrations and data schema.', '', 'Support business intelligence projects, working collaboratively with Tableau team.', '', 'Perform all data handling in compliance with applicable regulatory requirements.', '', 'Maintain knowledge and users training documents relevant to data access, authorization, automation, and control.', '', 'Develop new projects as business need arise and document business requirements.', '', 'Perform other duties as assigned.', '', '', 'QUALIFICATIONS:', '', '', '3+ years of progressive experience data processing and/or data integration. Bachelor’s degree in information technology, data science, or equivalent experience.', '', 'Basic level knowledge of scripting languages.', '', 'Intermediate level knowledge of transact SQL or equivalent structured query language.', '', 'Knowledge of on-premises and cloud-based data processing and database systems.', '', 'Azure data lake/factory experience preferred.', '', 'Strong English writing and communication skills in a professional setting.', '', 'Ability to collaborate effectively with cross functional teams.', '', 'Self-motivated with the ability to work autonomously, effectively prioritize and manage multiple concurrent tasks and projects.', '', '', 'REQUIREMENTS:', '', '', 'Experience in database management and business process automation.', '', 'Database management or data science certifications or equivalent experience.', '', 'CompTIA Data+ or Microsoft Certified: Azure Data Engineer Associate a plus.', '', 'ITIL Foundation certification a plus.', '', 'Perform duties on site in Las Colinas 3 days per work week.', '', 'Kelly-Moore provides equal opportunity in all terms and conditions of employment. We will not discriminate against qualified applicants or employees with respect to any terms or conditions of employment because of any basis protected by federal, state, local law including race, color, religion, religious dress or grooming practice, national origin, sex, age, marital status, physical and mental disability, medical condition, veteran status, sexual orientation, gender identity, gender expression, and genetic information.']"
Data Engineer, Southwestern Energy (SWN) - 4.0 ," Spring, TX", Full-time, Estimated: $100K - $127K a year, 4 days ago,"['Power BI', 'Oracle', 'Management', 'Computer Science', '5 years', 'Bachelor of Science', 'R', 'Microsoft SQL Server', 'Information Systems', 'Tableau', 'Databases', 'Analysis skills', ""Bachelor's degree"", 'System testing', 'Scripting', 'Software development', 'APIs', 'ETL', 'SSIS', 'Informatica', 'Python']","['Southwestern Energy', 'is searching for a', 'Data Engineer', 'to join our Corporate IT team.', 'You will analyze user needs and develop solutions to support data science workflows, data and application integrations, analytics platforms, or specialized utility programs with the aim of optimizing operational efficiency while adhering to appropriate data quality and data governance principles. You will work individually and coordinate database development as part of a team and lead small to medium projects and assists on large projects. Functions as primary support for all solutions in one or more discipline(s) and secondary support for multiple solutions in related disciplines. You will report to the BIS Manager and the position is located at our headquarters in Spring, TX.', 'To be successful in this role you will:', 'Write, analyze, review, and rewrite programs, using workflow charts and diagrams, and applying knowledge of computer capabilities, subject matter, and symbolic logic.', 'Perform revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements.', 'Analyze user needs and software requirements to determine feasibility of design within time and cost constraints.', 'Confer with systems analysts, engineers, programmers and others to design systems and to obtain information on project limitations and capabilities, performance requirements and interfaces.', 'Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program.', 'Develop and perform software system testing and validation procedures.', 'Store, retrieve, and manipulate data for analysis of system capabilities and requirements.', 'Analyze information to determine, recommend, and plan installation of a new system or modification of an existing system.', 'Coordinate software system installation and monitor equipment functioning to ensure specifications are met.', 'Consult with engineering staff to evaluate interface between hardware and software, develop specifications and performance requirements, or resolve customer problems.', 'Confer with data processing or project managers to obtain information on limitations or capabilities for data processing projects.', 'Participate in on-call and after-hours support, including weekends and holidays.', 'Lead medium projects as defined by scope', 'Qualifications - External', 'Your Background includes:', 'Bachelor of Science degree in computer science, engineering, or management of information systems is preferred.', 'Minimum of 5 years of software development experience', 'Experience creating dashboards and analysis using tools such as Microsoft PowerBI, TIBCO Spotfire, Tableau, etc. is required.', 'Experience querying and developing Oracle and Microsoft SQL Server databases is required.', 'Experience integrating data using ETL technologies such as Informatica, Dell Boomi, Microsoft SSIS/DTS, etc. is required.', 'Experience integrating applications using APIs and scripting languages. Python/R is a plus.', 'Knowledge of WellView, SiteView, Enertia, and other upstream oil and gas systems is a plus.', 'Ability to communicate ideas in both technical and user-friendly language', 'Strong customer focus mindset', 'Job Type: Full-time', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Schedule:', 'Monday to Friday', 'Ability to commute/relocate:', 'Spring, TX 77389: Reliably commute or planning to relocate before starting work (Required)', 'Work Location: In person']"
Data Center Lead Engineer, Iron Systems - 3.2 ," Richardson, TX",, Estimated: $98.2K - $124K a year, 4 days ago,,"['Date Posted:', '', '7/5/2023', '', 'Job Function:', '', 'Software Development', '', 'Location:', '', 'Richardson TX - USA', '', 'Offered Salary:', '', 'Competitive']"
Data Engineer, RumbleOn - 4.4 ," Irving, TX", Full-time," $115,000 - $125,000 a year", 3 days ago,"['Data modeling', 'Azure', 'Computer Science', 'Kubernetes', '5 years', 'Spark', 'NoSQL', 'Google Cloud Platform', 'Java', ""Master's degree"", 'Databases', 'SQL', 'AWS', 'Docker', ""Bachelor's degree"", 'Distributed systems', 'Scala', 'Terraform', 'Scripting', 'Apache', 'Kafka', 'Unit testing', 'Business requirements', 'Data warehouse', 'Python', 'Kitchen experience', 'Hadoop']","['As a Senior Data Engineer, you will be responsible for architecting, building, and maintaining scalable data infrastructure to support our data-driven initiatives. You will collaborate closely with cross-functional teams, including analysts, stakeholders, and software engineers, to design and implement data solutions that meet business requirements. Your expertise will be essential in ensuring data integrity, performance, and security while optimizing data processes for efficiency and scalability.', 'Responsibilities:', '', 'Design, develop, and maintain data infrastructure, including data pipelines, ETL processes, and data warehouses, to support data-intensive applications, analytics, and business intelligence.', '', 'Collaborate with stakeholders to gather data requirements and translate them into scalable data solutions.', '', 'Identify, evaluate, and implement appropriate tools and technologies for data ingestion, storage, processing, and analysis.', '', 'Ensure the reliability, availability, and performance of data platforms through monitoring, troubleshooting, and optimization.', '', 'Develop and enforce data governance policies, including data quality standards, privacy, and security protocols.', '', 'Lead and mentor junior data engineers, providing technical guidance and fostering a culture of continuous learning and improvement.', '', 'Collaborate with cross-functional teams to understand data needs and design efficient data models, schemas, and data transformation processes.', '', 'Stay up-to-date with industry trends, emerging technologies, and best practices in data engineering and recommend enhancements to existing systems and processes.', '', 'Participate in code reviews, perform unit testing, and maintain documentation to ensure code quality, maintainability, and knowledge sharing.', '', 'Proactively identify and resolve performance bottlenecks, data issues, and technical challenges related to data processing and storage.', '', 'Requirements', '', ""Bachelor's degree in Computer Science, Engineering, or a related field. A Master's degree is a plus."", '', 'Proven experience (5+ years) as a Data Engineer or similar role, with a strong focus on building scalable data infrastructure.', '', 'Strong proficiency in data modeling, data warehousing concepts, and SQL.', '', 'Expertise in designing and implementing data pipelines, ETL processes, and workflow orchestration using tools such as Apache Airflow, AWS Glue or similar.', '', 'Proficiency in programming languages such as Python, Java, or Scala for data processing and scripting.', '', 'Solid understanding of distributed systems, cloud platforms (e.g., AWS, Azure, GCP), and big data technologies (e.g., Hadoop, Spark, Kafka).', '', 'Experience with data integration and streaming technologies, such as AWS Kinesis Data Streams/Firehose, Apache Nifi, or similar.', '', 'Strong knowledge of database technologies (e.g., SQL databases, NoSQL databases, columnar databases).', '', 'Familiarity with containerization (e.g., Docker, Kubernetes) and infrastructure-as-code tools (e.g., Terraform) is a plus.', '', 'Excellent problem-solving skills, attention to detail, and the ability to work in a fast-paced, dynamic environment.', '', 'Benefits', 'What RumbleOn Offers You:', ""A fun, relaxed, and casual work environment with awesome people by your side working as a team to ensure the entire group's success! Plus..."", '', 'Healthcare, Dental, & Vision Insurance (RumbleOn pays a generous portion of medical premium!)', '', 'PTO Plan & Public Holidays Off', '', 'Close knit, open, inviting environment where you can make your mark and where your ideas are heard!', '', 'Employee discounts on purchases', '', 'Extremely competitive compensation packages commensurate with experience and skillset', '', 'Fully stocked kitchen with drinks and snacks all day', '', 'Fun company events', '', 'The opportunity for growth and a solid long term career...we promote from within!!', '', 'Casual Dress code', '', 'Training and full support while you learn', '', 'And more…', '', '*All applicants must pass pre-employment testing to include: background checks, MVR, and drug testing in order to qualify for employment*·']"
Data Engineer only W2, IDC," Houston, TX", Contract, Estimated: $113K - $142K a year, 4 days ago,"['Kubernetes', 'Data structures', 'Spark', 'Java', 'AWS', 'APIs', 'ETL', 'Apache']","['· The job function of a Java Spark Databricks AWS data engineer involves working with data engineering technologies and platforms to design, develop, and maintain data solutions on the AWS cloud platform. Here are some key responsibilities and tasks associated with this role:', '·', 'Data Ingestion:', 'Develop and implement processes to extract data from various sources, such as databases, APIs, and files, and load it into the data lake or data warehouse using Java, Spark, and AWS tools.', '·', 'Data Transformation:', 'Perform data cleansing, validation, and transformation using Spark and Java programming, ensuring data quality and consistency. Apply business rules and data processing techniques to prepare the data for analysis and consumption.', '·', 'Data Pipeline Development:', 'Design and build scalable data pipelines using AWS services like AWS Glue, AWS Data Pipeline, or Apache Airflow. Develop ETL (Extract, Transform, Load) processes to move and transform data between different systems and data stores.', '·', 'Data Modeling:', 'Create and maintain data models and schemas, including dimensional and relational models, to support data storage and retrieval requirements. Optimize data structures for performance and efficiency.', '·', 'Performance Optimization:', 'Fine-tune Spark applications and data processing workflows to improve performance and reduce processing time. Optimize resource utilization, data partitioning, and data caching strategies.', '·', 'Data Security and Governance:', 'Implement data security and access controls to ensure data privacy and compliance with regulatory requirements. Apply data governance practices to manage metadata, data lineage, and data cataloging.', '·', 'Monitoring and Troubleshooting:', 'Monitor data pipelines and Spark jobs for performance, errors, and issues. Troubleshoot and resolve data-related problems, such as data quality issues or performance bottlenecks.', '·', 'Collaboration and Documentation:', 'Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver data solutions. Document data pipelines, processes, and system configurations.', 'Job Type: Contract', 'Ability to commute/relocate:', 'Houston, TX 77001: Reliably commute or planning to relocate before starting work (Preferred)', 'Experience:', 'data engineer: 6 years (Preferred)', 'Java/Spark/Databricks/Kubernetes: 5 years (Preferred)', 'Work Location: In person']"
"No C2C/ Only W2/1099 - Lead Big Data Engineer - Charlotte, NC, MN, TX", BIGCLFY," Dallas, TX", Contract, From $72 an hour, 4 days ago,"['Azure', 'HDFS', 'Big data', 'Spark', 'Apache Hive', 'SQL', 'CPT coding', 'Software development', 'ETL', 'Agile', 'Kafka', '2 years', 'Python', 'Hadoop']","['No C2C / No Corp to Corp', 'W2 Requirement / Direct Client Requirement :', '·', 'Only taking USC, GC or H4 EAD, L2 Visa or TN Visa', '- they', 'will not take', 'OPT EAD or CPT', 'Lead Big Data Engineer', 'Charlotte, NC, Minneapolis, MN or Dallas, TX (Hybrid) – hybrid onsite', '12+ months', 'We will transfer Visas and process GCs', '6+ years in Big Data Engineering with at least 1 year as a lead', 'Must be hands on within the following:', 'HDFS, Hive, Spark, Python, Kafka, SQL', 'Must be able to work hybrid onsite – this is not a remote role', 'MUST HAVE', '4 Years of Azure – REQUIRED', '4+ years of Data engineering experience', '4+ years of experience in any or all Big-Data stack such as Hadoop, Hive, Spark, python', '4+ years of Relational data base experience', '4 + years of ETL (Extract, Transform, Load) development experience using any Big-Data technology', '2+ years of Agile software development experience', 'Hands-on experience with', 'Job Type: Contract', 'Pay: From $72.00 per hour', 'Schedule:', '8 hour shift', 'Ability to commute/relocate:', 'Dallas, TX 75201: Reliably commute or planning to relocate before starting work (Preferred)', 'Application Question(s):', 'Expected payrate on W2 or 1099? Please suggest.', 'Experience:', 'Lead: 1 year (Preferred)', 'Software Industry Big Data Engineering: 7 years (Preferred)', 'Work Location: In person']"
"Customer Engineer, Data and Analytics, Public Sector", Google - 4.3 ," Austin, TX", Full-time,, 2 days ago,"['Computer science', '6 years', 'Management', 'Computer Science', 'Data lake', 'Big data', 'Load balancing', ""Master's degree"", ""Bachelor's degree"", 'Virtualization', 'Product demos', 'Warehouse experience', 'Cloud computing', 'Linux', 'SAP BusinessObjects', 'Informatica', 'Data warehouse', 'Technical sales', 'VPN']","['Note: By applying to this position you will have an opportunity to share your preferred working location from the following:', 'Austin, TX, USA; Boulder, CO, USA; Addison, TX, USA', '.', 'Minimum qualifications:', '', ""Bachelor's degree in Computer Science, a related technical field, or equivalent practical experience."", '', '', '6 years of experience in virtualization or cloud native architectures in a customer-facing or support role.', '', '', 'Experience in cloud computing (e.g., cloud market) and delivering technical presentations.', '', '', 'Experience in analytic warehouse solutions, Big Data technologies, real-time streaming, performance, and scalability optimizations.', '', 'Preferred qualifications:', '', ""Master's degree in Computer Science or a related technical field."", '', '', 'Experience with Public Sector client groups including state and local government.', '', 'Experience in developing data warehousing, data lakes, batch, or real-time event processing and Exact Transform and Load (ETL) workflows solutions (e.g., Informatica, Talend, Alooma, SAP, Data Services).', '', '', 'Experience in technical sales in the field of cloud computing, data, information lifecycle management, and Big Data.', '', '', 'Knowledge of Linux.', '', '', 'Ability to address domain name systems, transmission control protocol, firewalls, proxy servers, load balancing, virtual private networks, and virtual private cloud.', '', 'About the job', ""The Google Cloud Platform team helps customers transform and build what's next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customers — developers, small and large businesses, educational institutions and government agencies — see the benefits of our technology come to life. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees and partners."", '', 'As a Customer Engineer, you will work with the Sales team to introduce Google Cloud to our customers. You will help prospective and existing customers and partners understand Google Cloud, develop creative cloud solutions and architectures to solve their business issues and problem-solve any potential roadblocks.', 'Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.', 'Additional Information:', 'The US base salary range for this full-time position is $139,000-$213,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.', 'Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.', 'Responsibilities', '', 'Work with the team to identify and qualify business opportunities, identify key customer technical objections, and develop a strategy to resolve technical blockers.', 'Manage the technical relationship with Google customers (e.g., managing product and solution briefings, proof-of-concept work, and the coordination of additional technical resources).', 'Work with customers to demonstrate and prototype Google Cloud product integrations in customer and partner environments.', 'Prepare and deliver product messaging in an effort to highlight the Google Cloud Platform value proposition, using techniques that include presentations, product demonstrations, white papers, and request for information response documents.', '', 'Travel to customer sites, conferences, and other events as needed.', '', ""Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.""]"
Data Analytics Engineer II, Fujitsu - 3.6 ," Richardson, TX",, Estimated: $93.2K - $118K a year, 2 days ago,"['Power BI', 'TCP', 'Cloud infrastructure', 'Azure', 'Operating systems', 'Go', 'Kubernetes', 'RESTful API', 'Customer service', 'LAN', 'Windows', 'Java', 'Database design', 'JavaScript', 'Virtualization', 'Perl', 'BGP', 'REST', 'Data analytics', 'MPLS', 'Linux', 'TCP/IP', 'Communication skills', 'Python', 'SDLC']","['Fujitsu at a Glance', 'Fujitsu is a leading information and communication technology (ICT) company, headquartered in Japan, offering a full range of technology products, solutions, and services. Approximately 132,000 Fujitsu people support customers in more than 100 countries. We use our experience and the power of ICT to shape the future of society with our customers.We are a corporate culture that places great value on the pursuit of new possibilities previously unimagined and brings them to fruition has been the foundation of the Fujitsu’s success since its inception. In an increasingly competitive world, in which the pace of change continues to accelerate, Fujitsu must strive for continuous innovation. Each and every employee will rise to the challenge of creating new value amid changes in the management environment, technology, society and the marketplace. With a spirit of challenge, we are committed to the continuous creation of new value. Fujitsu wants innovators like you!', 'Data Analytics Engineer II', 'Corporate Overview', 'Fujitsu Network Communications, Inc., is a trusted partner to a broad spectrum of customers across all industries, enabling them to realize the maximum value from their communications networks. We are a market-leading U.S.-based manufacturer of network equipment and a top U.S. patent holder in optical networking. Our solutions combine the best wireline, wireless, and software technology with extensive multivendor services expertise to deliver custom, end-to-end network integration, and management solutions. For more information, please see http://us.fujitsu.com/telecom, connect with us on LinkedIn at www.linkedin.com/company/fujitsu-network-communications, and follow us on Twitter @FujitsuFNC.', 'Job Description', 'Service Operations & Maintenance is looking for an experienced Data Analytics Engineer with advanced skillsets in data analyzing, software applications, and development methodologies. The selected candidate must demonstrate a good understanding of SDLC and also drive and support several data automation, software automation, and visualization initiatives. Deployed solutions may include Fujitsu products and/or 3rd party vendor products. Candidate must have excellent customer service soft skills and be able to work in a fast-paced environment.', 'Accountabilities', 'Data visualization, data engineering, and support integration and automation projects using Python/java/PowerBI and REST APIs', 'Help define policies, procedures, system requirements, and design solutions', 'Support onboarding and connectivity of devices for NOC customers', 'Monitor and report on network performance and health (availability, utilization, throughput, goodput, and latency)', 'Support OSS service assurance team with writing code to optimize and related software automation efforts', 'Develop, document, and execute validation test plans on hardware, software, and operating system', 'Experience with system engineering activities such as feature requirements identification, feature description documentation, parameter optimization, performance analysis, test strategy creation, and problem troubleshooting is desirable', 'Qualifications', 'Required', 'Strong programming knowledge and skills – python, java', 'Cloud infrastructure knowledge – MS Azure, AWS others', 'Knowledge of database design', 'Knowledge and experience with VM and container technologies and Kubernetes', 'Ability to work with multiple teams including vendors/clients in escalating/resolving possible security-related issues', 'Perform data audit, SWFW audit, and health check of the OSS', 'Strong interpersonal and verbal communication skills and experience working with cross-functional teams', 'Nice to have', 'Linux and virtualization background a plus', 'Experience with Java, JavaScript, Python, Go, Perl, Windows and Linux', 'Good understanding of networking in the TCP/IP LAN/WAN (MPLS, BGP, SIP, DMVPN, and SD-WAN) environment', 'At Fujitsu, one of our corporate principles is ""We respect human rights."" This principle underpins our corporate and individual activities and guides the actions of every Fujitsu Group member. We embrace diversity and equal opportunity. Qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. By empowering people, we can unleash our collective strengths to create a better experience for our employees, our customers, and our partners.', 'California Privacy Act: https://www.fujitsu.com/us/Images/CALIFORNIA-CONSUMER-PRIVACY-ACT-NOTICE.pdf']"
Senior Data Engineer, Invesco - 3.9 ," Dallas, TX", Full-time, Estimated: $116K - $147K a year, 3 days ago,"['Investment', 'Power BI', 'Microsoft SQL Server', 'SQL', 'AWS', 'Analysis skills', 'Project management', 'PostgreSQL', 'Scripting', 'ETL', 'Agile', 'IT', '4 years', 'Communication skills', 'Banking', 'Python', 'MySQL', 'SDLC']","[""As one of the world's leading asset managers, Invesco is dedicated to helping investors worldwide achieve their financial objectives. By delivering the combined power of our distinctive investment management capabilities, we provide a wide range of investment strategies and vehicles to our clients around the world."", ""If you're looking for challenging work, smart colleagues, and a global employer with a social conscience, come explore your potential at Invesco. Make a difference every day!"", 'Job Description', 'Your Team', 'Our mission is to create world-class, client-centric technology solutions that drive competitive advantage, grow our global business, and deliver an investment experience that helps people get more out of life. This mission is fueled by inventive and cohesive teams, which thrive on collaboration and shared trust and demonstrate the diversity of thought. Our success is driven by our people, which is why we invest heavily in our talent, promoting continuous learning and development, offering opportunities to work with emerging technologies, and creating the space to discover.', 'Our high-performing, OneTech team is seeking candidates who innovate, operate effectively in an agile environment, challenge the status quo and are driven to succeed.', 'Your Role', ""We are seeking a Sr. Engineer who will be responsible for participating in the build out, maintenance, and support of Invesco Real Estate's data and analytics platform. The Senior. Engineer will work with business representatives, project managers and architects understand the requirements, assist with formulation of technical designs, and implement and test the solutions to ensure compliance to requirements and technical standards. This role may also at times provide development support to production databases and reports."", '', 'You Will Be Responsible For:', 'Design and Develop enterprise grade reporting solutions according to business requirements and challenges', 'Provide maintenance/support for existing and new Power BI Dashboards and Paginaged reports for Real Estate domain', 'Build and scale existing snowflake and airflow environments while migrating from on-prem data solutions', 'Data Analysis and quality testing to ensure accuracy of all report metrics on visualizations', 'Collaborate with other enterprise teams and off shore data engineering team on project deliverables', 'Create documentation including functional/technical specifications and training guides', 'Exercise judgment and discretion in software development and work assignments by prioritizing, planning, and tracking project progress', 'Proactively look for modernizing, enhancing, and extending technical solutions wherever there is high value and benefit to business teams', 'Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes', 'Utilize both Agile and traditional project management principles and practices', '', 'The Experience You Bring:', 'Knowledge on Real Estate & Banking (Mortgage) domain and related processes is a PLUS', 'Thorough knowledge on SDLC processes in conjunction with agile project management principles', '6+ years of IT experience primarily designing and building dabases within any SQL database technology (SQL server, PostGres, MySQL etc)', '5+ years of enterprise level Power BI Dashoards and Reports development', '4+ years of experience with AWS Cloud services and technologies ( AWS )', '4+ years of experience with developing ETL pipelines within Airflow (MWAA)', '4+ years of experience with Snowflake environment', 'Good experience with Automation scripting using Python is a PLUS', 'Ability to quickly learn new technologies and apply them those concepts to enhance application capabilities', '', 'Skills / Other Personal Attributes Required:', ""You can bring clarity to chaos and you're comfortable working with ambiguity (e.g. imperfect data, loosely defined concepts, ideas, or goals) and translating these into more tangible outputs"", 'Strong analytical and critical thinking skills', 'Strong written and verbal communication skills', 'Enjoy challenging and thought-provoking work and have a strong desire to learn and progress', 'Ability to manage multiple tasks and requests', 'You listen to the input of your team members and take diverse perspectives into account to approach challenges from multiple angles', 'Structured, disciplined approach to work, with attention to detail', 'Flexible - able to meet changing requirements and priorities', 'Maintenance of up-to-date knowledge in the appropriate technical areas', 'Able to work in a global, multicultural environment', 'Full Time / Part Time', 'Full time', 'Worker Type', 'Employee', 'Job Exempt (Yes / No)', 'Yes', 'Workplace Model', 'At Invesco, our workplace model supports our culture and meets the needs of our clients while providing flexibility our employees value. As a full-time employee, compliance with the workplace policy means working with your direct manager to create a schedule where you will work in your designated office at least three days a week, with two days working outside an Invesco office.', ""What's in it for you?"", 'Our people are at the ver y core of our success. Invesco employees get more out of life through our comprehensive compensation and benefit offerings including:', 'Flexible time off and opportunities for a flexible work schedule', '401(K) matching of 100% up to the first 6% with additional supplemental contribution', 'Health & wellbeing benefits', 'Parental Leave benefits', 'Employee stock purchase plan', 'The above information on this description has been designed to indicate the general nature and level of work performed by employees within this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The job holder may be required to perform other duties as deemed appropriate by their manager from time to time.', ""Invesco's culture of inclusivity and its commitment to diversity in the workplace are demonstrated through our people practices. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender, gender identity, sexual orientation, marital status, national origin, citizenship status, disability, age, or veteran status. Our equal opportunity employment efforts comply with all applicable U.S. state and federal laws governing non-discrimination in employment.""]"
Technical Data Engineer, Bell Textron Inc. - 3.9 ," Fort Worth, TX", Full-time,, 6 days ago,"['Microsoft Powerpoint', 'Microsoft Word', 'Microsoft Excel', 'Engineering', 'Configuration management', 'Microsoft Office', ""Bachelor's degree"", 'Data management', 'Organizational skills', '2 years', 'Product lifecycle management']","['Technical Data Engineer', '315101', 'We’re more than aviation experts, we’re pioneers. We challenge what’s possible. From breaking the sound barrier to developing the tiltrotor, we’ve reimagined the experience of flight for more than 85 years. Today, we’re redefining what flight is capable of.', '', 'Bell, a leader in aerospace and defense industry has an opening for an experienced', 'Technical Data Engineer', ""to work on new and innovative projects. This position will be located at Bell's Commercial Business Center in Fort Worth, TX."", '', 'Responsibilities', ':', '', '', 'Review program engineering configuration control methodology and variances in the Product Lifecycle Management (PLM) environment (ENOVIA) and provide specific direction to data owners that will prevent process or system issues and to ensure proper standards and quality are established and maintained', '', 'Conduct assessments of feature or functionality and compare to the enterprise policies and procedures documentation.', '', 'Research, understand, advocate and be responsible for compliance of regulations, standards, doctrines related to engineering, procurement, and production PLM systems.', '', 'Ensure that the application development, database, technical, security and general IT architecture interests are considered and engagement with the respective architects occurs for all solutions.', '', 'Perform reviews to assess options, gain agreement of solutions, and ensure choices are made and deviations from standards are properly identified, addressed and documented.', '', 'Document architecture, design choices, and requirements related to systems, processes, and data management.', '', 'Monitor engineering release and provide appropriate and compliant data submittals to requesting or contracting customers.', '', 'Analyze assigned program Feature/Configuration Item (CI) structure in ENOVIA and their related data and documentation elements', '', 'Analyze data to make recommendations that aid program and functional leadership to plan work, understand data flow, and reduce schedule impacts.', '', 'Coordinate with cross-functional teams to resolve issues and provide specific direction to data owners to ensure compliance.', '', 'Coordinate with contracts organization and customers regarding new or changing requirements.', '', 'Establish and maintain good working relationships with internal Bell and external customers (USG, regulatory agencies, partners, OEMs, and suppliers).', '', 'Monitor the stability and health of the Engineering Bill-of-Material and Planning Bill-of-Material for the assigned program and provide feedback to data owners regarding data issues.', '', 'Manage Contract Data Requirements List (CDRL) and Data Item Deliverable (DID) requirements.', '', 'Determine and apply the proper data marking to deliverable information.', '', 'Manage engineering data correction, consolidation, or system migration.', '', '', 'Educational Requirements:', '', '', 'Bachelor’s degree in engineering', 'Certification in configuration management is preferred', '', '', 'Position Requirements:', '', '', 'At least 2 years’ experience working with engineering data and data systems', '', 'Proficiency in Microsoft Office (Word, Excel and PowerPoint) is required and can learn new software.', '', 'Good interpersonal and organizational skills.', '', 'Ability to work effectively within a team.', '', 'Ability to prioritize a variety of assignments.', '', '', 'Ideal Candidates Also Have:', '', '', 'Prior experience working with PDM/PLM experience.', '', 'Familiarity with ENOVIA.', '', 'Familiarity with data management software, and document imaging software.', '', 'Practical and working knowledge of the International Traffic in Arms Regulations (ITAR), Export Administration Regulations (EAR) and associated markings.', '', 'Basic understanding of roles, tasks, policies and procedures required to execute the change process, configuration management, data management, and product-related data maintained in the ENOVIA environment.', '', 'Familiarity with the Configuration Management principles and methods contained in ANSI/EIA‑649B, ISO 10007, and MIL-HDBK-61A.', '', 'Familiarity with the Data Management principles and methods contained in DI-SESS-81000E, DoD Directive 5230.24, and MIL-STD-31000A.', '', 'Bell will consider candidates nationally; however, this position does not offer relocation assistance.', '', 'You have the unique opportunity to join a different kind of team; one that is focused on pushing boundaries, one that advocates for our customers by presenting them with the very best and by cultivating a culture of inclusivity and excitement for what’s ahead.', '', 'We’re an award-winning organization with a legacy of reliability, precision, and exceeding expectations. Be on the forefront of flight technology and join our team', 'EEO Statement', 'Textron is committed to providing Equal Opportunity in Employment, to all applicants and employees regardless of, race, color, religion, gender, age, national origin, military status, veteran status, handicap, physical or mental disability, sexual orientation, gender identity, genetic information or any other characteristic protected by law.', '', ""This position requires use of information which is subject to the International Traffic in Arms Regulations (ITAR) and/or the Export Administration Regulations (EAR)., Non-U.S. persons selected must meet eligibility requirements for access to export-restricted information. , The ITAR/EAR defines a U.S. person as a U.S. Citizen, U.S. Permanent Resident (i.e. 'Green Card Holder'), Political Asylee, or Refugee."", 'Recruiting Company', 'Bell Textron Inc.', 'Primary Location', 'US-Texas-Fort Worth', 'Job Field', 'Engineering', 'Schedule', 'Full-time', 'Job Level', 'Individual Contributor', 'Shift', 'First Shift', 'Job Posting', '07/03/2023, 11:39:04 AM', 'Relocation', 'Unavailable']"
"Senior Software Engineer, Full Stack (Enterprise Data)", Capital One - 3.9 ," Plano, TX",,, 1 day ago,"['Node.js', 'Software Engineering', 'Kubernetes', 'Full-stack development', 'NoSQL', 'AWS', 'Docker', ""Bachelor's degree"", 'JavaScript', 'Agile', '2 years', 'Python']","['Plano 1 (31061), United States of America, Plano, Texas', 'Senior Software Engineer, Full Stack (Enterprise Data)', ""Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking"", '', 'Full Stack Software Engineers', '', 'who are passionate about marrying data with emerging technologies. As a Capital One Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.', 'In this role, you will be supporting an enterprise wide data management initiative and data governance application for managing digital assets including datasets, datastores, and applications that are owned by various organizations across Capital One. The application will be the centralized repository of metadata that will facilitate the navigation, discovery, and change management of digital assets. Engineers on this team will support data use, file transfer, and data retention functionalities for the application while prioritizing data security and compliance.', 'What You’ll Do:', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Utilize programming languages like Python, JavaScript, and Node.js, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services', 'Basic Qualifications:', 'Bachelor’s Degree', 'At least 4 years of experience in software engineering (Internship experience does not apply)', 'Preferred Qualifications:', '5+ years of experience with Python', '3+ years of experience with AWS', '3+ years of experience in open source frameworks', '2+ years of experience in Agile practices', 'At this time, Capital One will not sponsor a new applicant for employment authorization for this position.', 'Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.', 'No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.', 'If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.', ""For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com"", 'Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.', 'Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).']"
Field Engineer – Audio Visual and Data Networks, ELB US Inc.," Dallas, TX", Full-time," $70,000 - $95,000 a year", 6 days ago,"['Microsoft Office', ""Bachelor's degree"", '4 years', 'Communication skills']","['ELB US Inc. is a world class integrated solutions provider, specializing in visual collaboration and unified communication services and solutions. We strive to create high quality integrated solutions for all our enterprise, government and education customers. At ELB we create experiences, we communicate ideas, and we collaborate across the world!', 'We are currently recruiting for a', 'Field Engineer – Audio Visual and Data Networks.', 'As a Field Engineer, you will configure, commission, and test hardware and software for full system operation of audio-video systems and networks. You will work with the Project Teams to provide full system functionality and ready projects for completion. In this role, you will get to work on high quality, high profile, national and international projects.', 'Key Responsibilities include, but are not limited to:', 'Provision of audio visual systems control programming services, including design and implementation', 'On site loading of programs, testing and commissioning. This includes any required rectification works – cabling, terminations etc', 'On site installation and integration of Audio Visual components including any rack building.', 'Offsite programming and support for remote locations when necessary', 'Consult with clients and colleagues as required regarding audio visual (AV) requirements.', 'Assess briefs provided by customers and/or Account Managers/Business Development Managers and identify options for potential solutions and assess them for both technical and business suitability.', 'Develop logical and innovative AV solutions to complex problems, ensuring that AV system designs meets customer business requirements.', 'Assist Project Managers where necessary with planning the installation of systems.', 'Assist with commissioning and troubleshooting of audio visual systems, including control systems and DSP platforms', 'Qualifications:', 'Possess a four-year degree, or equivalent combination of education and related work experience in the Professional Audio, Professional/Broadcast Video, Audio Visual, Security, or Data Integration fields.', 'A minimum of four years’ experience as a Field or Commissioning Engineer with an AV Integrator.', 'Extensive, hands-on experience with configuration of Audio DSP, Video Routing systems, Video Wall Processors, Display Calibration and Configuration, and Audio Room Tuning.', 'Industry and Manufacturer Certifications, such as Biamp Tesira, latest Crestron DM and NVX,QSC Q-SYS, etc. are required.', 'Knowledge of Crestron Tool Box and AMX Netlinx Studio. NOTE – Control Programming skills are a very strong plus, but are not explicitly mandatory.', 'Direct, hand-on experience with signal testers and analyzers, particularly Fluke DSX-5000 or similar.', 'Excellent verbal and written communication skills with an emphasis on the ability to organize and present designs to clients is a must. Must be proficient in Microsoft Office software.', 'Extensive knowledge of open architecture Audio Digital Signal Processor configuration and commissioning.', 'Job Type: Full-time', 'Pay: $70,000.00 - $95,000.00 per year', 'Benefits:', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Experience level:', '4 years', 'Schedule:', '8 hour shift', 'Monday to Friday', 'Ability to commute/relocate:', 'Dallas, TX 75238: Reliably commute or planning to relocate before starting work (Preferred)', 'Education:', ""Bachelor's (Preferred)"", 'Experience:', 'Field or Commissioning Engineer with an AV Integrator: 4 years (Preferred)', 'Willingness to travel:', '25% (Preferred)', 'Work Location: Hybrid remote in Dallas, TX 75238']"
Product Data Engineer Technician II, Mouser Electronics - 3.1 ," Mansfield, TX",, Estimated: $58.6K - $74.2K a year, 6 days ago,"['Microsoft Powerpoint', 'Microsoft Word', 'Microsoft Excel', 'System design', 'Windows', 'Electrical engineering', 'Taxonomy', 'Analysis skills', ""Bachelor's degree"", 'Product management', 'Organizational skills', 'Electrical Engineering', '2 years']","['The mission of the Product Data Group is to provide the most accurate and complete data for design engineers sourcing electronic components on Mouser.com The group maintains the Product Information Management (PIM) system and Data Quality tools to accomplish that responsibility.', '', 'The Product Data Engineering Technician performs technical data research, assessment, acquisition, and quality assurance of data for electronic components using a variety of resources and tools. They work with and establish solid relationships with the Products team, Pricing team and other departments within Mouser to ensure the highest standard in the structure and maintenance of technical data.', '', 'ACCOUNTABILITIES & ESSENTIAL FUNCTIONS', '', 'Performs technical data research, assessment and acquisition using the Internet, Supplier websites, search engines, spreadsheets, and internal databases', 'Normalizes all collected data into a consistent format that is governed by Tech Data established procedures', 'Collaborates, coordinates, and manages the classification, collection, implementation, and maintenance of the product technical data using Product Information Management (PIM) system and Data Quality Analyst tools', 'Plans, develops, and manages the hierarchies for assigned product categories based on product type and/or technology through technical processes', 'Ensures that collected data is relevant for uses that are sourcing products, in all regions worldwide', 'Develop a basic Mouser Product Data acumen and use it with each classification and attribution task assigned', 'Develops an understanding of the classification Hierarchy to the extent that misclassified products can be readily identified and reclassified into the correct template', 'Evaluate template attributes for relevance with the template Taxonomy and make recommendations for changes that would benefit customers', 'Evaluate the data as presented on Mouser.com and make recommendations regarding normalization, sorting, and order of parametric attributes to enhance the overall product sourcing for customers', 'Establish open and timely communications with interested parties, stakeholders, and teams', 'Expected to utilize organizational skills to document, categorize, prioritize, provide easy access to information, ask questions, follow up and maintain communications', 'Represents the company in a professional manner with internal and external customers', '', 'SKILLS & CERTIFICATIONS', '', 'Ability to manage multiple projects and priorities', 'Familiarity in working in and with cross-functional teams', 'Strong organizational skills', 'Strong ability to work independently or in teams with a collaborative interpersonal style', 'Demonstrates a positive attitude toward self and others', 'Ability to set and track goals', 'Uses sound judgement to identify issues and escalates when appropriate', 'Able to research data for long periods of time', 'Able to quickly learn new software applications and adapt to project related process changes', 'Detailed and thorough in work habits with multi-tasking ability', 'Demonstrated ability in reading, analyzing, and interpreting Technical Data Sheets, Product Guides, Scientific and Technical Journals and other related engineering documents', 'Professional with the ability to interface directly with internal business contacts and represent the business unit', 'PC experience in Microsoft Windows environment, proficient with internet email, Microsoft Word, Excel, Power Point, Outlook, and related platforms', 'Electronic Design, Systems Design, Test Engineering or Electronic Component experience required', 'Exhibits strong analytical, technical, problem solving and organizational skills', 'Able to work with minimum supervision and independent judgements', '', 'Product Data Engineer Technician II', '', 'Maintain and continuously build on an established strong Mouser Product Data classification and attribution assignments', 'Contribute to functional design of process solutions', 'Proficient to quickly learn and adapt to project related process changes', 'Proficient in work habits with multi-tasking ability', 'Proficient in classifying and attributing products using the Product Information Management (PIM) system and related tools', 'Proficient in in using Excel', 'Knowledge and understanding of Mouser Taxonomy and hierarchies', 'Proficient in reading and using Technical Data Sheets and related scientific document', '', 'Requirements', '', 'Bachelor’s Degree in Electrical Engineering or relevant discipline. In lieu of a degree 5+ years of relevant work experience in Electrical Engineering or technical field is acceptable', '2+ years Electronic Component experience required. For internal candidates, experience can be a combination of internal and external experience.', '', 'Equal Opportunity Employer, including disability and veterans.', '', 'Category:Internet Business', '', 'This is a summary of the primary accountabilities and requirements for this position. The company reserves the right to modify or amend accountabilities and requirements at anytime at its sole discretion based on business needs. Any part of this job description is subject to possible modification to reasonably accommodate individuals with disabilities.', '', '#LI-SR1', '', 'Mouser Electronics endeavors to make its Career page accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact Human Resources at (817) 804-3850 or hr@mouser.com. This contact information is for accommodation requests only and cannot be used to apply for positions or to inquire about the status of applications.', '', 'Mouser is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.']"
Senior Lead Data Engineer," JPMorgan Chase Bank, N.A. - 3.8 "," Plano, TX", Full-time,, 21 hours ago,"['Cassandra', 'Big data', 'Spark', 'NoSQL', 'Apache Hive', 'AWS', 'Presentation skills', 'Financial services', 'Kafka', 'Data collection', 'Redshift', 'DynamoDB', 'Banking']","[""Embrace this pivotal role as an essential member of a high performing team dedicated to reaching new heights in data engineering. Your contributions will be instrumental in shaping the future of one of the world's largest and most influential companies."", 'Job Summary', 'As a Senior Lead Data Engineer at JPMorgan Chase Commercial Bank, you are an integral part of an agile team that works to enhance, build, and deliver data collection, storage, access, and analytics in a secure, stable, and scalable way. Leverage your deep technical expertise and problem solving capabilities to drive significant business impact and tackle a diverse array of challenges that span multiple data pipelines, data architectures, and other data consumers.', 'Job Responsibilities', '', '', 'Provides recommendations and insight on data management, governance procedures, and intricacies applicable to the acquisition, maintenance, validation, and utilization of data', '', 'Designs and delivers trusted data collection, storage, access, and analytics data platform solutions in a secure, stable, and scalable way', 'Defines database back-up, recovery, and archiving strategy', 'Generates advanced data models for one or more teams using firmwide tooling, linear algebra, statistics, and geometrical algorithms', 'Approves data analysis tools and processes', 'Creates functional and technical documentation supporting best practices', '', 'Advises junior engineers and technologists', 'Evaluates and reports on access control processes to determine effectiveness of data asset security', 'Adds to team culture of diversity, equity, inclusion, and respect', '', 'Required Qualifications, Capabilities, and Skills', '', 'Working experience with both relational and NoSQL databases', 'Advanced understanding of database back-up, recovery, and archiving strategies', 'Advanced knowledge of linear algebra, statistics, and geometrical algorithms', '', 'Experience presenting and delivering visual data', '', 'Strong background in a Big Data technologies (Spark, Impala, Hive, Redshift, Kafka, etc.)', '', 'Expertise in Big Data technologies in the AWS ecosystem ( Lake Formation, Redshift, Lambda, SQS, EMR etc.)', '', 'Preferred Qualifications, Capabilities, and Skills', '', 'Proficiency across the full range of database and business intelligence tools; publishing and presenting information in an', 'engaging way is a plus', '', 'Financial Services and Commercial banking experience is a plus', '', 'Familiarity with NoSQL database platforms(DynamoDB, Cassandra) is a plus', ""JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management."", ""We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."", 'The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.', ""As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law."", '', 'We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.', 'Equal Opportunity Employer/Disability/Veterans']"
Sr Data Engineer with Vertex.AI, Gannett - 3.0 ," Plano, TX", Full-time," $140,000 - $160,000 a year", 2 days ago,"['Computer science', 'Data modeling', 'Azure', 'Go', 'Computer Science', 'Spark', 'Ceridian', 'Git', 'Google Cloud Platform', 'Java', 'SQL', 'AWS', ""Bachelor's degree"", 'Machine learning', 'PostgreSQL', 'Distributed systems', 'ETL', 'Agile', 'AI', 'Communication skills', 'Data warehouse', 'Python', 'Marketing', 'MySQL', 'Data Science']","['Gannett Co., Inc. (NYSE:', 'GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services.', 'Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures.', 'Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid.', 'To connect with us, visit www.gannett.com', '', 'Job Specification:', 'Sr Data Engineer with Vertex.AI', 'Location:', 'Remote', 'Salary:', '$140,000-$160,000 based on skills, experience, location, and union representation, if applicable.', '', 'Position Overview:', ""We are seeking a skilled and experienced Data Engineer to join our team at Localiq DMS. The ideal candidate should have a strong background in data engineering, with specific exposure in working with the Vertex.AI platform. As a Data Engineer, you will play a crucial role in developing and maintaining our data infrastructure, ensuring the efficient extraction, transformation, and loading of data from various sources. Your expertise with Vertex.AI will be instrumental in leveraging the platform's capabilities to enhance our data processing and analysis workflows."", '', 'Responsibilities:', '', '', 'Develop and maintain data pipelines and ETL processes using Vertex.AI platform to support data acquisition, transformation, and loading.', '', 'Collaborate with cross-functional teams, including data scientists, analysts, and software engineers, to design and implement efficient data processing solutions.', '', 'Design and optimize data models and schemas to support business requirements and data analysis needs.', '', 'Implement data quality checks and ensure data integrity throughout the data pipeline.', '', 'Monitor and troubleshoot data pipelines to identify and resolve issues in a timely manner.', '', 'Work closely with stakeholders to understand data requirements and translate them into technical specifications.', '', 'Research and evaluate new technologies and tools related to data engineering and provid recommendations for improvements.', '', 'Stay up to date with industry best practices and emerging trends in data engineering and data management.', '', '', 'Requirements:', '', '', ""Bachelor's degree in Computer Science, Engineering, or a related field. Equivalent work experience will also be considered."", '', 'Proven experience as a Data Engineer, with a focus on designing and implementing data pipelines and ETL processes.', '', 'Strong expertise in working with the Vertex.AI platform, including familiarity with its capabilities and features.', '', 'Proficiency in programming languages such as Python, Java, or Golang for data processing and manipulation.', '', 'Experience with distributed computing frameworks like Apache Spark for large-scale data processing.', '', 'Knowledge of SQL and database systems (e.g., PostgreSQL, MySQL) for data querying and manipulation.', '', 'Familiarity with cloud platforms such as AWS, GCP, or Azure and their respective data services.', '', 'Understanding of data warehousing concepts and experience with data modeling and schema design.', '', 'Excellent problem-solving and troubleshooting skills, with the ability to identify and resolve data-related issues.', '', 'Strong communication skills and the ability to collaborate effectively with cross-functional teams.', '', '', 'Preferred Qualifications:', '', '', 'Advanced degree in a relevant field, such as Data Science or Computer Engineering.', '', 'Experience with other data engineering platforms and tools, in addition to Vertex.AI.', '', 'Knowledge of machine learning concepts and experience with integrating ML models into data pipelines.', '', 'Familiarity with agile development methodologies and version control systems (e.g., Git).', '', 'Experience working in an advertising or marketing data environment will be a plus.', '', '#LI-REMOTE', '#LI-SG1', '#PRODUCTGNT', 'The annualized base salary for this role will range between $90,000 and $213,900. Variable compensation is not reflected in these figures and based on the role, may be applicable. Exact compensation may vary based on skills, experience, location, and union representation, if applicable.', 'Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee’s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant’s disability or religion, to complete this employment application and/or any other process in connection with an individuals’ application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.’s Recruitment Department at Recruit@gannett.com.']"
Senior Data Engineer, Shell - 3.9 ," Houston, TX", Full-time, Estimated: $138K - $174K a year, 3 days ago,"['Azure', 'Go', 'Data lake', 'Full-stack development', 'Relational databases', 'Big data', 'Spark', 'Google Cloud Platform', 'Java', 'Databases', '8 years', 'SQL', 'Pandas', 'AWS', 'Docker', ""Bachelor's degree"", 'Scala', 'Kafka', 'GraphQL', 'Python', 'Debugging']","['The Role', '', 'What is the role', 'The Senior Data Engineer will join the Energy Marketing Powerhouse Team and will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.', 'Responsibilities:', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure, AWS ‘big data’ technologies', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs', 'Keep our data separated and secure across national boundaries through multiple data centers and Azure, AWS regions', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Requirements:', 'Must have legal authorization to work in the US on a full-time basis for anyone other than current employer', 'Bachelor’s degree or relevant industry experience', '8 or more years of experience in Full Stack development work', 'Working knowledge of the power and renewable energy (wind, solar and battery) markets', 'Experience with the various stages of the data pipeline - ingesting and transforming data, designing a schema, building checks and redundancy, and adapting schemas based on new requirements', 'Deep understanding of data lakes and relational databases and experience in handling Large Scale Time Series data', 'Experienced with modern coding, testing, debugging and automation techniques.', 'Expertise in data model design with sensitivity to usage patterns and goals - schema, scalability, immutability, idempotency, etc.', 'Experience in productionizing various big data technologies both open source and cloud native, AWS preferred (Kafka, Airflow, Dremio etc)', 'Expertise in at least two of the following languages - Python, Go, Scala, Java', 'Experience in Apache Spark, Python libraries such as Pandas for data manipulation, AWS, GCP, ETL/ELT tools, GraphQL, Apollo, Hasura, Docker, K8, Cloud, microservices, containerization, web services, DB/SQL, etc.', 'Company description', 'Shell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally, and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.', 'As a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity, and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork, and professionalism, as well as pride in what we do and how we conduct business.', 'Building on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.', 'An innovative place to work', 'There’s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.', 'Join us and you’ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy or developing technology that helps the world to use energy more efficiently.', 'An inclusive place to work', 'To power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we’re nurturing an inclusive environment – one where you can express your ideas, extend your skills, and reach your potential.', 'We’re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we’ll take it from there.', 'We’re closing the gender gap – whether that’s through action on equal pay or by enabling more women to reach senior roles in engineering and technology.', 'We’re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity.', 'We consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application.', 'A rewarding place to work', 'Combine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.', 'We’re huge advocates for career development. We’ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible.', '', '', '', 'Disclaimer', 'Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Shell/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell participates in E-Verify. All qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws. Shell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability. As a US Federal Contractor, hiring selections are subject to periodic audit review and documentation of your selections should be maintained for a period of three calendar years. It is the policy of Shell in the U.S. (“Shell”) to provide equal opportunity to all individuals, employees and all qualified applicants for employment consistent with employment requirements and qualifications. Shell prohibits discrimination based on race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, veteran status, citizenship, genetic information, or other protected status under federal, state or local laws. All employees are expected to support this policy and contribute to an environment of equal opportunity. If you need an accommodation for a disability during the resourcing process, please speak with an HR representative.']"
Data Security Engineer - Corporate - US, Sysco - 3.3 ," Houston, TX", Full-time, Estimated: $118K - $149K a year, 23 hours ago,"['MCSE', '5 years', 'Big data', 'Data analysis skills', 'Java', 'OOP', 'C++', 'CISSP-ISSEP', 'Scala', 'APIs', 'ETL', 'Vulnerability management', 'GIAC Certification', 'CompTIA Security+', 'Python']","['Company:', '', 'US6469 Sysco Payroll, Division of Sysco Resources Services, LLC', '', '', 'Zip Code:', '77077', '', '', 'Minimum Years of Experience:', '10+ Years', '', '', 'Employment Type:', 'Full Time', '', '', 'Travel Percentage:', '', '0', '', '', 'Job Summary:', '', ""This position sits within the Vulnerability and Threat Management program at Sysco where you'll play a key role integrating data end-to-end for a complete lifecycle view. Main key responsibilities will include Big data manipulation, data engineering in the cloud, data pipelines and orchestration, data virtualization, streaming data and APIs, and coding for data integration and interaction."", '', '', 'Duties and Responsibilities:', '', 'Partner with multiple teams for data integration points to discover key system attributes from each tool', 'Use object-oriented programming (Python, Java, C++, Scala, etc.) to transform massive datasets at scale by writing high-performing programs', 'Design highly-available and scalable cloud integrations for data engineering using cloud providers', 'Monitor the health of data pipelines using various tools and techniques to test reliability and validate data integrity', 'Configure batch and real-time processing for data ingestion', 'Communicate issues, report risks, and troubleshoot findings for resolution', 'Design and test APIs for robust performance and security', '', 'Education Required:', '', 'Security Certification', '', 'Education Preferred:', '', 'AWS Data Analytics, CCP: Data Engineer, etc.), MCSE Data Management and Analytics, Security+, CISSP, ISSEP, or GIAC', '', 'Experience Required:', '', 'Minimum 7 years in IT 5 years in data engineering', '', 'Experience Preferred:', '', '10 years in IT, Minimum 7 years in data engineering', '', 'Licenses/Certification Required:', '', 'Security Certification', '', 'Licenses/Certification Preferred:', '', 'AWS Data Analytics, CCP: Data Engineer, etc.), MCSE Data Management and Analytics, Security+, CISSP, ISSEP, or GIAC', '', 'Skills & Abilities:', '', 'Understanding of data science concepts', 'Expertise in data analysis', 'Hands on with ETL tools', 'Experience with BI tools', 'Big data technologies knowledge', 'Highly motivated self-starter with ability to multitask and complete assignments within time constraints and deadlines', '', 'Physical Demands:', '', 'Reasonable accommodations will be made to enable individuals with disabilities to perform the essential functions of this job.', '', 'Work Environment:', '', 'Remote', '', 'BENEFITS INFORMATION:', ""For information on Sysco's Benefits, please visit https://SyscoBenefits.com"", '', '', 'HOW WE PROTECT OUR', '', 'ASSOCIATES', '', 'COVID-19 Precaution(s):', '', 'Personal protective equipment and masks provided', 'Temperature screenings', 'Social distancing guidelines in place', 'Sanitizing, disinfecting, and cleaning procedures in place', '', 'OVERVIEW:', '', 'Sysco is the global leader in foodservice distribution. With over 57,000 associates and a fleet of over 13,000 vehicles, Sysco operates approximately 326 distribution facilities worldwide and serves more than 625,000 customer locations.', '', ""We offer our associates the opportunity to grow personally and professionally, to contribute to the success of a dynamic organization, and to serve others in a manner that exceeds their expectations. We're looking for talented, hard-working individuals to join our team. Come grow with us and let us show you why Sysco is at the heart of food and service."", '', '', 'AFFIRMATIVE ACTION STATEMENT:', '', 'Applicants must be currently authorized to work in the United States.', '', 'We are proud to be an Equal Opportunity and Affirmative Action employer, and consider qualified applicants without regard to race, color, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, disability, veteran status or any other protected factor under federal, state or local law.', '', 'This opportunity is available through Sysco Corporation, its subsidiaries and affiliates.']"
Senior Lead Data Engineer - Head of Operations," JPMorgan Chase Bank, N.A. - 3.8 "," Plano, TX", Full-time,, 2 days ago,"['Oracle', 'Relational databases', 'Big data', 'Spark', 'UNIX', 'Microsoft SQL Server', 'Apache Hive', 'SQL', 'Analysis skills', 'Scripting', 'ETL', 'Kafka', 'Data collection', 'Redshift', 'Python', 'Shell Scripting', 'Control-M']","[""Embrace this pivotal role as an essential member of a high performing team dedicated to reaching new heights in data engineering. Your contributions will be instrumental in shaping the future of one of the world's largest and most influential companies"", 'Job Summary', 'As a Senior Lead Data Engineer at JPMorgan Chase in Commercial Bank, you are an integral part of an agile team that works to enhance, build, and deliver data collection, storage, access, and analytics in a secure, stable, and scalable way. Leverage your deep technical expertise and problem solving capabilities to drive significant business impact and tackle a diverse array of challenges that span multiple data pipelines, data architectures, and other data consumers.', 'Job Responsibilities', 'Provides recommendations and insight on data management, governance procedures, and intricacies applicable to the acquisition, maintenance, validation, and utilization of data', 'Designs and delivers trusted data collection, storage, access, and analytics data platform solutions in a secure, stable, and scalable way', 'Defines database back-up, recovery, and archiving strategy', 'Generates advanced data models for one or more teams using firmwide tooling, linear algebra, statistics, and geometrical algorithms', 'Approves data analysis tools and processes', 'Establish release toll-gates to enforce a controlled and governed production environment', 'Advises junior engineers and technologists', 'Evaluates and reports on access control processes to determine effectiveness of data asset security', 'Comfortable learning cutting edge technologies and applications to greenfield project', '', 'Required Qualifications, Capabilities, and Skills', '', 'Experience in a Big Data technologies (Spark, Impala, Hive, Redshift, Kafka, etc.)', 'Highly skilled at running operations across a large data ecosystem with 100+ developers', '', 'Strong experience with orchestration tools like Airflow, Control-M , Autosys etc.', '', 'Strong experience with monitoring tools like Tivoli, Grafana, DataDog etc.', '', 'Strong experience working with stakeholders and defining SLA/SLO/SLIs and maintaining healthy metrics', '', 'Strong Experience with UNIX shell scripting to automate file preparation and database loads', '', 'Experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues', '', '', 'Preferred Qualifications, Capabilities, and Skills', '', 'Solid experience with Python is preferred', '', 'Experience with ETL tools, writing SQL', '', 'Familiarity with relational database environment (Oracle, SQL Server, etc.) leveraging databases, tables/views, stored procedures, agent jobs, etc.', '', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information', 'with attention to detail and accuracy', '', ""JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management."", ""We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."", 'The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.', ""As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law."", '', 'We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.', 'Equal Opportunity Employer/Disability/Veterans']"
Senior Software Engineer (Senior Azure Data Engineer)," Vizient, Inc. - 3.7 "," Irving, TX", Full-time," $102,400 - $152,200 a year", 2 days ago,"['Azure', 'Data lake', '5 years', 'Spark', 'Test-driven development', 'Apache Hive', 'ADLs', 'SQL', 'Database design', 'HBase', 'Continuous integration', 'Software development', 'Agile', 'Python', 'T-SQL', 'Analytics']","['When you’re the best, we’re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents while living and working as their authentic selves. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance through an inclusive environment both now and in the future.', 'Summary:', 'In this role, you will use best practices and knowledge of internal and external business operations to improve products and/or services. You will solve complex problems and bring a new perspective to the usage of existing solutions. You will also mentor employees in the immediate group.', 'Responsibilities:', 'Design, develop, enhance, code, test, deliver and debug software independently across multiple products.', 'Implement larger, more complex, or new stories for multiple products.', 'Play an active role in story breakup and refinement sessions.', 'Drive and lead story level architecture/design sessions.', 'Participate in feature level architecture/design sessions.', 'Recommend actions to improve procedures and standards.', 'Stay up to date on technical trends and emerging technology.', 'Proactively improve standards and procedures.', 'Qualifications:', 'Relevant degree preferred.', '5 or more years of experience in a software development role required.', 'Exceptional analytical and conceptual thinking along with logical and physical database design skills required.', 'Strong aptitude and experience in writing and troubleshooting SQL and T-SQL required.', 'Data analysis, data modeling, and data integration using Azure technologies like Azure Data Factory (ADF) required.', 'Experience with Azure SQL and cloud data solutions within a data warehouse environment, using multiple data sources, data lakes, etc. preferred.', 'Hands on experience with Azure Synapse, Azure Stream Analytics, Azure Event Hubs, Azure Event Grid, Databricks, ADLS Gen 2, & Logic Apps strongly preferred.', 'Experience with Python, Spark, Hive, Hbase and other bigdata technologies preferred.', 'Extensive experience working with enterprise solution delivery in a large-scale distributed software design environment is preferred.', 'Experience working in an Agile based development environment, using Agile concepts such as Continuous Integration, TDD (Test Driven Development), and Paired Programming preferred.', 'You must be authorized to work in the United States without sponsorship.', 'Estimated Hiring Range:', '$102,400.00 - $152,200.00', 'This position is also incentive eligible.', 'Vizient has a comprehensive benefits plan! Please view our benefits here:', 'http://www.vizientinc.com/about-us/careers', 'Equal Opportunity Employer: Females/Minorities/Veterans/Individuals with Disabilities', 'The Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.']"
Big Data Engineer - GBDETX0623, Genpact - 3.8 ," Richardson, TX", Full-time,, 6 days ago,"['DataStage', 'Big data', 'Google Cloud Platform', 'Apache Hive', 'Ab Initio', ""Master's degree"", 'SQL', ""Bachelor's degree"", 'ETL', 'Teradata', 'Informatica', 'PL/SQL', '2 years', 'Python', 'Hadoop']","['With a startup spirit and 115,000+ curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us. Inviting applications for the role of PD, AP Helpdesk', '', 'Skills – Genpact LLC seeks', 'Big Data Engineer (multiple positions)', 'in Richardson, TX to', '', 'develop technical specifications for software application and provide quick resolution to production incidents or problems. Communicate project status, requirements, issues, risks, and assumptions effectively to end clients, the business teams, and development resources.', 'Responsible for all the activities related to the analysis, architecture, design, and implementation of new or modified application software for data Extraction, Transformation, and Loading (ETL) solutions (including data lake, data marts, and data warehouses) within the banking, financial services, and insurance domains. Design and develop ETL and Big Data applications, scripts, queries, reports, and other automated procedures. Employ relevant application development tools, platforms, and methodologies including ETL and Big Data tools (Informatica, DataStage, Abinitio, Hadoop, and Hive), SQL, PL/SQL, Teradata tools, Python, PySpark, and data governance tools (Informatica IDQ, and Data Quality). Employ experience in Google Cloud along with Google Sataproc and Google Big Query. Apply management and technical (Distributed and Legacy technologies) expertise in primary industry domains (Banking and Financial Services, Healthcare, Pharmacy, or Insurance) to lead and coordinate the overall activities of distributed software engineering and development resources. Establish the feasibility of application development and delivery plans. Interact with clients to clarify business requirements and key operations. Manage and lead project team and coordinate efforts with client teams, serving as single point of contact. Participate in business analysis, functional design, data quality, and testing activities for any new enhancements. Responsible for assessment and effort estimates for any new enhancements or extensions, and plan and allocate resources accordingly. Participate in daily scrum calls, serve as part of the team for creation of user stories, feasibility analysis, effort estimation, and prioritization of change requests. Participate in the daily team calls and provide updates to servicing project manager for incidents. Develop technical specifications for software application and provide quick resolution to production incidents or problems. Communicate project status, requirements, issues, risks, and assumptions effectively to end clients, the business teams, and development resources.', '', 'Education –', ""Position requires a Master’s degree in an Engineering (all), Computer Science, Sciences, Mathematics, or related field and 2 years of experience in the job offered, a related software engineering architect, designer, programmer, or systems analyst position, or related occupation. As an alternative, a Bachelor’s degree in an Engineering (all), Computer Science, Sciences, Mathematics, or related field and 5 years of progressively responsible post-Bachelor's experience in the job offered, a related software engineering architect, designer, programmer or systems analyst position, or related occupation is also acceptable."", 'Foreign degree equivalents are acceptable. Position headquartered in Richardson, TX with travel required to unanticipated project sites throughout the U.S. based on client need', '.', '', 'Please send resume and cover letter to:', '', 'Talent.Recruitment@genpact.com', '', 'Indicate job code “', 'G', 'BDETX0', '623', '” when applying.', '', 'Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.', 'Job', 'Senior Principal Consultant', 'Primary Location', 'USA-Richardson', 'Education Level', ""Bachelor's / Graduation / Equivalent"", 'Job Posting', 'Jul 5, 2023, 12:54:45 PM', 'Unposting Date', 'Aug 4, 2023, 1:29:00 PM', 'Master Skills List', 'Corporate', 'Job Category', 'Full Time']"
Big Data Integration Engineer, KBR - 4.1 ," Houston, TX", Full-time, Estimated: $108K - $136K a year, 3 days ago,"['Microsoft Windows Server', 'Top Secret Clearance', 'Management', 'Computer Science', 'NFS', 'Kubernetes', 'Big data', 'Software deployment', 'Microsoft SQL Server', 'Secret Clearance', 'Windows', '3 years', ""Bachelor's degree"", 'Ubuntu', 'CentOS', 'S3', 'VMWare', 'Linux', 'Cybersecurity', 'Communication skills', 'Debugging', 'Data Science', 'Hadoop']","['Title:', 'Big Data Integration Engineer', 'ABOUT THIS POSITION', 'The successful candidate will be part of the KBR team supporting the Test Resource Management Center’s (TRMC) Big Data (BD) and Knowledge Management (KM) Team deploying BD and KM systems for DoD testing Ranges and various acquisition programs.', 'This is being hired nationwide as it is a remote work capable position. The candidate can either work in one of KBR’s facilities or work from home, assuming the candidate has a stable internet connection.', 'Responsibilities:', 'Deployment and integration of a highly visible data analytic project called Cloud Hybrid Edge-to-Enterprise Evaluation Test & Analysis Suite (CHEETAS) at multiple DoD ranges and labs', 'Work with the data science and software engineering team members to support our customers by demonstrating the ‘art of the possible’ with insights gained from analyzing DoD Test & Evaluation data', 'Deploy and configure Big Data and Knowledge Management tools in an enterprise environment', 'Configure and troubleshoot a variety of Big Data ecosystem tools', 'Work with a wide range of stakeholders and functional teams at various levels of experience', 'Become a CHEETAS deployment subject matter expert', 'Act as a critical part of our technical team responsible for deploying CHEETAS within customer environments', 'Work closely with system administrators and software developers to communicate, document and ultimately resolve deployment issues as they arise', 'Provide deployment services to various DoD testing Ranges and acquisition programs', 'Deploy CHEETAS within disparate environments (on different non-standard hardware stacks and integrated into different existing ecosystems) sometimes located within DoD vaults with no outside internet connectivity', 'Act as the frontline interface that customers will have when first experiencing CHEETAS within their DoD Range and lab environments', 'This requisition will be used to hire multiple individuals', '', 'Entry level Integration Engineers will', 'NOT', 'be considered due to the breadth of knowledge necessary to be successful in the position. This position is anticipated to require travel of 25% with surges possible up to 50% to support end users located at various DoD Ranges and Labs across the United States.', 'Come join the KBR BDKM team and be a part of the award-winning team responsible for revolutionizing how data analysis is performed across the entire Department of Defense!', 'BASIC QUALIFICATIONS', ""This position requires a bachelor's degree in a STEM Computer Science, Data Science, Statistics or related, technical field, and 7-10 years of experience. Entry level Integration Engineers will NOT be considered."", 'Previous experience must include five (5) years of hands-on experience in big data environments.', 'Previous experience must include three (3) years of hands-on experience with Kubernetes. Experience in the integration with and configuration of: Hadoop, SQL Server Big Data Cluster, Kubernetes, CentOS, Ubuntu, RedHat, Windows Server, VMWare, etc.)', 'Active or Current Secret Clearance required - Top Secret Clearance preferred.', 'Knowledge / Skills / Abilities:', 'Experience with installation, configuration, integration with and usage of the following tools and technologies: Helms Charts, YAML, Kubernetes, Kubectl, Kubernetes IDE, NFS, SMB, S3, SQL Server, Windows Server, Windows 10/11, Linux (CentOS, Ubuntu, RedHat), Hadoop.', 'Must be prepared to learn new business processes or CHEETAS application nuances every Agile sprint release (roughly every 6 weeks) prior to deploying to customer sites.', 'Experience with working in distributed team environment is preferred.', 'Ability to problem solve, debug, and troubleshoot while under pressure and time constraints is required.', 'Ability to communicate effectively about technical topics to both experts and non-experts at both the management and technical level is required.', 'Excellent interpersonal skills, oral and written communication skills, and strong personal motivation are necessary to succeed within this position.', 'Ability to work independently and provide appropriate recommendations for optimal design, analysis, and development.', 'Excellent written and verbal communications skills are required, as the Integration Engineer will be in frequent contact with the project technical lead, be taking direction from various government leads, and will frequently be interacting with end users to gather requirements and implement solutions while away from other team members.', 'Ability to teach and mentor engineers with a variety of skill levels and backgrounds is a plus.', 'Excellent testing, debugging and problem-solving skills are required to be successful in this position.', 'Experience designing, building, integrating with and maintaining both new and existing big data systems and solutions.', 'ADDITIONAL QUALIFICATIONS', 'The preferred candidate will have experience working in government/defense labs and their computing restrictions.', 'Knowledge of the Test and Training Enabling Architecture (TENA), the Joint Mission Environment Testing Capability (JMETC), and Distributed Testing and Training is a plus.', 'Experience working with major DoD Acquisition programs such as Joint Strike Fighter (JSF) or Missile Defense Agency (MDA) is a plus.', 'Knowledge of DoD Cybersecurity policies is a plus.', 'KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.']"
Senior Software Engineer - Data and API, Rehrig Pacific Company - 3.3 ," Richardson, TX",, Estimated: $113K - $143K a year, 6 days ago,"['Computer science', 'Management', 'Computer Science', 'Management Information Systems', '5 years', 'Git', 'SOAP', 'SQL', ""Bachelor's degree"", 'REST', 'APIs', 'ETL', 'Agile', 'Python']","['Here at Rehrig Pacific, we are all about our people. Since 1913, our organization has focused on sustainable supply chain solutions while creating a culture and atmosphere where amazing people, like you, are celebrated for doing their best work. Rehrig Pacific has grown to meet the needs of our industry consumers across the country and internationally. We are constantly creating innovative solutions to transcend the new standards set forth by our customers. We find true fulfillment in helping others, both within the Rehrig Pacific family and in our communities. As servant leaders, we lead by example.', '', 'Brief Role Description', '', 'The Senior Software Engineer with a specialty in data and APIs will be accountable for helping our customers integrate with our enterprise products and applications. The person will collaborate with both our client’s and Rehrig’s engineers to integrate data between systems. The desired skills of the senior software engineer involve high levels of understanding around database architecture, SQL queries, ETL, authentication, authorization, REST, and python. This position reports to the Technology Engineering Director in the New Product Development group.', '', '', 'Accountabilities', '', 'Ability to work closely with technical architects and our client’s architecture governance technical team for solution development and design reviews', '', 'Manages API lifecycle and release management', '', 'Manages data integrity', '', 'Manages how we do reporting', '', 'Manages the database architecture', '', 'Creates and maintains effective documentation on solutions: The Engineer will create documentation on the data flow, architecture, and daily operation and troubleshooting for all assigned solutions and maintain that documentation in an ongoing fashion', '', 'Work closely with Rehrig’s Product Owners, and must understand the short and medium-term strategy for the business', '', 'Function as an escalation point for technical support and troubleshooting: The Engineer will help troubleshoot API/ETL issues and problem resolution', '', '', 'General Responsibilities', '', 'Provide timely updates to management on open issues and projects', '', 'Ensure availability and security requirements are met consistently', '', 'Other duties as assigned', '', '', 'Qualifications', '', 'Bachelor’s Degree in Computer Science, Management Information Systems or a related field or equivalent in work experience.', '', 'Minimum of 5 years of software engineering experience', '', 'Experience with REST based APIs', '', 'Knowledge of HTTP and SOAP Protocols', '', 'Experience with source code management tool (git)', '', 'Demonstrated subject matter expertise in all of the following: Python, Agile Development, SQL Queries, ETL', '', 'Experience working cross functionally in disparate geographies required', '', 'Ability to travel approximately 10% of the time', '', 'Rehrig Pacific Company is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also here.']"
"Data Engineer, Staff (RTE/PO) / Active Clearance / Onsite - GA or TX", Lockheed Martin - 4.0 ," Fort Worth, TX", Full-time,, 2 days ago,"['Computer science', 'Computer Science', 'Secret Clearance', ""Bachelor's degree"", 'Product management', 'Business Information Systems', 'Communication skills', 'Data Science']","['Job ID:', '638707BR', '', 'Date posted:', 'May. 16, 2023', '', '', 'Description:', 'This role will have Release Train Engineer, Product Owner responsibilities under Scaled Agile framework to drive mission of the data team for ADP (Advanced Development Program). This will require on-site support for Classified Aero Programs (Marietta, GA or Ft Worth, TX).', 'The individual will:', '', 'Maintain focus on the project and synchronize agile teams', 'Work with Product Management and other stakeholders to define and prioritize epics/features/stories/projects', 'Translate business requirements into features/stories for the technical teams', 'Identify and remove impediments and risks', 'Facilitate Agile ceremonies (DSU, Program Backlog/Vision, PI Planning, Iteration Planning/Review, Retrospective, etc)', 'Build significant relationships and responsibilities outside the local team, including working with Product Management, Customers, Business Owners, and other stakeholders.', 'Basic Qualifications:', '', 'US Citizenship. Will require program clearance prior to start (DoD Secret Clearance)', 'Significant years of proven experience aligned to the RTE / PO duties listed in Job Description', 'Strong problem-solving skills and strong oral and written communication skills', ""Bachelor's degree in Data Science, Computer Science, Business Information Systems, or other relevant areas, or equivalent education/experience"", 'Desired Skills:', '', 'Understanding of Data security', 'Previous experience in Data Engineering', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work."", '', 'With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.', '', ""If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'ENTERPRISE BUSINESS SERVICES', '', 'Relocation Available:', 'No', '', 'Career Area:', 'Information Technology', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
Portal Req - Flight Test Instrumentation and Data Processing Engineer, Lockheed Martin - 4.0 ," Fort Worth, TX", Full-time,, 1 day ago,"['VMWare', 'vSphere']","['Job ID:', '621543BR', '', 'Date posted:', 'Mar. 01, 2023', '', '', 'Description:', 'By applying to the position listed on this site, you will be considered for opportunities within Lockheed Martin Aeronautics Corporation.', '', ""Our products play an important role in the national security of the United States and more than 70 other countries, ensuring peace and stability around the world. Highly trained and specialized personnel and facilities are key to the company's unrivaled success in the aeronautics industry. Our workforce of more than 25,000 has pre-eminent expertise in advanced aircraft design and production, modification and support, stealth technology, and systems integration."", '', ""Lockheed Martin Aeronautics Test and Evaluation (T&E) is hiring Flight Test Instrumentation and Data Processing Engineers at our test sites in California, Maryland, Nevada, Georgia, and Texas. Our Mission Statement: A United World Class Test Team Committed to Effective, Safe and Quality Product Deliver to Meet Our Customer's Needs. Every Commitment, Every Time, On Time."", '', 'Flight Test Instrumentation and Data Processing Engineers for T&E include Flight Test Instrumentation Operations Engineers, Flight Test Data Processing Engineers, Flight Test System Administrators, or Flight Test Simulation Administrators.', '', 'Flight Test Instrumentation Operations Engineers will be responsible for integrating requirements and programming new instrumentation data acquisition equipment, as well as fiber system, analog and digital signal conditioning hardware during integration and flight test. Knowledge of video compression and recording devices; solid state media recorders; analog/digital encoders/decoders; GPS and IRIG time standards and receiving devices; and other instrumentation devices to develop, test, and troubleshoot data acquisition systems is a plus. Works with LM homesite instrumentation engineers to identify instrumentation components, select parts, place orders, and manage status and costs.', '', 'Participate in real time control room activities during flight execution. The successful candidate will validate that aircraft sensors and mission system tests are conducted correctly by actively monitoring real time telemetry data during flight.', '', 'Assist with on aircraft troubleshooting and failure resolution as needed to ensure test aircraft are mission capable. Coordinate with other system personnel to resolve system failures or performance questions. Participate in problem identification, analysis, and resolution. Assist with collection, distribution, and analysis of data acquired during flight test missions.', '', 'Flight Test Data Processing Engineers will design, build, integrate, and operate systems for the real-time display of aircraft data as well as post-test processing of recorded data to create data products. Will interface with other technical personnel in the diagnosis and resolution of any problems (hardware/software) encountered in the recovery of test data utilizing various data systems including PCM ground stations, telemetry ground stations, specialized data processing equipment, etc.', '', 'Flight Test System Administrator Job duties include:', '', 'System Installation/Configuration (IT-centric tasks).', 'Network Switch Configuration/Maintenance.', 'Server Maintenance/Stand-Alone System', 'Support/Install Framework Patches.', '', 'Deploy security updates/System Regression Tests.', 'Maintain Documentation of System Configuration/Changes.', 'Troubleshooting issues as they arise.', 'Vulnerability Remediation on both Networked and Stand-Alone Systems.', 'Flight Test Simulation Administrator Job duties include:', '', 'Build Custom Test Scenarios and Weapons Loadouts for Scheduled Missions.', 'Software Integration with SCRUM Framework Style Reporting on New Build Outs.', 'Coordination with Engineering HQ (In Fort Worth, TX) on Current Issues and Build Updates.', 'Management of Flight Sim NAS, Switches, VSphere (VMWare) and Virtual Servers', 'Management of iSCSI booted Hosts Servers', 'Configuring/Supporting Security on Cybersecurity Tools and Servers such as ePO, AC', 'Basic Qualifications:', '**Must be a US Citizen. This position is located at a facility that requires special access.**', '', 'Education background in a STEM discipline', '', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about."", '', ""As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'AERONAUTICS COMPANY', '', 'Relocation Available:', 'Possible', '', 'Career Area:', 'Miscellaneous Engineering', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
Senior Principal Software Engineer - Platform Data Cloud, Blue Yonder - 4.1 ," Dallas, TX", Full-time," $180,538 - $234,273 a year", 6 days ago,"['Jira', 'Spring Boot', 'Computer science', 'Elasticsearch', 'Cloud infrastructure', 'Azure', 'Cloud architecture', 'Node.js', 'Computer Science', 'Data lake', 'React', 'Kubernetes', 'Ansible', 'Full-stack development', 'DevOps', 'Spark', 'Test automation', 'NoSQL', '11+ years', 'Git', 'Test-driven development', 'Google Cloud Platform', 'Java', ""Master's degree"", 'SQL', 'AWS', 'Analysis skills', 'Docker', ""Bachelor's degree"", 'JavaScript', 'PostgreSQL', 'Distributed systems', 'Continuous integration', 'GitHub', 'Agile', 'Kafka', 'Groovy', 'Jenkins', 'Python', 'Spring']","['The Luminate Cloud Data Platform team’s mission is to reimagine the supply chain technology and serve as the backbone of Blue Yonder’s SaaS products. Role serves as one of the key global architect to focus on innovation in SaaS platform engineering, spanning infrastructure architecture through enterprise, application platform features, to accelerate our cloud data team’s delivery and solution quality.', '', 'Primary Duties and Responsibilities', 'Consistently delivers solid quality in both design and implementation and helps the team shape what is built how, in particular:', 'Core responsibilities includes focusing on innovation and improving delivery effectiveness by driving product development features across the organization in software development, deployment, and infrastructure consistency.', 'Provide standardized enterprise solutions for cloud infrastructure and application deployment across multiple products.', 'Apply the appropriate software engineering patterns utilizing a meta-driven systems approach to build robust and scalable systems', 'Expert in Object Oriented and Functional programming and the ability to apply your skills in developing Blue Yonder products.', 'Influence fellow engineers by proposing software designs, providing feedback on software designs and/or implementation.', 'Demonstrated experience in large-scale Kubernetes systems, including how to sufficiently scale very large services in Kubernetes', 'Modular and Service based Architectural Design', 'The team currently comprises of global associates across US, Canada, India, and Germany and is expected to grow. The incumbent will need to be a quick learner.', 'Our Current Technical Environment:', 'Software/Tools: Java, Python, Groovy, GitHub, Node.js, React.js, Jenkins, GitHub, Codacy, Checkmarx, GitHub Advance Security, Black Duck Hub, BlazeMeter, Artifactory, Ansible, Docker, etc.', 'Application Architecture: Scalable, Resilient, event driven, secure multi-tenant Microservices architecture', 'Cloud Architecture: MS Azure (ARM templates, AKS, Virtue Networks, Event Hub, Azure AD)', 'Frameworks/Others: Kubernetes, Kafka, Elasticsearch, Spark, NOSQL, RDBMS, Spring Boot, Snowflake', 'What you’ll do:', 'An Architect- You’re comfortable crafting robust distributed systems that achieve both short and long-term business goals.', 'An Influencer- You communicate well across the organization to help define technical strategies and design tactics to execute them. You have the ability to articulate a clear technical vision.', ""Clean, Performant Code- You’re hands-on and comfortable writing code. You keep up with best practices and have a breadth of experience with different languages and frameworks. You are passionate about code quality and automation. You're comfortable driving the implementation and adoption of new frameworks, tools and technologies."", 'Agile Best Practices-You like working in an agile development environment and enjoy pairing, test-driven development, leading demos with working code and slicing work in a way that focuses on the highest value.', 'A Mentor- You have a passion for passing on your hard-earned experience. You disseminate knowledge and strive to level up those around you.', 'Be a change agent with technology development using cloud native architecture patterns in a distributed environment', 'Drive culture change in technology to become a truly Agile team which is self-organizing, DevOps and believes in everything automated', 'Collaborate with application teams for adoption of single Data platform', 'Discovering, Understanding, Leveraging, and Exposing new technologies and designs that will benefit the Data Platform', 'Evaluate and coach other senior engineers on the technical and interpersonal best-practices.', 'What we are looking for:', 'Masters/Bachelor’s Degree in Computer Science or related', 'You have 12+ years of Software Engineering experience and have experience in leadership roles across the full technology stack.', 'You have demonstrated organizational impact in your career by championing engineering principles like SOLID, TDD, OO design, etc.', 'You have a passion for pulling others up the ladder in their technology career and sharing best practices with more junior engineers.', 'Ability to collaborate well with the broader organization to include product, QA, senior leadership, compliance and other key stakeholders to your work.', 'Experience building robust, highly available, and scalable data lakes', 'Experience working with SQL and no-SQL datastores like Elasticsearch, Postgres, Snowflake', 'Expert in leveraging continuous integration and robust build/test automation, with a preference for cross platform stacks and containerization (Jira, Git, Jenkins)', 'Experience in one of the public cloud technology stack in Azure , AWS, GCP', 'Experience with Docker Containerization and Cloud services such as ElasticCache, EKS', 'Strong analytical skills to be able to manage complex problems using a number of techniques', 'Experience in leading complex software product delivery in an Agile environment', 'Experience in a leadership position responsible for building, motivating and leading high performing development teams', 'Experience with enterprise multi-tenant software', '-', 'The salary range for this position is: USD $ 180,537.50 – $234,272.5', 'The salary range information provided, reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual salary will be commensurate with skills, experience, certifications or licenses and other relevant factors. In addition, this role will be eligible to participate in either the annual performance bonus or commission program, determined by the nature of the position.', 'At Blue Yonder, we care about the wellbeing of our employees and those most important to them. This is reflected in our robust benefits package and options that includes:', 'Comprehensive Medical, Dental and Vision', '401K with Matching', 'Flexible Time Off', 'Corporate Fitness Program', 'Wellbeing Days', 'A variety of voluntary benefits such as; Legal Plans, Accident and Hospital Indemnity, Pet Insurance and much more', 'At Blue Yonder, we are committed to a workplace that genuinely fosters inclusion and belonging in which everyone can share their unique voices and talents in a safe space. We continue to be guided by our core values and are proud of our diverse culture as an equal opportunity employer. We understand that your career search may look different than others, and embrace the professional, personal, educational, and volunteer opportunities through which people gain experience.', 'Our Values', 'If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here:', 'Core Values', 'Diversity, Inclusion, Value & Equality (DIVE)', ""is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural"", 'Diversity Report', 'which outlines our commitment to change, and our', 'video', 'celebrating the differences in all of us in the words of some of our associates from around the world.', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.']"
Project Engineer Stf - Mission Data, Lockheed Martin - 4.0 ," Fort Worth, TX", Full-time,, 4 days ago,"['Microsoft Powerpoint', 'Microsoft Word', 'Microsoft Excel', 'Management', 'Auto estimating', 'Microsoft Office', 'Analysis skills', ""Bachelor's degree"", 'Systems engineering', 'Software development', 'Agile', 'Avionics', 'Microsoft Project', 'Leadership', 'Communication skills', 'Construction estimating']","['Job ID:', '640273BR', '', 'Date posted:', 'Jun. 09, 2023', '', '', 'Description:', ""The F-35 Common Reprogramming Tool (CRT) team is in need of a Project Engineer to coordinate and perform CAM duties across a variety of CRT contracts. The project engineer shall be required to coordinate across a number of teams to ensure the mission data organization's plans are in alignment with the broader organization's goals in order to meet tool delivery and contractual constraints. The candidate will be responsible for providing support and leadership for F-35 CRT team"", 'estimate efforts along with support to program & project managers. The candidate will be responsible for coordinating software milestones are met with the appropriate technical content. The candidate will be responsible for reviewing the status of projects & budgets, support & cost inquiries, variance documentation, critical', 'path & forecast misses, and bi-annual estimate at', 'completion (EAC) efforts. The candidate will provide earned value (EV) performance and EAC assessments. The candidate will identify risks, issues and opportunities and implement approved risk handling plans. The successful', 'candidate will use the complete CAM toolset to gather cost and budget data. The candidate will ensure the team follows all tenants of the LM Aero EVMS processes as defined within the F35 program. The candidate will participate in all required reviews and audits with the', 'customer, government, DCMA, etc.', '', 'Basic Qualifications:', '', 'Bachelors degree from an accredited college', 'Knowledge of Earned Valued Management, metrics and process management', 'Familiarity with the CAM toolset', 'Proficiency with MS Office products (Project, Word, Excel, and PowerPoint)', 'Desired Skills:', '', 'Team Leadership Experience', 'EV for Agile development', 'Systems engineering and mission systems/avionics background', 'Experience with Safety Critical and trusted software development process', 'Experience with F35 proposal process', 'Experience with resource estimation & management, software development estimation, project planning, and project management', 'Excellent communication, organization, and presentation skills of technical assignments', 'Experience in areas of cost analysis, schedule, and risk & opportunity management', 'Possess strong verbal and written communication skill', 'Security Clearance Statement:', 'This position requires a government security clearance, you must be a US Citizen for consideration.', '', 'Clearance Level:', 'Secret with an investigation within 5 years', '', 'Other Important Information You Should Know', '', 'Expression of Interest:', 'By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.', '', 'Ability to Work Remotely:', 'Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.', '', 'Work Schedules:', 'Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.', '', 'Schedule for this Position:', '4x10 hour day, 3 days off per week', '', 'Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.', ""Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about."", '', ""As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories."", '', 'Experience Level:', 'Experienced Professional', '', 'Business Unit:', 'AERONAUTICS COMPANY', '', 'Relocation Available:', 'Possible', '', 'Career Area:', 'Program Management', '', 'Type:', 'Full-Time', '', 'Shift:', 'First']"
Sr. Data Center Network Engineer, Samsung SDS America - 4.0 ," Taylor, TX", Full-time," $140,000 - $160,000 a year", 2 days ago,"['Computer science', 'Data center experience', 'Computer Science', 'CCNP', 'Ansible', '5 years', 'Software deployment', 'Load balancing', 'OSPF', 'UNIX', 'CCIE', 'Analysis skills', ""Bachelor's degree"", 'SSL', 'BGP', 'Computer networking', 'Network support', 'Linux', 'EIGRP', 'Network engineering', 'AI', 'Communication skills', 'Python']","['Samsung SDS America is looking for a Sr. Data Center Network Engineer to support, maintain, manage, troubleshoot, and execute network projects for a brand new state-of-the-art Samsung Semiconductor Manufacturing facility in Taylor, TX. The ideal candidate would bring a strong background as a SME supporting and designing Data Center network solutions, with strong experience in Spine-Leaf, and VxLAN with Cisco and Arista. Candidate should have over 10 years of experience as a network engineer supporting large enterprise environments, and a minimum of 5 years of hands on design/support experience on Data Center networking infrastructure (SME).', '', '', 'This role will provide ongoing network support for all enterprise network aspects, provide 2nd to last level of support to resolve complex issues, and is expected to be a technical leader for network guidance for other team members and management. Participation in on-call rotation is required. Candidates should be team oriented, have a strong sense of responsibility, adhere to SOPs, and effectively communicate with all levels of the organization. Candidates must also have strong verbal and written communication skills, and must know the importance of time management and prioritization, and understand criticality of uptime in a manufacturing environment.', '', '', 'This position will temporarily join the network team at the Samsung Austin Semiconductor facility (in North-East Austin) to received training, and learn about Samsung standards and procedures. After or during training, the work location will move to Taylor, TX to support the construction site network, and later to support the brand new manufacturing facility during implementation and ongoing operation.', '', '', 'This is an onsite role and employees must live within a 1-hour drive to Taylor, TX.', '', '', 'Samsung SDS is the digital arm of the Samsung group and a global provider of cloud and digital transformation innovations. Samsung SDS delivers enterprise-grade solutions and services in cloud, secure mobility, analytics / AI, digital marketing and digital workspace. We enable our customers in government, financial services, healthcare, and other industries to drive business in a hyper-connected economy helping them to increase productivity, safeguard assets, and make smarter decisions.', 'Responsibilities:', '', 'Provide senior level operational support for all company networks, including Data Center networks and legacy networks', 'Provide network support for issues escalated by other network team members and internal customers', 'Provide immediate response to restore service due to outage/impact events', 'Support the design and implementation of complex network architectures, including routing, switching, network security, load balancing and virtualization technology', 'Make recommendations for the Spine-Leaf topology designs, VxLAN EVPN, legacy networks.', 'Collaboration with other teams, such as system administrators, developers, and security teams to ensure that the data center network infrastructure is aligned with their requirement', 'Resolve assigned tickets in a timely manner to provide solutions to internal customers', 'Perform POC testing in a lab environment (HW/SW Validations, workarounds, etc.)', 'Review, provide feedback, and approve other team members’ network procedures (Release Plans) to validate technical accuracy for network changes, and help answer technical questions in Change Management meetings', 'Candidate must be available and willing to provide support 24/7 (overnight support as needed - due to the nature of our manufacturing environment) – Must respond to escalation tickets within SLA, and participate in an on-call rotation', 'Must adhere to standard operating procedures, standard configuration, check lists, and conform to corporate change-control and security policies', 'Participate in maintenance window planning, coordination, preparation, execution and monitoring', 'Perform network lifecycle management – Design, implement, manage, and support hundreds of critical network devices (Cisco and Arista switches, routers, PAN firewalls, F5 load balancers, Cisco wireless controller and access points, etc.)', 'Perform HW/SW upgrades, refresh/migration projects, expansion projects, plan and execute network changes, process RMAs, escalate and manage SRs with vendors, perform internal network audits and remediation', 'Excellent analytical, troubleshooting and communications skills at all organizations levels', 'Create reports per management request, and on a weekly basis', 'Setup and analyze packet captures to support network team and internal customers', 'Maintain and update documentation for all network systems, create completion reports, and conduct knowledge transfer to other team members', 'Must be a team player with passion to mentor other team members', 'Requirements', '', 'Bachelor’s Degree in Computer Science or related field', '', '10+ years of continuous large scale, enterprise class planning, design, implementation, and network support experience in network engineer positions', '', 'Expert Level: 5+ years of continuous hands on experience with Cisco/Arista EVPN VXLAN design and Spine-Leaf topologies, implementation and support', '', 'CCNP (Preferred CCNP Data Center or CCIE)', '', 'Strong experience with VPC configurations, MLAG, and best practices for server’s connectivity', '', 'Extensive routing protocol experience - EIGRP, OSPF, BGP, MPBGP, PIM and EVPN', '', 'Strong experience of VPC, STP, MLag, LACP, VRF, IPv4 subnetting, 802.1x, TACACS+, SYSLOG, Cisco IOS, Cisco NX-OS', '', 'Strong ability to troubleshoot complex issues related to hardware, L3/L2 deployment, applications', '', 'Experience with PIM, MSDP, Anycast-RP, Multicast', '', 'Strong experience with design, configuration, operations and support of Cisco Catalyst Switches, Nexus, Arista switches, Palo Alto Firewalls, and F5 Load Balancers’', '', 'Must live within 1 driving hour maximum from Taylor, TX', '', 'Strong customer focus, ownership, urgency and drive', '', 'Strong responsibility for network documentation, and passion to mentor other team members', '', 'Nice to have:', '', 'Experience with Packet Capture Analysis, SSL certificates, Cisco DCNM or ACI', 'Experience supporting connectivity for servers in a Data Center environment and Data Center design experience', '', 'Familiarity with Unix/Linux and the ability to script in Python, Ansible or other automation tools is a plus', '', 'Benefits', 'Samsung SDSA offers a comprehensive suite of programs to support our employees:', '', 'Top-notch medical, dental, vision and prescription coverage', '', 'Wellness program', '', 'Parental leave', '', '401K match and savings plan', '', 'Flexible spending accounts', '', 'Life insurance', '', 'Paid Holidays', '', 'Paid Time off', '', 'Additional benefits', 'Samsung SDS America, Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity or expression, national origin, disability, status as a protected veteran, marital status, genetic information, medical condition, or any other characteristic protected by law.']"
